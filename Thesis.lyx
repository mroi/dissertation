#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass tufte-book
\begin_preamble
% simplified title and author for fancy headers, height-correct the dash
\renewcommand{\plaintitle}{Practical Real\raisebox{-0.45mm}{-}Time with Look\raisebox{-0.45mm}{-}Ahead Scheduling}
\renewcommand{\plainauthor}{Michael Roitzsch}
\hypersetup{pdfauthor={\plainauthor}}

% typesetting tweaks
\clubpenalty=10000
\widowpenalty=10000
\relpenalty=9999
\binoppenalty=9999
\hyphenation{Atlas}

% font setup: disable Hoefler swashes, set math fonts
\usepackage{mathspec}
\setmainfont[ItalicFeatures={Contextuals={NoLineInitial,NoLineFinal}}]{Hoefler Text}
\setmathrm{Hoefler Text}
\setmathsfont(Digits,Latin)[ItalicFeatures={Contextuals={NoLineInitial,NoLineFinal}},Numbers={Lining,Proportional}]{Hoefler Text}
\setmathsfont(Greek){Georgia}
% restore mathspec's activation of " at document beginning, someone messes with it
\begingroup
\catcode`\"=\active
\AtBeginDocument{\let"=\eu@active@quote}
\endgroup

% letter spacing for capitalized text
\renewcommand{\allcapsspacing}[1]{{\addfontfeature{LetterSpace=6.5}#1}}
\renewcommand{\smallcapsspacing}[1]{{\addfontfeature{LetterSpace=5.0,Letters=SmallCaps}#1}}

% lining figures for bibtex references (usually enabled by using math mode)
\newcommand{\liningfigures}[1]{{\addfontfeature{Numbers=Lining}#1}}

% use all-bullets for itemize and give them the right size and height
\AtBeginDocument{
\def\labelitemi{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
\def\labelitemii{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
\def\labelitemiii{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
\def\labelitemiv{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
}

% top-align floats on float pages
\setlength\@fptop{0pt}
% do not indent the bibliography
\setlength{\bibhang}{0pt}

% QR-code generator used for some URLs
\usepackage{pst-barcode}

% repeat tufte caption definition because it gets garbled by hyperref
\long\def\@caption#1[#2]#3{\par%
\addcontentsline{\csname ext@#1\endcsname}{#1}%
{\protect\numberline{\csname the#1\endcsname}{\ignorespaces #2}}%
\begingroup%
\@parboxrestore%
\if@minipage\@setminipage\fi%
\@tufte@caption@font\@tufte@caption@justification%
\noindent\csname fnum@#1\endcsname: \ignorespaces#3\par%
\endgroup}

% colored page edge when a new chapter starts
\newcommand{\chapteredge}{
\fancypagestyle{plain}{
\fancyhf{}
\fancyfoot[LE,RO]{
\begin{picture}(0,0)
\color{gray}
\put(49,-60){\rule{10mm}{305mm}}
\end{picture}
}}}
\newcommand{\nochapteredge}{
\fancypagestyle{plain}{
\fancyhf{}
}}

% alternative chapter titling with big chapter number on the right
\titleformat{\chapter}[display]
{\relax\ifthenelse{\NOT\boolean{@tufte@symmetric}}{\begin{fullwidth}}{}}
{\hfill\sffamily\color{gray}\fontsize{42}{0}\selectfont\thechapter}
{0pt}
{\vskip -32pt\huge\rmfamily\itshape}
[\ifthenelse{\NOT\boolean{@tufte@symmetric}}{\end{fullwidth}}{}]

% epigraph commands
\newcommand{\epigraphquote}[1]{
\begin{fullwidth}
\sffamily\Large
\begin{doublespace}
\noindent\allcaps{#1}\\
}
\newcommand{\epigraphsource}[1]{
\color{darkgray}\noindent\allcaps{#1}
\end{doublespace}
\end{fullwidth}
}

% use my own palette of gray tones
\definecolor{note_fontcolor}{HTML}{808785}
\definecolor{gray}{HTML}{808785}
\definecolor{darkgray}{HTML}{48494B}
\end_preamble
\options a4paper
\use_default_options true
\begin_modules
fixltx2e
enumitem
logicalmkup
\end_modules
\maintain_unincluded_children false
\begin_local_layout
Style EpigraphQuote
Category	FrontMatter
LatexType	Command
LatexName	epigraphquote
LeftMargin	MM
Font
Family	Sans
Shape	Smallcaps
EndFont
End

Style EpigraphSource
Category	FrontMatter
LatexType	Command
LatexName	epigraphsource
LeftMargin	MM
Font
Family	Sans
Shape	Smallcaps
EndFont
End

Style Verleger
Category	FrontMatter
LatexType	Command
LatexName	publisher
Margin	Static
InTitle	1
InPreamble	1
Font
Size	Large
EndFont
End

InsetLayout Flex:NoWrap
LyxType	charstyle
LabelString	NoWrap
LatexType	Command
LatexName	mbox
HTMLTag	span
HTMLAttr	style='white-space:nowrap'
End
\end_local_layout
\language english
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman Hoefler Text
\font_sans Gill Sans
\font_typewriter Menlo
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 83

\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Practical Real-Time with Look-Ahead Scheduling"
\pdf_author "Michael Roitzsch"
\pdf_subject "Dissertation"
\pdf_keywords "Real-Time, Look-Ahead, Work Queues, Asynchronous Lambdas, Deadlines, Adaptive"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 2
\pdf_breaklinks true
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\papersize default
\use_geometry true
\use_amsmath 2
\use_esint 0
\use_mhchem 0
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 0
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\listings_params "aboveskip=0pt,basicstyle={\ttfamily\small},belowskip=0pt,language=C,numberstyle={\ttfamily\small\color{gray}},tabsize=2"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
\begin_inset Flex AllCaps
status collapsed

\begin_layout Plain Layout
Outer Front Cover Placeholder
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\end_layout

\begin_layout EpigraphQuote
I love deadlines.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newline
\backslash
noindent
\end_layout

\end_inset

 I love the whooshing noise they make as they go by.
\end_layout

\begin_layout EpigraphSource
Douglas Adams
\end_layout

\begin_layout Standard
\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout EpigraphQuote
The art of prophecy is very difficult,
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newline
\backslash
noindent
\end_layout

\end_inset

 especially with respect to the future.
\end_layout

\begin_layout EpigraphSource
Mark Twain
\end_layout

\begin_layout Standard
\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout EpigraphQuote
Oh dear! Oh dear! I shall be too late!
\end_layout

\begin_layout EpigraphSource
The White Rabbit
\end_layout

\begin_layout Standard
\begin_inset Newpage cleardoublepage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
frontmatter
\end_layout

\end_inset


\end_layout

\begin_layout Author
Michael Roitzsch – born August 15, 1980
\end_layout

\begin_layout Title
Practical Real
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.8mm}{
\end_layout

\end_inset

-
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

Time
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

with Look
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.8mm}{
\end_layout

\end_inset

-
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

Ahead
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Scheduling
\end_layout

\begin_layout Verleger
Dissertation
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Advisor: Prof.
\begin_inset space ~
\end_inset

Dr.
\begin_inset space ~
\end_inset

rer.
\begin_inset space ~
\end_inset

nat.
\begin_inset space ~
\end_inset

Hermann Härtig
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Technische Universität Dresden
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Graphics
	filename Figures/TU-Logo.pdf
	width 5cm

\end_inset


\end_layout

\begin_layout Full Width

\lang ngerman
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout

\lang ngerman
Dissertation
\end_layout

\end_inset

 zur Erlangung des akademischen Grades 
\begin_inset Flex AllCaps
status collapsed

\begin_layout Plain Layout

\lang ngerman
Doktoringenieur
\begin_inset space ~
\end_inset

(Dr.-Ing.)
\end_layout

\end_inset

, vorgelegt an der 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout

\lang ngerman
Technischen Universität Dresden, Fakultät Informatik
\end_layout

\end_inset

, eingereicht von
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset


\begin_inset Flex AllCaps
status collapsed

\begin_layout Plain Layout

\lang ngerman
Dipl.-Inf.
\begin_inset space ~
\end_inset

Michael
\begin_inset space ~
\end_inset

Roitzsch
\end_layout

\end_inset

, geboren am 15.
\begin_inset space ~
\end_inset

August 1980 in Dresden.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Full Width

\lang ngerman
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="0pt" special="@{}l">
<column alignment="left" valignment="top" width="0pt">
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Betreuender Hochschullehrer:
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Prof.
\begin_inset space ~
\end_inset

Dr.
\begin_inset space ~
\end_inset

rer.
\begin_inset space ~
\end_inset

nat.
\begin_inset space ~
\end_inset

Hermann Härtig,
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Technische Universität Dresden
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Zweitgutachter:
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Prof.
 Dr.
 Gerhard Fohler,
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Technische Universität Kaiserslautern
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Fachreferent:
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Prof.
\begin_inset space ~
\end_inset

Dr.
\begin_inset space ~
\end_inset

Christof Fetzer,
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Technische Universität Dresden
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Statusvortrag:
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
12.
\begin_inset space ~
\end_inset

Dezember 2011
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Abgabe:
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\lang ngerman
fehlt
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Full Width

\lang ngerman
\begin_inset VSpace bigskip
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Dresden, 
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\lang ngerman
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
Acknowledgments
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
OS group, Prof.
\begin_inset space ~
\end_inset

Härtig, fellow researchers, friends, parents
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage cleardoublepage
\end_inset


\end_layout

\begin_layout Full Width
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\begin_inset VSpace vfill
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent
\backslash
nohyphenation 
\end_layout

\end_inset


\shape italic
\size huge

\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\shape italic
\size huge
Dedication
\end_layout

\end_inset


\end_layout

\begin_layout Full Width
\begin_inset VSpace vfill
\end_inset


\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
mainmatter
\backslash
chapteredge
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The evolution of computing
\end_layout

\end_inset

 has treated users with an impressive stream of innovation: From the mainframe
 era through the age of productivity computing to today’s multimedia and
 mobile world, the capabilities of systems and thus the possibilities for
 users increased steadily.
 This sea change thrives on the exponential improvement of the underlying
 transistor technology as predicted by Moore’s Law:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Moore’s law
\end_layout

\end_inset

 The number of transistors that can be integrated cost efficiently doubles
 approximately every two years.
\begin_inset Foot
status open

\begin_layout Plain Layout
This period is often misquoted as 18 months, which is a follow-up prediction
 of the increase in single chip performance.
 (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "CNET News: Moore’s Law to roll on for another decade"
target "http://news.cnet.com/2100-1001-984051.html"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset

 Software matches this exponential growth: The total body of open source
 software in the world doubles about every 14 months.
\begin_inset CommandInset citation
LatexCommand cite
key "Deshpande:GrowthSoftware"

\end_inset


\end_layout

\begin_layout Section
Application Necessities
\end_layout

\begin_layout Standard
Users have grown accustomed to the constant improvement of technology.
 What started as high-end and expert use cases will become a commodity just
 a few years later and will be expected to work predictably and efficiently.
 The previous generation iPad
\begin_inset space ~
\end_inset

2 would have been in 1994’s Top
\begin_inset space ~
\end_inset

500 list of the fastest computers in the world
\begin_inset CommandInset citation
LatexCommand cite
key "Markoff:DongarraIPad"

\end_inset

 and it is arguably more intelligible today than those supercomputers were
 back then.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Living up to these expectations
\end_layout

\end_inset

 is a demanding job for developers.
 Users are no longer satisfied with functionality alone.
 Increasingly, 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
non-functional properties
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
non-functional properties
\end_layout

\end_inset

 separate good from great applications.
 Next to user interface design and visual appearance such properties include
 responsive and stutter-free operation,
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:FastFluid"

\end_inset

 perceived performance, and the useful and efficient employment of the invested
 resources,
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:PowerEfficiency"

\end_inset

 also driven by the resource and energy constraints of today’s battery-powered
 devices.
\end_layout

\begin_layout Standard
My dissertation is motivated by a need to integrate the non-functional requireme
nts within applications with system-wide decision-making.
 The following properties exemplify such cooperation opportunities:
\end_layout

\begin_layout Description
Timeliness:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timeliness
\end_layout

\end_inset

 User interface responsiveness and the smoothness of multimedia operations
 require that applications’ 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset

 are met.
\begin_inset CommandInset citation
LatexCommand cite
key "Sasinowski:ARTIFACT"

\end_inset

 Such requirements arise when computers interface with the real world.
 Subsumed under the term real-time,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
real-time
\end_layout

\end_inset

 these constraints tie the completion of software results to wall-clock
 time.
 A system-wide solution is needed, because time is a global resource.
 However, the majority of commodity systems today offer only weak temporal
 guarantees and predictability to applications, so developers have to work
 around those limitations.
 While real-time operating systems are available, they are typically applied
 only in special-purpose scenarios.
\begin_inset Foot
status open

\begin_layout Plain Layout
A notable exception is the BlackBerry PlayBook,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
BlackBerry PlayBook
\end_layout

\end_inset

 a general-purpose tablet computer which runs the real-time capable QNX
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
QNX
\end_layout

\end_inset


\end_layout

\end_inset

 kernel.
 (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "QNX: Meet the Power Behind the BackBerry Tablet OS"
target "http://www.qnx.com/company/announcements/power_behind_playbook.html"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset


\end_layout

\begin_layout Description
Quality-Aware
\begin_inset space \space{}
\end_inset

Overload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
overload
\end_layout

\end_inset


\begin_inset space \space{}
\end_inset

Mitigation: Overload situations occur when all ready applications collectively
 ask for more computation time than the machine can offer without violating
 any timing constraints.
 Real-time systems avoid such situations statically with an admission
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
admission
\end_layout

\end_inset

 process: The system will not allow new tasks unless it can establish a
 formal guarantee that the total resource demand will never outgrow the
 available resources.
 On interactive systems, users will not accept rejected application launches.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:UserControl"

\end_inset

 These systems have to handle overload situations dynamically at runtime
 by reducing the resource allotment of a subset of applications.
 This reduction needs global oversight to maintain the system’s fairness
 policy, but applications may want to adapt their service according to a
 local notion of quality.
 Instead of keeping information local for limited management within applications
, I propose to aggregate knowledge of 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset

 to globally predict overload.
 Communicating these situations 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
ahead of time
\end_layout

\end_inset

 allows applications to prepare before the resource shortage arrives.
\end_layout

\begin_layout Description
Usage
\begin_inset space \space{}
\end_inset

of
\begin_inset space \space{}
\end_inset

Multiple
\begin_inset space \space{}
\end_inset

Cores: Single-core performance is leveling off, so processor manufacturers
 rely on increasing core counts to offer higher performance.
 Applications thus have to employ parallel programming to benefit from multiple
 cores.
\begin_inset CommandInset citation
LatexCommand cite
after "-6\\baselineskip"
key "Sutter:FreeLunch"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 The ideas I present here build on top of a modern parallel runtime, but
 I leave the exploration of scheduling aspects on multiple cores for future
 work.
 Users only perceive core usage indirectly, timeliness and responsive behavior
 under overload are directly observable.
 For that reason I want to focus on these two properties.
 But processors are a global resource, so assigning work to cores requires
 system-wide control.
 Therefore, I hint at extensions of my work toward contention-
\begin_inset CommandInset citation
LatexCommand cite
after "-10\\baselineskip"
key "Zhuravlev:DIO"

\end_inset

 and energy-aware
\begin_inset CommandInset citation
LatexCommand cite
after "-4\\baselineskip"
key "Rangan:ThreadMotion"

\end_inset

 core placement at the end of this thesis.
\end_layout

\begin_layout Full Width
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
Non-functional properties such as timeliness and quality-aware overload
 handling benefit from the aggregation of local application knowledge to
 implement a global system-wide policy.
 My mission is to show that a little added developer effort can be augmented
 by a newly designed runtime and lead to closer cooperation with the scheduler,
 enhancing application behavior with respect to non-functional properties.
 While I do not explore scheduling on multiple cores, the design does not
 rule it out.
 In this thesis, I demonstrate how communicating application’s timing requiremen
ts helps overall timeliness, how knowledge on resource requirements enables
 overload detection and how ahead-of-time overload notification improves
 quality when adapting.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Developing a modern application
\end_layout

\end_inset

 is already a complex undertaking, because users expect intricate features
 and applications have to handle new failure cases by connecting with the
 cloud.
 To face non-functional properties on top of that, developers need to rely
 on a foundation that helps them deliver without much development overhead.
 Systems research can and should help here.
 Libraries can mediate between the application’s view and the system interface.
 I will now motivate my work from the system’s perspective and show that
 the cross-cutting nature of non-functional properties calls for participation
 of the lower system levels.
\end_layout

\begin_layout Section
Scheduler Knowledge
\end_layout

\begin_layout Standard
As illustrated by Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Interaction"

\end_inset

, the scheduler
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
scheduler
\end_layout

\end_inset

 is a system component responsible for accumulating information about the
 work applications want to perform and determine an order to execute that
 work.
 The ordering policy should serve the non-functional properties applications
 expect: It should fulfill timing requirements and handle overload early
 and fairly.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Interaction_Application_Scheduler.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Interaction"

\end_inset

Interaction Between Application and Scheduler
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Every device in a computer system
\end_layout

\end_inset

 has a different notion of work: sending and receiving network packets,
 reading and writing storage requests or the execution of graphics shader
 code.
 Consequently, every devices follows a different policy for ordering its
 work and thus needs its own dedicated scheduler.
 However, this thesis focuses exclusively on scheduling a single CPU
\begin_inset Foot
status open

\begin_layout Plain Layout
Central Processing Unit: the assembly of general purpose processors executing
 the operating system and application code (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Wikipedia: Central Processing Unit"
target "http://en.wikipedia.org/w/index.php?title=Central_processing_unit&oldid=511660312"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset

 core of a computer system.
 The CPU plays a central role in the system as it is the gateway for the
 scheduling of all other devices.
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

 To submit work to a peripheral device, applications need to execute code
 on the CPU.
\end_layout

\begin_layout Standard
Nevertheless, taking a closer look at peripheral schedulers does help to
 reveal an important disadvantage of CPU scheduling: Schedulers for peripheral
 devices have a deeper insight into the jobs they are supposed to order.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
So how does a peripheral scheduler operate?
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
peripheral device scheduling
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Love:IO_Schedulers"

\end_inset

 We start with an application asking for the service of a device.
 A write request to persistent storage shall serve as an example.
 The application collects the data it wants to make durable and submits
 a job toward the device.
 A write request to a file traverses file system and buffer caching code
 in the operating system and finally arrives at the device driver as a write
 request to the magnetic disk.
 As part of the driver, the scheduler maintains a work queue of jobs waiting
 for execution.
 Our write request is added to that queue together with concurrent requests
 arriving from other applications, from other threads of the same application,
 or even from the same thread of the same application, if the initial write
 executes asynchronously.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Device-Scheduling"

\end_inset

 depicts this situation.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Peripheral_Scheduling.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Device-Scheduling"

\end_inset

Peripheral Device Scheduling
\end_layout

\end_inset


\end_layout

\end_inset

The scheduler now orders the jobs and sends them off to the device for execution.
 The scheduling algorithm performs that ordering with a service goal in
 mind, for example to maximize device throughput.
 Every job carries metadata for the request.
 In the case of our disk write request, that metadata contains the size
 of the request and its location on disk.
\end_layout

\begin_layout Standard
When ordering jobs, the scheduler can inspect the metadata to decide which
 order best supports its service goal.
 The disk scheduler in the example can use the on-disk location to execute
 a shortest access time first
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
shortest access time first
\end_layout

\end_inset

 policy
\begin_inset CommandInset citation
LatexCommand cite
key "Jacobson:SATF"

\end_inset

 to improve drive throughput.
 Peripheral device schedulers enjoy the advantage that the outstanding requests
 are self-describing jobs.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
self-describing job
\end_layout

\end_inset

 Inspecting them reveals all information the peripheral will use to execute
 them.
 This is natural, because to program the device, the driver must have all
 that information available anyway.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The CPU scheduler
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
CPU
\end_layout

\end_inset

 scheduling
\end_layout

\end_inset

does not share this benefit: It does not deal with self-describing jobs
 in a queue of outstanding work.
 Instead, it maintains a ready queue of runnable threads.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
thread
\end_layout

\end_inset

 Other than a job, a thread is not consumed after it executed, but is automatica
lly inserted into the ready queue again until terminated by the application.
 Other than a job, a thread is not a self-describing aggregate of payload
 and metadata, but rather an opaque handle to an execution context within
 the application’s address space.
 The actual behavior that unfolds if the thread is executing
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

whether it blocks after a short burst of code, or runs a long computation,
 or a periodic task
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

is hidden within the application’s code and memory state as illustrated
 by Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:CPU-Scheduling"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/1-Introduction/CPU_Scheduling.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:CPU-Scheduling"

\end_inset

CPU Scheduling
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
CPU schedulers in commodity operating systems support a notion of precedence,
 expressed with priorities
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
priority
\end_layout

\end_inset

 or the Unix nice levels.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
nice level
\end_layout

\end_inset

 This single numeric value
\begin_inset CommandInset citation
LatexCommand cite
key "Unix:Nice"

\end_inset

 is a coarse abstraction of a thread’s behavior, because it only indicates
 the importance of a thread relative to other threads.
 The application developer has to supply the priority without knowledge
 of concurrent load, which gives rise to other problems I discuss in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

.
\end_layout

\begin_layout Standard
Real-time schedulers supporting a periodic task model
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
periodic task model
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RMS"

\end_inset

 have the benefit of implicit knowledge about a thread’s upcoming behavior,
 but only for applications fitting into that rigid model.
 More details again follow in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
In this thesis,
\end_layout

\end_inset

 I want to argue that it is beneficial to organize CPU scheduling using
 self-describing jobs similar to peripheral schedulers.
 Those CPU jobs represent a specific piece of code execution and are consumed
 once the CPU executed them.
 They carry metadata describing the jobs’ urgency and required execution
 time.
 If the CPU scheduler receives jobs ahead-of-time, before they execute,
 it can build up a limited look into the applications’ future and detect
 overload situations early.
 In contrast to periodic task models, this knowledge is not available implicitly
, but applications share information with the scheduler by submitting jobs
 explicitly.
 I show how such a scheduling regime improves the non-functional application
 properties portrayed above.
\end_layout

\begin_layout Section
Driving Insights
\end_layout

\begin_layout Standard
The walk-through of the problem area shows that the considered non-functional
 properties timeliness and quality-aware overload mitigation are cross-cutting
 concerns.
 They involve local knowledge from the applications and global policy executed
 by the scheduler.
 Furthermore, many applications act as an execution environment tailored
 to a specific workload:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload
\end_layout

\end_inset

 a text editor manipulates documents, a photo album manages photos, a video
 player renders continuous media.
 Those applications’ behavior dynamically depends on the workload they handle.
 This workload is what users care about after all.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
A vertically integrated solution
\end_layout

\end_inset

 spanning from the workload through the application down to the scheduler
 is called for.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace -1mm
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Verically_Integrated_Solution.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Vertically-Integrated-Solution"

\end_inset

Vertically Integrated Solution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

Refining the previous concept sketch from Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Interaction"

\end_inset

, Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Vertically-Integrated-Solution"

\end_inset

 shows how I imagine this integration to operate.
 Applications should be aware of their workload and extract information
 to model it.
 They communicate a useful representation of their local knowledge down
 to the scheduler.
 The scheduler collects this knowledge from all applications and executes
 its global policy, consequences of this policy take effect either implicitly
 by executing the scheduling decisions, or explicitly by the scheduler reporting
 back to an application.
 Overload situations propagate this way, because they require an application-spe
cific notion of quality to resolve them.
 The application in turn uses its model of the workload to decide on a quality-a
ware reaction.
\end_layout

\begin_layout Standard
What information is relayed along those paths and what the interfaces look
 like remains to be discussed.
 But as motivated in the section on scheduler knowledge above, the scheduler
 should operate on self-contained jobs instead of threads which hide their
 execution behavior deep in the application state.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Applications should expose local knowledge
\end_layout

\end_inset

 to the scheduler by explicitly submitting self-describing jobs that encapsulate
 timing and resource requirements depending on the current workload.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

To provide knowledge explicitly, applications likely have to be modified.
 We may get away with adapting key libraries to change the behavior of multiple
 applications at once, but in the context of this dissertation, modifying
 a library counts as modifying the application.
 How to reduce programming effort by architecting software so it hides this
 problem in library layers is outside the scope of this thesis.
 In scope however is to design the interfaces for ease of use:
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The programming model should be approachable
\end_layout

\end_inset

 by matching current application development methods and by never asking
 the developer for parameters outside the application domain.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

I hope developers can provide parameters from within the application domain
 with reasonable effort.
 An example are deadlines
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset

 to describe the timing requirements of a job.
 Parameters requiring knowledge outside the application scope should be
 avoided.
 Developers should not need to provide estimated execution times of jobs,
 because these are specific to the underlying hardware platform.
\end_layout

\begin_layout Standard
An emerging trend in the development of parallel software is the use of
 lambdas,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
lambda
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:LambdasEverywhere"

\end_inset

 depending on the programming language also called closures
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
closure
\end_layout

\end_inset

 or blocks.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset

 They are used to structure code into pieces that can be executed asynchronously
, which keeps applications responsive in the presence of long-running background
 computation or blocking operations.
 Because asynchronously executed code runs concurrently with other code,
 lambdas are also a tool to express parallelism.
 A more in-depth discussion of this programming style follows in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-chap:Anatomy"

\end_inset

.
 I will illustrate how lambdas and jobs can cooperate
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

both describe a bounded, self-contained piece of code execution
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

and how the communication of jobs to the scheduler integrates with the use
 of lambdas.
 Big platform vendors such as Apple
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatchIntro"

\end_inset

 and Microsoft
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:C++PPL"

\end_inset

 adopted lambda programming, so by drafting a scheduler interface that leans
 toward it, I hope to create a pragmatic solution that developers can adopt
 as part of their programming toolbox.
\end_layout

\begin_layout Standard
The asynchronous execution of lambdas gives rise to another interesting
 benefit: announcing future code execution ahead-of-time.
 Application code can specify multiple pieces of work and dispatch them
 for later asynchronous and potentially parallel execution.
 The queues in the lambda runtime therefore contain knowledge about what
 pieces of code will execute in the future.
 Again, more details on how these runtimes operate follow in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-chap:Anatomy"

\end_inset

.
 Here we conclude:
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Knowledge of future execution
\end_layout

\end_inset

 should be propagated to the scheduler.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

I expect many applications to have knowledge on their future execution available
, but they currently lack a way to expose this information.
 Any operation that runs autonomously after being triggered by a system
 event or user interaction is fully determined at the moment it is triggered.
 If a user clicks “play” to watch a video, the application knows that it
 will now be fetching, decoding and displaying video frames.
\end_layout

\begin_layout Standard
Like video, some of these chains of actions may be long-running, others
 may be short, like the reaction to a user’s mouse click in a graphical
 interface.
 Highly interactive applications like games may have almost no knowledge
 of what will happen next, because the user can change the course of action
 at any moment.
 However, applications that do have knowledge of their future should be
 able to tell the scheduler about it early.
 Such insights enable the system to perform 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
look-ahead scheduling:
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
look-ahead scheduling
\end_layout

\end_inset

 It can make ahead-of-time, anticipating decisions rather than exercising
 post-mortem, reactive control.
\end_layout

\begin_layout Section
Thesis Goals
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
In this dissertation, I target two scheduling-related problems:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

timeliness and
\end_layout

\begin_layout Itemize
quality-aware overload mitigation.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
I chose these problems because I believe they constitute important non-functiona
l properties,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
non-functional properties
\end_layout

\end_inset

 which applications should offer to their users.
 Therefore, I investigate these problems in the context of interactive end-user
 systems,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
interactive systems
\end_layout

\end_inset

 running a commodity operating system
\begin_inset CommandInset citation
LatexCommand cite
key "StatCounter:OSMarketShare"

\end_inset

 as an application platform.
 This category of systems includes classical desktop computers, notebooks
 and the ballooning family of smartphones and tablets.
 It does not include servers, although I am confident that my ideas generalize
 to this class of systems due to the large amount of shared technology.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I do not consider reactive systems
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
reactive systems
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Harel:ReactiveSystems"

\end_inset

 that continuously supervise sensors and actuators, for example in an industrial
 control environment or within other deeply embedded systems.
 Graphical and touch user interfaces however are subject to timing constraints
 dictated by the physical reality.
 Here, human-machine-interfaces and reactive systems overlap.
\begin_inset CommandInset citation
LatexCommand cite
key "Halbwachs:LUSTRE"

\end_inset

 Beyond these common timeliness demands, I ignore reactive systems in this
 work.
\end_layout

\begin_layout Standard
Similarly, I do not consider offline scheduling, where a precomputed schedule
 is reenacted at runtime.
 In a dynamic, interactive system, advance knowledge on the executed task
 set is generally not available.
 Therefore, I exclusively research online scheduling, where scheduling decisions
 happen while the system runs.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/1-Introduction/Deadline_Types.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Deadline-Types"

\end_inset

Types of Real-Time Deadlines
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset

Real-time literature
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RealTimeSystems"

\end_inset

 distinguishes between systems with hard,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
hard deadline
\end_layout

\end_inset

 firm
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
firm deadline
\end_layout

\end_inset

 and soft deadlines.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
soft deadline
\end_layout

\end_inset

 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Deadline-Types"

\end_inset

 shows the delineating characteristics.
 Hard deadlines must never be missed and the system has to guarantee this
 invariant with a formal analysis.
 For firm and soft deadlines, weaker guarantees apply.
 Deadlines may be missed, but with predictable consequences.
 Jobs missing a firm deadline are aborted, whereas results arriving after
 a soft deadline are still useful.
\end_layout

\begin_layout Standard
I think an interactive system should not reject the user’s instruction to
 start an application.
 Therefore, a task admission
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
admission
\end_layout

\end_inset

 is not appropriate and consequently, the system cannot handle hard deadlines.
 Overload situations may occur and my solution provides methods to handle
 them.
 It is up to the application to decide on aborting the job or continuing.
\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Three layers have to be bridged
\end_layout

\end_inset

 for a comprehensive solution:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

workload,
\end_layout

\begin_layout Itemize
application, and
\end_layout

\begin_layout Itemize
CPU scheduler.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
I presume that combining application-specific knowledge on workload and
 execution behavior with system-wide knowledge on urgency and overall load
 is beneficial.
 Any solution that handles any of these aspects in isolation will be incomplete.
 Instead, applications and the scheduler have to collaborate
\begin_inset CommandInset citation
LatexCommand cite
key "Peter:EndToEndScheduler"

\end_inset

 to integrate application-local and global scheduling mechanisms.
 I propose self-describing jobs as this integrative device.
 To encourage adoption, application developers should not face different
 programming paradigms for different non-functional properties, but one
 wholesale solution.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Integration
\end_layout

\end_inset

 along the properties dimension and the layers dimension is crucial.
 The following Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-tab:Overview-Thesis"

\end_inset

 summarizes the thesis goals:
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="16text%">
<column alignment="left" valignment="top" width="36text%">
<column alignment="left" valignment="top" width="36text%">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timeliness
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timeliness
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Overload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
overload
\end_layout

\end_inset

 Mitigation
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Workload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
derive workload metrics to predict execution times
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
offer degraded processing options
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Application
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
expose deadlines and execution time estimates ahead of time
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
balance resource and quality impact of load shedding
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CPU Scheduler
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
scheduler
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
globally order jobs to meet deadlines, detect misses ahead of time
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
exert back-pressure when anticipating deadline misses
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Enabling Feature
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timing
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset

 and Resource Requirements
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scheduler Look-Ahead
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
look-ahead scheduling
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thesis Chapter
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset ref
LatexCommand nameref
reference "3-chap:Real-Time"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Adaptivity"

\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset ref
LatexCommand nameref
reference "4-chap:Adaptivity"

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace 15pt
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-tab:Overview-Thesis"

\end_inset

Overview of the Solution Developed in This Thesis
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Vertical integration across the three layers is necessary, because no layer
 alone has enough knowledge to provide the desired non-functional property.
 Horizontal integration across the properties is necessary to curb complexity
 for the developer and because of the cross-talk between the properties.
\end_layout

\begin_layout Standard
A large body of individual research results is available covering the six
 intersections of my goals matrix.
 In this dissertation I provide a comprehensive, end-to-end solution and
 I demonstrate improvements over the state of the art in each property lane.
 The scheduling system I present is dubbed 
\noun on
Atlas
\noun default
, the Auto-Training Look-Ahead Scheduler.
\begin_inset Foot
status open

\begin_layout Plain Layout
Like its namesake, the Greek titan who supports the celestial globe (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Wikipedia: Atlas"
target "http://en.wikipedia.org/wiki/Atlas_(mythology)"

\end_inset


\end_layout

\end_inset

), I hope the 
\noun on
Atlas
\noun default
 system can support applications and developers.
\end_layout

\end_inset

 I will now give an overview of the work within each property lane and summarize
 the key contributions.
 Each lane is discussed in detail in its own chapter.
\end_layout

\begin_layout Section
Timeliness
\end_layout

\begin_layout Standard
Timeliness is the primary property of real-time scheduling.
 The scheduling policy considers secondary service goals only when timeliness
 is not jeopardized.
 Time is a global resource and is therefore managed by a system-wide scheduler.
 Imposing a separation of concerns as in the resource kernels concept,
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

 applications specify their timing requirements to the scheduler, which
 then exercises global management.
 This functional separation must be accompanied by an integration of knowledge:
 Only the application knows its workload and should expose this knowledge
 to the scheduler using appropriate interfaces.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I contribute a scheduler interface
\end_layout

\end_inset

 and an accompanying task model and runtime infrastructure that allow applicatio
ns to express timing and resource requirements.
 Other than the majority of related work, I do not employ a periodic task
 model.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
periodic task model
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RMS"

\end_inset

 Explicit submission of future jobs substitutes the implicit knowledge on
 future execution that periods provide.
\end_layout

\begin_layout Standard
The 
\noun on
Atlas
\noun default
 interface as seen by the application developer only asks for parameters
 from the application domain.
 Deadlines specify timing requirements.
 Resource requirements are specified using 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
workload metrics:
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

 parameters from the workload that describe its computational weight.
 
\noun on
Atlas
\noun default
 uses machine-learning to automatically derive execution time estimates
 from the metrics before the actual execution.
 The estimated execution time of each job is therefore known ahead of time.
 I presented the prediction method employed by 
\noun on
Atlas
\noun default
 on the 27
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

 IEEE Real-Time Systems Symposium
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Predict"

\end_inset

 and the overall 
\noun on
Atlas
\noun default
 architecture on the 19
\begin_inset script superscript

\begin_layout Plain Layout
th
\end_layout

\end_inset

 IEEE Real-Time and Embedded Technology and Applications Symposium.
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:ATLAS"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
BibTeX entry lacks the DOI link
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The 
\noun on
Atlas
\noun default
 runtime has been designed with current programming trends in mind.
 It explores the interaction between real-time jobs and asynchronous lambdas.
 I believe this combination has not been investigated yet.
 I demonstrate with code examples that the task model is easy to program
 against.
 However, a formal usability analysis of the programming interface is not
 part of this thesis.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I claim that the flexibility of this task model
\end_layout

\end_inset

 allows to inform the scheduler more accurately of application behavior
 than alternative approaches.
 I validate this claim by demonstrating that 
\noun on
Atlas
\noun default
 can predict the future execution of applications precise enough to anticipate
 deadline misses before they occur.
 Outside the implicit clairvoyance of periodic task systems, no other scheduling
 system I am aware of features a comparable look-ahead capability.
\end_layout

\begin_layout Standard
Literature mentions look-ahead together with scheduling in the areas of
 constraint satisfaction problems,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
constraint satisfaction problem
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Schaerf:CSP"

\end_inset

 factory scheduling,
\begin_inset CommandInset citation
LatexCommand cite
key "Itoh:ProductionScheduling"

\end_inset

 and server management for on-demand video.
\begin_inset CommandInset citation
LatexCommand cite
key "Yu:VOD_LookAhead"

\end_inset

 For constraint satisfaction problems and factory scheduling, look-ahead
 improves the traversal of the solution search space.
 Thus, the scheduling does not look ahead along the time axis into the future,
 but along the search tree into the solution space.
 In the on-demand video context, the server tries to batch multiple viewers
 of the same video to save disk requests.
 Look-ahead and buffering help the server to satisfy multiple users from
 the same disk stream, even if they independently pause and resume playback.
 Patterson
\begin_inset space ~
\end_inset

et
\begin_inset space ~
\end_inset

al.
\begin_inset space ~
\end_inset

investigated the submission of future jobs to a peripheral scheduler to
 improve prefetching for input devices.
\begin_inset CommandInset citation
LatexCommand cite
key "Patterson:InformedPrefetching"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I also evaluate the timeliness
\end_layout

\end_inset

 delivered by 
\noun on
Atlas
\noun default
 due to its compliance with the requested timing requirements.
 I compare with the behavior under conventional fair share scheduling without
 timing constraints.
 This evaluation serves to convince the reader of the scheduler’s basic
 functionality with respect to the timeliness property.
 I do not claim to improve the state of the art in this aspect.
\end_layout

\begin_layout Standard
I describe and evaluate the real-time task model and scheduler in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

.
 This chapter also comprehensively explains the fundamental architecture
 of 
\noun on
Atlas
\noun default
, which the succeeding two chapters build upon.
 I use a complete implementation stack from application runtime down to
 an in-kernel scheduler to experiment with timeliness.
\end_layout

\begin_layout Section
Overload Mitigation
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 does not enforce an admission process.
 I think rejecting application launches or new subtasks within an application
 would be too surprising for the user and the developer.
 Consequently, the system can experience overload situations.
 Lacking an admission that can analytically prevent overloads, 
\noun on
Atlas
\noun default
 instead needs to offer mechanisms that handle overload gracefully.
\end_layout

\begin_layout Standard
Overload can occur for two reasons: First, an application can lie about
 its CPU demand.
 It announces timing and resource requirements that the scheduler can meet
 with idle computing capacity.
 However, at runtime, the application’s jobs run longer than reported.
 The scheduler handles such situations by ensuring that lying applications
 never degrade the service of honest applications.
\end_layout

\begin_layout Standard
The second overload condition is more interesting: Applications specify
 their demands correctly, but collectively ask for more CPU resources than
 available.
 In such a situation, service degradation is unavoidable.
 The best the system can do is control the overload to maximize the quality
 delivered to the user.
 Quality is a workload-specific measure and applications may apply custom
 strategies to adapt to overload.
\begin_inset CommandInset citation
LatexCommand cite
after "-24pt"
key "Isovic:QoS_Video"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 Interaction between scheduler and applications is therefore needed.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I contribute quality-weighted back-pressure
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
back-pressure
\end_layout

\end_inset

as a mechanism to communicate overload mitigation from the scheduler to
 applications.
 When the scheduler detects an overload situation, it forcibly reduces the
 CPU time allocated to each application so that the overload is resolved.
 These cutbacks are apportioned according to a quality-weighted policy:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
quality-weighted policy
\end_layout

\end_inset

 Applications tell the scheduler how much reduction they can tolerate to
 maintain a minimal acceptable quality.
 This quality threshold resembles probabilistic real-time task models such
 as QRMS.
\begin_inset CommandInset citation
LatexCommand cite
after "-119pt"
key "Hamann:QRMS"

\end_inset

 The scheduler combines this elasticity with the CPU load caused by the
 application to distribute the cutbacks.
 I will evaluate how a fully quality-fair policy compares to a fully resource-fa
ir policy.
\end_layout

\begin_layout Standard
The remaining CPU time assigned to each application is reported back to
 encourage adaptation.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
adaptation
\end_layout

\end_inset

 Developers can implement custom degradation strategies like load-shedding
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
load-shedding
\end_layout

\end_inset

 or imprecise computation
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
imprecise computation
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
after "-127pt"
key "Lin:Imprecise"

\end_inset

 that take an application-specific notion of quality into account.
 I published a quality-aware adaptation technique for video playback in
 the Journal of Visual Communication and Image Representation.
\begin_inset CommandInset citation
LatexCommand cite
after "-108pt"
key "Roitzsch:VideoQuality"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Global management and local adaptation
\end_layout

\end_inset

 to react to overload have been researched independently.
 Scheduler systems such as AQuoSA
\begin_inset CommandInset citation
LatexCommand cite
after "-106pt"
key "Palopoli:AQuoSA"

\end_inset

 or Cooperative Polling
\begin_inset CommandInset citation
LatexCommand cite
after "-54pt"
key "Krasic:CoopPoll"

\end_inset

 manage overload situations by distributing CPU capacity according to an
 inter-application fairness policy.
 AQuoSA applies resource fairness, while Cooperative Polling uses application
 knowledge to establish quality fairness.
 Intra-application adaptation has been investigated for tasks like video
 playback
\begin_inset CommandInset citation
LatexCommand cite
after "-49pt"
key "Wuest:QoS_Video"

\end_inset

 or network servers.
\begin_inset CommandInset citation
LatexCommand cite
after "-11pt"
key "Welsh:SEDA"

\end_inset


\end_layout

\begin_layout Standard
Priority-Progress Adaptation
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:PriorityProgress"

\end_inset

 by Krasic
\begin_inset space ~
\end_inset

et
\begin_inset space ~
\end_inset

al.
\begin_inset space \space{}
\end_inset

is the only work I am aware of that combines global overload mitigation
 with per-application adaptation.
 It does so by exposing a quality measure for each individual job, allowing
 the scheduler to globally order jobs by quality.
 The adaptation strategy to shed low-priority jobs on overload is therefore
 dictated by the scheduling method.
\end_layout

\begin_layout Standard
None of the presented research results exploit look-ahead to steer adaptation
 decisions.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I claim that look-ahead improves quality
\end_layout

\end_inset

 when mitigating overload.
 Because of its look-ahead characteristic, 
\noun on
Atlas
\noun default
 can detect overload before it occurs.
 Applications receive announcements of resource cutbacks ahead of time,
 including the time when the future deadline miss is anticipated and how
 much CPU capacity remains.
 The applications can then degrade any pending job before the critical deadline
 to satisfy the reduction in CPU time.
 The resulting choice allows trimming jobs with a favorable ratio between
 resource savings and quality impact.
 Additionally, each application can choose the most suitable adaptation
 technique independently.
\end_layout

\begin_layout Standard
I validate the claim by comparing overload mitigation with and without look-ahea
d.
 The flexibility of quality-weighted back-pressure is evaluated with implementat
ions of different degradation strategies.
 I explain and analyze these overload management and adaptation techniques
 in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Adaptivity"

\end_inset

.
 The scheduling infrastructure builds on the architecture developed for
 the timeliness experiments.
 The extensions to handle overload are implemented prototypically.
\end_layout

\begin_layout Section
Core Placement
\end_layout

\begin_layout Standard
I do not make a formal contribution in this area, but I want to convince
 the reader that the 
\noun on
Atlas
\noun default
 design is compatible with parallel execution and scheduling.
 Managing multiple cores adds another dimension to the scheduling problem:
 Not only does the scheduler order jobs along the time axis, but it also
 has to decide on a placement of the work onto cores.
 To this end, I sketch an extension toward core placement in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "5-chap:The-Road-Ahead"

\end_inset

.
\end_layout

\begin_layout Standard
Serving the timeliness goal, applications structure their execution into
 jobs that carry a timing requirement.
 To enable parallel processing, applications must also structure their work
 into independent pieces that can execute simultaneously.
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Balancing"

\end_inset

 To simplify development, I intend to decouple these two structures by allowing
 for parallelism within an individual job.
 Collette et al.
\begin_inset space \space{}
\end_inset

presented a similar task model before,
\begin_inset CommandInset citation
LatexCommand cite
key "Collette:JobParallelism"

\end_inset

 but without showing a programming environment to present it to developers.
 By building on top of an asynchronous lambda runtime, 
\noun on
Atlas
\noun default
 hands developers a powerful tool for parallel programming.
\end_layout

\begin_layout Section
Demo Application
\end_layout

\begin_layout Standard
The primary example workload in this thesis is video playback.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
video playback
\end_layout

\end_inset

 I chose video because I think it is representative for a number of real-time
 and throughput applications due to its combination interesting properties:
\begin_inset CommandInset citation
LatexCommand cite
after "-3\\baselineskip"
key "Baiceanu:VideoScheduling"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/1-Introduction/Decoding_Times_Histogram.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Decoding-Time-Histogram"

\end_inset

Histogram of Sintel-
\begin_inset Formula $4\mathrm{k}$
\end_inset

 Decoding Times
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Video playback is subject to deadlines that derive naturally from the frame
 rate
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
frame rate
\end_layout

\end_inset

 specification or the presentation timestamps in the video stream.
 Timing requirements are tight, because even small delays in the frame display
 will be visible to the user.
\begin_inset Foot
status open

\begin_layout Plain Layout
The telecine conversion of 24
\begin_inset space \thinspace{}
\end_inset

frames/s cinematic content to 30
\begin_inset space \thinspace{}
\end_inset

frames/s for NTSC television causes timing errors smaller than 20
\begin_inset space \thinspace{}
\end_inset

ms, which are visible to some viewers as jerky motion, especially in scenes
 with slow and steady camera movement.
 This error is called telecine judder (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Wikipedia: Telecine"
target "http://en.wikipedia.org/w/index.php?title=Telecine&oldid=475341309#Telecine_judder"

\end_inset


\end_layout

\end_inset

).
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Although decoding and displaying video frames are repetitive tasks, they
 do not adhere to the classical periodic task model where the deadline of
 one job coincides with the release of the next job.
 Due to buffering in the video player, the jobs’ scheduling windows between
 release and deadline can overlap.
\end_layout

\begin_layout Itemize
Video playback can be CPU intensive, especially with high resolutions and
 modern coding schemes.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Decoding-Time-Histogram"

\end_inset

 visualizes the single-thread decoding times of the 
\begin_inset Formula $4096\!\!\times\!\!1744\,\mathrm{pixel}$
\end_inset

 Sintel-
\begin_inset Formula $4\mathrm{k}$
\end_inset

 video
\begin_inset Foot
status open

\begin_layout Plain Layout
Such video dimensions may not be common today, but they are already used
 in cinematic applications.
 With high resolution displays coming to market, such videos may appear
 on desktops soon.
 The properties of this video are summarized in Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-tab:Film-Clips"

\end_inset

.
\end_layout

\end_inset

 on a 
\begin_inset Formula $2.4\,\mathrm{GHz}$
\end_inset

 Intel Core
\begin_inset space ~
\end_inset

i5.
 The high utilization is challenging for schedulers because it increases
 the likelihood that misdirection of CPU time leads to deadline misses.
 In the figure, the marked decoding time equivalent to 24
\begin_inset space ~
\end_inset

frames per second shows that a significant portion of the frames need more
 time for decoding than available between the display instants of two consecutiv
e frames.
\end_layout

\begin_layout Itemize
The CPU load is also highly dynamic.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-fig:Total-and-Zoomed"

\end_inset

 illustrates the short-term and long-term variations.
 The execution times of jobs are therefore difficult to predict and worst-case
 estimates would prohibitively over-allocate resources.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/1-Introduction/Decoding_Times_Timeline.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-fig:Total-and-Zoomed"

\end_inset

Total and Zoomed Views of Sintel-
\begin_inset Formula $4\mathrm{k}$
\end_inset

 Decoding Times
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
When overloaded, a video player conventionally adapts by dropping frames.
 However, more sophisticated degradation options like low-quality decoding
 fallbacks are also available and can improve quality per invested CPU cycles.
\end_layout

\begin_layout Standard
By showing that 
\noun on
Atlas
\noun default
 can support video playback in all these aspects I hope to convince the
 reader that it also handles other applications with a subset of the stated
 properties.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Typical-Properties"

\end_inset

 condenses typical behavior of selected desktop real-time tasks.
 Although video is the running example throughout this thesis, I complement
 it with other experiments to substantiate the evaluation.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Real-Time_Applications.svg

\end_inset


\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Typical-Properties"

\end_inset

Typical Properties of Selected Real-Time Applications
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Before we dive into the details
\end_layout

\end_inset

 of the timeliness and overload mitigation aspects of 
\noun on
Atlas, 
\noun default
the next chapter gives an overview of the emerging use of lambdas as the
 programming model for parallel desktop applications.
 The intimate vertical integration proposed by 
\noun on
Atlas
\noun default
 requires developer endorsement, so taking a closer look at programming
 innovation is valuable.
 Aligning my task model with a future-proof paradigm helps simplifying the
 use of 
\noun on
Atlas
\noun default
 for developers.
 Building 
\noun on
Atlas
\noun default
 around a parallel runtime keeps the door open for future extensions toward
 scheduling multiple cores.
\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "2-chap:Anatomy"

\end_inset

Anatomy of a Modern Desktop Application
\end_layout

\begin_layout Standard
For 
\noun on
Atlas
\noun default
, I envision a tight integration of application, runtime libraries and the
 CPU scheduler.
 The following pages explain the programming style of modern desktop application
s and motivate, how 
\noun on
Atlas
\noun default
 complements this style and what benefits the combination offers.
 Apart from guiding ideas framed in the context of real-world programming,
 I do not claim a distinct scientific contribution, but rather give an understan
ding of my target applications and explain basic terminology.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Three major paradigm shifts
\end_layout

\end_inset

 changed the way desktop software is written, with the latest of these transitio
ns still in progress.
 Historically, all applications started out single-threaded.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
single-threaded
\end_layout

\end_inset

 The traditional Unix design only knows about processes that implicitly
 host only a single activity.
\begin_inset CommandInset citation
LatexCommand cite
key "OpenGroup:SingleThread"

\end_inset

 There was no notion of multiple threads per address space.
 The resulting applications had no internal parallelism, which simplified
 programming and freed libraries from the worries of reentrant calls.
\end_layout

\begin_layout Standard
However, this model made the developers’ lives easier at the price of user
 irritation: When an application synchronously performs an input or output
 operation, for example reading a large file from disk or waiting for data
 from the network, its only thread is stuck in a blocking system call.
 Consequently, that thread is now unavailable for user interactions.
 The application appears dead for a while.
 The visual cue for such a mishap are redraw artifacts that tail other applicati
ons’ windows when the user drags them over the blocked application.
 They appear like in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-mar:Blocked-Window-Redraws"

\end_inset

 because the blocked application underneath no longer updates its window
 content and thus never clears the ghost copies of the window on top.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/Blocked_Redraw.svg
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-mar:Blocked-Window-Redraws"

\end_inset

Blocked Window Redraws
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Recognizing the importance of responsiveness,
\end_layout

\end_inset

 developers started to migrate long-running or blocking work off the main
 thread.
 Two mechanisms to support this change were asynchronous interfaces
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
asynchronous interface
\end_layout

\end_inset

 and the use of multiple threads.
 Both have their share of problems.
 Asynchronous interfaces split the logical code flow into two parts: The
 setup of context and arguments prepares the asynchronous invocation.
 Results come in as the asynchronous operation finishes.
 Often, a callback by the underlying framework executes this second part,
 which riddles the code with additional functions just for callback purposes.
 This callback-soup
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
callback-soup
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "SantAnna:ProblemEvents"

\end_inset

 complicates code understanding.
 Furthermore, because the callback executes in a separate function, the
 context of local variables is different from when the asynchronous processing
 started, a problem known as stack ripping.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
stack ripping
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Adya:StackRipping"

\end_inset


\end_layout

\begin_layout Standard
On the other hand, it is also difficult for programmers to orchestrate multiple
 threads correctly.
 Threads do not suffer from stack ripping, because they individually follow
 a single control flow with a dedicated stack.
 However, as the number of concurrent threads increases, their interleaving
 becomes increasingly complex to manage.
 Programmers unknowingly make wrong assumptions on the execution order of
 code in different threads.
\begin_inset CommandInset citation
LatexCommand cite
key "Lu:ConcurrencyBugs"

\end_inset

 As mainstream computers featured only a single CPU core, those assumptions
 used to hold.
 But when multiple CPU cores made their way into commodity machines, many
 multithreaded programs suddenly broke.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
A new approach to concurrency is needed.
\end_layout

\end_inset

 The current shift in parallel programming
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:LambdasEverywhere"

\end_inset

 leads us away from threads and closer to the ideas behind asynchronous
 invocation, but without inheriting their historical callback-soup and stack
 ripping downsides.
 Today, developers are discouraged from using threads directly, but should
 instead use new programming language constructs called lambdas, closures,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
closure
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Jarvi:Wording"

\end_inset

 or blocks that allow them to envelop a piece of code and dispatch it for
 asynchronous invocation.
\end_layout

\begin_layout Standard
The name for this paradigm changes with the chosen programming language
 and runtime environment.
 The term task-based programming
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
task-based programming
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:TaskBasedProgramming"

\end_inset

 has been coined, but also covers traditional callback-style models.
 Given that the term “task” is hopelessly overloaded already, I will avoid
 it and call the programming style 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
asynchronous lambdas
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
asynchronous lambda
\end_layout

\end_inset

 instead.
\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:Mouse-Processing-Styles"

\end_inset

 shows four pseudo-code versions
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

from the historical serial version to the modern lambda-style
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

of a user-initiated long-running computation, which updates the user interface
 when finished:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="22text%" special="@{}>{\centering}p{101pt}">
<column alignment="center" valignment="top" width="110pt">
<column alignment="center" valignment="top" width="102pt">
<column alignment="center" valignment="top" width="107pt">
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	result = longWork();
\end_layout

\begin_layout Plain Layout

	view.update(result);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	context = { view };
\end_layout

\begin_layout Plain Layout

	async(longWork,
\end_layout

\begin_layout Plain Layout

		cb, context);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

/* callback */
\end_layout

\begin_layout Plain Layout

void cb(result, context)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = context[0];
\end_layout

\begin_layout Plain Layout

	view.update(result);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	context = { view };
\end_layout

\begin_layout Plain Layout

	thread_create(work,
\end_layout

\begin_layout Plain Layout

		context);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

/* worker thread */
\end_layout

\begin_layout Plain Layout

void work(context)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = context[0];
\end_layout

\begin_layout Plain Layout

	result = longWork();
\end_layout

\begin_layout Plain Layout

	view.update(result);
\end_layout

\begin_layout Plain Layout

	thread_exit();
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	async(^{
\end_layout

\begin_layout Plain Layout

		result = longWork();
\end_layout

\begin_layout Plain Layout

		view.update(result);
\end_layout

\begin_layout Plain Layout

	});
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Serial Version
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Asynchronous with Callback
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Multiple Threads
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Asynchronous Lambda
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace 20pt
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:Mouse-Processing-Styles"

\end_inset

Pseudo-Code Examples for Long-Running Mouse Click Processing
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

Serial
\begin_inset space \space{}
\end_inset

Version is the shortest of the four and the easiest to read, because it
 describes the logical order of processing steps without much distraction
 by language clutter: First, the user interface element 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
view
\end_layout

\end_inset

 is fetched by evaluating where the user clicked.
 The long computation follows and its result updates the representation
 on screen.
\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

Callback
\begin_inset space \space{}
\end_inset

Version illustrates the stack ripping problem: What used to be a continuous
 control flow representing a single conceptual job is now broken across
 two functions.
 The programmer must explicitly deliver local state from the first function,
 if the second function needs access to it.
 After registering 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
longWork
\end_layout

\end_inset


\end_layout

\end_inset

 for execution, control returns to the runtime, which invokes the callback
 as the result is available.
 The callback function and the context act as a continuation
\begin_inset CommandInset citation
LatexCommand cite
key "Reynolds:Continuation"

\end_inset

 to complete the job.
\end_layout

\begin_layout Description
Multiple
\begin_inset space \space{}
\end_inset

Threads similarly require manual passing of contextual state between the
 invoker and the worker thread.
 Processing is again split across two functions.
 A new problem introduced in this version is the updating of the view from
 a background thread.
 Many user interface frameworks limit updates to the main thread to avoid
 dealing with concurrent invocation.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:ThreadSafety,Qt:ThreadingBasics"

\end_inset

 Such a limitation further complicates the use of multiple threads.
\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

Lambda
\begin_inset space \space{}
\end_inset

Version on the very right invokes a block of code asynchronously, but without
 using a callback or manually managing separate threads.
 In fact, using lambdas, the code regains a lot of the simplicity of the
 serial version, which is the main reason why this programming style is
 so attractive.
 It may appear as syntactic sugar in this toy example, but such assistance
 encourages new paradigms for concurrent and responsive program design.
\begin_inset CommandInset citation
LatexCommand cite
key "Cowin:ParadigmShift"

\end_inset

 The pseudo-code lambda in the figure uses the block syntax from Apple’s
 Grand
\begin_inset space ~
\end_inset

Central
\begin_inset space ~
\end_inset

Dispatch (GCD) system,
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatchIntro"

\end_inset

 where a caret
\begin_inset space ~
\end_inset


\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
^
\end_layout

\end_inset

 marks the lambda code.
 The notation is not simplified, the example shows all typing the programmer
 has to do.
 The 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
view
\end_layout

\end_inset

 variable, which was assigned outside the lambda, is transparently available
 inside the lambda without any manual state transfer.
 If libraries impose concurrency limitations, GCD allows for seamless dispatchin
g of work back to the main thread.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:MainThread"

\end_inset


\end_layout

\begin_layout Standard
Threads are still used behind the scenes to implement the asynchronous execution
 of lambdas, but the programmer does not need to bother.
 This avoids explicit thread management which often leads to an inflexible
 hard-coded assignment of work to threads that may not be optimal on the
 end-user’s machine.
 Instead, the runtime environment can manage the number of active threads,
 taking into account the number of cores and the current load on the machine.
\end_layout

\begin_layout Section
Lambdas Far and Wide
\end_layout

\begin_layout Standard
Asynchronous lambdas combine a programming pattern based on asynchronous
 invocation and a lambda language feature to deliver a unique combination
 of properties.
\begin_inset CommandInset citation
LatexCommand cite
key "Voelp:ElasticManycores"

\end_inset


\end_layout

\begin_layout Description
Asynchronous
\begin_inset space \space{}
\end_inset

invocation originates from event-based programming.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
event-based programming
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Krohn:Events"

\end_inset

 High-throughput network servers experience scalability bottlenecks when
 assigning each incoming request to a dedicated thread.
 Performance improves when organizing the server such that queues collect
 pieces of work and execute them asynchronously.
\begin_inset CommandInset citation
LatexCommand cite
key "Welsh:SEDA"

\end_inset

 Queuing work instead of explicitly spawning a thread allows the runtime
 layer to control the number of threads, employing strategies like transparent
 thread pooling.
\end_layout

\begin_layout Description
Lambdas automatically transfer state by capturing variables from the enclosing
 scope.
 This relieves the programmer from manually collecting contextual data.
 Lambdas also preserve the logical locality of the code, because they appear
 inline and not as separate functions.
 The code looks like a serial flow of instructions and is easier to read
 than code written for threaded or callback parallelism.
\end_layout

\begin_layout Standard
The compiler and runtime combine the lambda’s code block and the necessary
 state to an object that can be passed as an argument to functions, making
 this language feature a natural fit for the pattern of asynchronous invocation.
 Herb Sutter believes lambdas are “The
\begin_inset space ~
\end_inset

Holy
\begin_inset space ~
\end_inset

Grail” for developing a library of parallel programming patterns.
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:C++AMP_Keynote"

\end_inset

 Early academic research pioneered many concepts of parallel language runtimes
\begin_inset CommandInset citation
LatexCommand cite
key "Murer:pSather"

\end_inset

 or work queue management strategies.
\begin_inset CommandInset citation
LatexCommand cite
key "Blumofe:Cilk"

\end_inset

 Now, these systems appear as mature industrial solutions.
\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Existing implementations
\end_layout

\end_inset

 of asynchronous lambdas cover all or a significant subset of the four aspects
 of the programming paradigm:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

logical coherence of the code,
\end_layout

\begin_layout Itemize
automatic state capturing,
\end_layout

\begin_layout Itemize
asynchronous execution, and
\end_layout

\begin_layout Itemize
automatic thread management.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
To show that this concept is now gaining traction, the following Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-tab:Asynchronous-Lambdas"

\end_inset

 presents a selection of popular complete and partial implementations, including
 their name for the unit of code execution, for which the different solutions
 are unfortunately not in agreement.
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\begin_inset Tabular
<lyxtabular version="3" rows="11" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="0pt">
<column alignment="left" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Implementation
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Code Unit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Logical Coherence
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
State Capture
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Async.
 Execution
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thread Management
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Apple Grand Central Dispatch
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
grand central dispatch
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Block
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Microsoft Parallel Patterns Library
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
parallel patterns library
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Lambda
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
lambda
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google Go
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
go
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Goroutine
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
goroutine
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathrm{X10}$
\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $\mathrm{X10}$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activity
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
activity
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{
\end_layout

\end_inset

++
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset Formula $11$
\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{
\end_layout

\end_inset

++
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset Formula $11$
\end_inset


\end_layout

\end_inset

 (no additional libraries)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Lambda
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel Threading Building Blocks
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
threading building blocks
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Task
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OpenMP
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
OpenMP
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iteration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Galois
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
galois
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iteration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Qt
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Qt
\end_layout

\end_inset

 Signals and Slots
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Event
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CoreManager
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
CoreManager
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Task
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-tab:Asynchronous-Lambdas"

\end_inset

Complete or Partial Implementations of Asynchronous Lambdas
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Two complete solutions are available from commercial operating system vendors:
 Microsoft offers the Parallel Patterns Library,
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:C++PPL"

\end_inset

 a library on top of standard C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{
\end_layout

\end_inset

++
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset space ~
\end_inset

lambdas, and Apple is pushing for Grand Central Dispatch,
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatchIntro"

\end_inset

 a combined C
\begin_inset space ~
\end_inset

language extension and work queue library.
 Both offer fully featured lambdas that can be dispatched for asynchronous
 execution with transparent thread management by the underlying framework.
\end_layout

\begin_layout Standard
Goroutines in Google’s Go language
\begin_inset CommandInset citation
LatexCommand cite
key "Google_Go"

\end_inset

 are functions that execute asynchronously, with the Go runtime managing
 threads automatically.
 Using anonymous inline functions, developers can write Goroutine code in
 place, without branching off to a separate function.
 Like C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{
\end_layout

\end_inset

++
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset space ~
\end_inset

lambdas, Go closures can access variables from the surrounding context and
 capture them by value or by reference.
\end_layout

\begin_layout Standard
IBM developed 
\begin_inset Formula $\mathrm{X10}$
\end_inset

, a new language for parallel programming,
\begin_inset CommandInset citation
LatexCommand cite
key "Charles:X10"

\end_inset

 which also offers a full implementation of asynchronous lambdas.
 In addition, 
\begin_inset Formula $\mathrm{X10}$
\end_inset

 also introduces a 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
\noindent
places
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
place
\end_layout

\end_inset

 concept to represent locality in a partitioned address space.
 Places host activities, which is the 
\begin_inset Formula $\mathrm{X10}$
\end_inset

 name for lambdas.
\end_layout

\begin_layout Standard
C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{
\end_layout

\end_inset

++
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset Formula $11$
\end_inset

 offers lambdas as part of the language,
\begin_inset CommandInset citation
LatexCommand cite
key "C++11"

\end_inset

 but thread management for parallel execution is incomplete
\begin_inset CommandInset citation
LatexCommand cite
key "Milewski:C++Async"

\end_inset

 and needs to be supplied by an additional library like Intel’s Threading
 Building Blocks.
\begin_inset CommandInset citation
LatexCommand cite
key "Intel_TBB"

\end_inset

 Its primitives however are tailored for parallelizing iterative and pipelined
 work, not for general asynchronous execution.
\end_layout

\begin_layout Standard
OpenMP
\begin_inset CommandInset citation
LatexCommand cite
key "OpenMP"

\end_inset

 employs a model of strict fork-join-concurrency.
 The programmer marks intermittent parallel sections in otherwise serial
 code.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "2-fig:OpenMP-Fork-Join"

\end_inset

 shows how the master thread fans out into a number of worker threads to
 execute parallel work.
 The focus is on parallelizing loops, with an automatic assignment of iterations
 to threads.
\end_layout

\begin_layout Standard
Like OpenMP, the Galois research runtime parallelizes iterative work.
 However, it extends the traditional parallel loop to a dynamic set iterator,
 where executing one iteration can add new iterations to a work set.
\begin_inset CommandInset citation
LatexCommand cite
key "Kulkarni:Galois"

\end_inset

 While parallel loops suffice to implement array processing or dense matrix
 operations, the generalization to set iterators helps with irregular algorithms
 like traversing graphs or other pointer-based data structures.
 For the latter class of algorithms, parallelism is data-dependent and builds
 up at runtime.
 The runtime is therefore unable to split the iteration space among threads
 at the beginning of the iteration, but must dynamically assign work while
 the iterator progresses.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:Galois-Set-Iterator"

\end_inset

 illustrates the resulting irregular parallelism.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/Fork_Join.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:OpenMP-Fork-Join"

\end_inset

OpenMP Fork-Join-Model
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/Set_Iterator.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:Galois-Set-Iterator"

\end_inset

Galois Set Iterator
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Among the application frameworks popular on Linux, the Qt library provides
 a mechanism called Signals and Slots to flexibly dispatch function invocation.
 This mechanism works across threads
\begin_inset CommandInset citation
LatexCommand cite
key "Qt:SignalsSlotsThreads"

\end_inset

 and allows for asynchronous execution of work in the background.
 Automatic thread management is available by way of a thread pool facility.
\end_layout

\begin_layout Standard
Even hardware is trending towards asynchronous programming models, forecasting
 the relevance for future heterogeneous manycore chips.
\begin_inset CommandInset citation
LatexCommand cite
key "Knauerhase:ExtremeParallelism"

\end_inset

 CoreManager
\begin_inset CommandInset citation
LatexCommand cite
key "Arnold:CoreManager"

\end_inset

 is a scheduler that dispatches tasks to processing elements on a heterogeneous
 multiprocessor.
 The Tomahawk
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
tomahawk
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Limberg:Tomahawk"

\end_inset

 research chip is based on a hardware implementation of the CoreManager
 concept.
 Allocation of processing elements is transparent to the programmer and
 the main application processor continues executing while a task is running
 asynchronously on a processing element.
 Although input and output data of a task must be marked explicitly, the
 memory content is automatically transferred by a memory controller.
 Similar hardware-implemented scheduling like Nvidia’s Gigathread engine
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
gigathread engine
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "NVIDIA_Fermi"

\end_inset

 operates in today’s GPUs.
\end_layout

\begin_layout Section
The Lambda Style
\end_layout

\begin_layout Standard
Throughout this thesis, I use the Grand Central Dispatch
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
grand central dispatch
\end_layout

\end_inset

 (GCD) implementation of asynchronous lambdas to illustrate examples and
 to demonstrate the 
\noun on
Atlas
\noun default
 scheduling concepts.
 However, I believe my work does not rely on specifics of GCD and generalizes
 to any complete asynchronous lambda system.
 The two reasons for siding with GCD are:
\end_layout

\begin_layout Standard
First, GCD is a mature and fully-featured implementation of asynchronous
 lambdas that enjoys the backing of a major company.
 It is actively used by developers writing applications for Apple’s OS
\begin_inset space ~
\end_inset

X and iOS.
 GCD is becoming an essential technology on these platforms, with older
 frameworks being rewritten to use it and newer interfaces relying on it
 exclusively.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:AVFoundation"

\end_inset


\end_layout

\begin_layout Standard
Second, unlike Microsoft’s Parallel Patterns Library or Intel’s Threading
 Building Blocks, GCD does not require C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{
\end_layout

\end_inset

++
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 and is therefore compatible with existing C-code.
 GCD consists of a C language extension called blocks
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset

 and the libdispatch
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
libdispatch
\end_layout

\end_inset

 runtime library.
 The clang
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
clang
\end_layout

\end_inset

 compiler
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "clang: a C language family frontend for LLVM"
target "http://clang.llvm.org/"

\end_inset

.
\end_layout

\end_inset

 The LLVM Compiler Infrastructure.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
href{http://clang.llvm.org/}{
\backslash
nolinkurl{clang.llvm.org}}
\end_layout

\end_inset


\end_layout

\end_inset

 implements the blocks extension and libdispatch is available from Apple.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "libdispatch"
target "http://libdispatch.macosforge.org/"

\end_inset

.
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
href{http://libdispatch.macosforge.org/}{
\backslash
nolinkurl{libdispatch.macosforge.org}}
\end_layout

\end_inset


\end_layout

\end_inset

 Both are open-source licensed and have been ported to Linux,
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "OpenGCD: Portable implementation of Grand Central Dispatch"
target "http://sourceforge.net/projects/opengcd/"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 turning GCD into a suitable research platform with complete source code
 available.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The two basic primitives of GCD
\end_layout

\end_inset

 are blocks and dispatch queues.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
dispatch queue
\end_layout

\end_inset

 Blocks implement the lambda part of asynchronous lambdas.
 They turn a piece of executable code into a language object, but other
 than a function they are written inline and automatically capture surrounding
 variables as needed within the block.
 The example in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:GCD-Blocks-Capture"

\end_inset

 demonstrates these properties:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
lstparams "numbers=left"
inline false
status open

\begin_layout Plain Layout

#include <stdio.h>
\end_layout

\begin_layout Plain Layout

int main(void) {
\end_layout

\begin_layout Plain Layout

	int multiplier = 7;
\end_layout

\begin_layout Plain Layout

	void (^multiplication)() = ^{
\end_layout

\begin_layout Plain Layout

		int result = 6 * multiplier;
\end_layout

\begin_layout Plain Layout

		printf("%d", result);
\end_layout

\begin_layout Plain Layout

	};
\end_layout

\begin_layout Plain Layout

	multiplier++;
\end_layout

\begin_layout Plain Layout

	multiplication();
\end_layout

\begin_layout Plain Layout

	// prints 42
\end_layout

\begin_layout Plain Layout

	return 0;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:GCD-Blocks-Capture"

\end_inset

GCD Blocks Capture State
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
In lines four to seven, a block is defined
\begin_inset Foot
status open

\begin_layout Plain Layout
Refer to Apple’s documentation 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Blocks Programming Topics"
target "https://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/Blocks/Blocks.pdf"

\end_inset


\end_layout

\end_inset

 for an in-depth explanation of the blocks syntax.
\end_layout

\end_inset

 and assigned to the local variable 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
multiplication
\end_layout

\end_inset


\end_layout

\end_inset

.
 The block multiplies a variable by six and prints the result.
 The 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
multiplier
\end_layout

\end_inset


\end_layout

\end_inset

 variable is not part of the block’s local scope, but is imported from the
 surrounding scope.
 The value of this variable is captured at definition time of the block.
 When the block is finally executed in line nine, it still uses that captured
 value, even though the multiplier has been changed in line eight.
 The result printed in line nine is therefore 42.
\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:Anonymous-GCD-Block"

\end_inset

 shows that blocks can be passed to functions as arguments and they can
 be defined anonymously right in the function call, omitting the assignment
 to a local block variable:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
lstparams "numbers=left"
inline false
status open

\begin_layout Plain Layout

#include <stdio.h>
\end_layout

\begin_layout Plain Layout

static void run(void (^block)()) {
\end_layout

\begin_layout Plain Layout

	block();
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

int main(void) {
\end_layout

\begin_layout Plain Layout

	int multiplier = 7;
\end_layout

\begin_layout Plain Layout

	run(^{
\end_layout

\begin_layout Plain Layout

		int result = 6 * multiplier;
\end_layout

\begin_layout Plain Layout

		printf("%d", result);
\end_layout

\begin_layout Plain Layout

	});
\end_layout

\begin_layout Plain Layout

	// prints 42
\end_layout

\begin_layout Plain Layout

	return 0;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:Anonymous-GCD-Block"

\end_inset

Anonymous GCD Block Passed to Function
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Again, when the block is defined in lines seven to ten, it captures the
 variable 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
multiplier
\end_layout

\end_inset


\end_layout

\end_inset

 from the surrounding scope.
 The block is passed as an argument to the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
run()
\end_layout

\end_inset


\end_layout

\end_inset

 function, which invokes it in line three, where it prints 42 as the result.
 In this example, the block is executed immediately, but 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
run()
\end_layout

\end_inset


\end_layout

\end_inset

 is also free to store the block for later invocation, in which case the
 original 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
multiplier
\end_layout

\end_inset


\end_layout

\end_inset

 variable may already be destroyed, leaving only the captured copy in the
 block.
\end_layout

\begin_layout Standard
Here, libdispatch enters the stage.
 It implements dispatch queues to which a programmer can submit asynchronous
 work items in the form of blocks.
 GCD conveniently provides synchronization primitives as a natural part
 of its programming idioms.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:SerialQueue"

\end_inset

 Dispatch queues come in two flavors: serial and parallel queues.
 Blocks submitted to a serial queue execute one after the other, never running
 two of them at the same time.
 This guarantee not only implies protection for critical sections, it also
 allows developers to reason about the order of block execution.
 Blocks on a parallel queue execute concurrently and may complete in any
 order.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:Asynchronous-Execution-libdispatch"

\end_inset

 restates our running example using libdispatch functions:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
lstparams "numbers=left"
inline false
status open

\begin_layout Plain Layout

#include <dispatch/dispatch.h>
\end_layout

\begin_layout Plain Layout

#include <stdio.h>
\end_layout

\begin_layout Plain Layout

int main(void) {
\end_layout

\begin_layout Plain Layout

	dispatch_queue_t queue = dispatch_get_global_queue(0, 0);
\end_layout

\begin_layout Plain Layout

	int multiplier = 7;
\end_layout

\begin_layout Plain Layout

	dispatch_async(queue, ^{
\end_layout

\begin_layout Plain Layout

		int result = 6 * multiplier;
\end_layout

\begin_layout Plain Layout

		printf("%d", result);
\end_layout

\begin_layout Plain Layout

	});
\end_layout

\begin_layout Plain Layout

	// prints 42
\end_layout

\begin_layout Plain Layout

	dispatch_barrier_sync(queue, ^{});
\end_layout

\begin_layout Plain Layout

	return 0;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:Asynchronous-Execution-libdispatch"

\end_inset

Asynchronous Execution with libdispatch
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Line four obtains a reference to the default global dispatch queue.
 The block is passed in line six to a libdispatch function, which enqueues
 it for asynchronous execution.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-mar:GCD-Asynchronous-Dispatch"

\end_inset

 pictures the libdispatch runtime automatically spawning a worker thread
 behind the scenes to process the block from the queue.
 Line eleven waits for background work to finish before the program exits.
 Of course the main thread could perform other duties before waiting, resulting
 in two-way parallel execution.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/GCD_Async.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-mar:GCD-Asynchronous-Dispatch"

\end_inset

GCD Asynchronous Dispatch
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
GCD can parallelize loops
\end_layout

\end_inset

 by dispatching all iterations at once with the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_apply()
\end_layout

\end_inset


\end_layout

\end_inset

 convenience function.
 The dispatch queue will suddenly contain a number of blocks, so the runtime
 library starts multiple threads to process iterations concurrently, leading
 to OpenMP-style fork-join parallelism.
\end_layout

\begin_layout Standard
But GCD also allows dispatching additional blocks at any time during the
 iteration, enabling dynamic parallelism like the Galois set iterator.
 In fact, while the set iterator is restricted to adding more runs of the
 same iteration, GCD can also dispatch different blocks of code.
 It therefore generalizes the Galois single-program multiple-data concept
 to a multiple-program multiple-data system.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The programming paradigm
\end_layout

\end_inset

 of asynchronous lambdas relieves the developer from explicitly managing
 parallelism with threads.
 Instead, the code expresses latent parallelism: The developer states explicitly
 which code pieces can potentially run in parallel.
 The runtime library later decides dynamically, which pieces do run concurrently.
 It translates the latent parallelism to actual parallelism.
\end_layout

\begin_layout Section
An Asynchronous World
\end_layout

\begin_layout Standard
If developers follow the rules and ensure responsiveness by keeping all
 non-trivial work off the main thread, the bulk of execution will be funneled
 through dispatch queues.
 Especially for autonomous computing tasks, where the user triggers a long-runni
ng operation with a single mouse click, the queues can fill with substantial
 amounts of work.
 At the time of the click, no further input from the user or the environment
 influences the result of the computation, so only the application’s code
 and data determine the following execution.
 Therefore, when the user triggers the operation, the application can inspect
 its internal state and expose its knowledge about the upcoming computation
 to the CPU scheduler ahead of time.
\end_layout

\begin_layout Standard
Media playback is an example for such an operation that is one-shot triggered,
 but then runs autonomously for an extended period of time.
 As the user clicks play and sits back, all the following calculations are
 predetermined and known to the application.
 This also holds true for interactive applications such as games, albeit
 with a much smaller time horizon.
 In an application, which primarily reacts to user input with short latency,
 the dispatch queues will only contain short bursts of work.
 The application can still foresee and report to the scheduler what it is
 going to do, but the time horizon shortens compared to media playback use
 cases.
\end_layout

\begin_layout Standard
In the next chapter 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand nameref
reference "3-chap:Real-Time"

\end_inset

,
\end_layout

\end_inset

 I demonstrate the benefits of reporting future application behavior to
 the scheduler early: it can anticipate deadline misses before they occur.
 I also evaluate the different time horizons of applications.
 Here, I want to emphasize that such ahead-of-time knowledge and introspection
 capabilities are a natural consequence of the programming style of modern
 applications:
\end_layout

\begin_layout Full Width
\begin_inset VSpace defskip
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
Blocks expose static program structure to the compiler to enable automatic
 state capturing.
 Dispatch queues expose dynamic program structure to the runtime library
 to enable automatic thread management.
 Asynchronous execution by definition announces future computation before
 it begins.
 As shown above, the asynchronous lambda style is gaining traction.
 Thus, modern applications increasingly have knowledge about their future
 execution behavior at hand.
 My goal is to expose future program behavior to the CPU scheduler ahead
 of time to improve global management of timeliness and overload.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Blocks package execution
\end_layout

\end_inset

 into discrete portions, introducing boundaries the runtime library can
 recognize and act upon.
 Individual block instances can be amended with metadata, either manually
 by the developer or automatically by the system through machine learning.
 As I show in the next chapter, metadata can convey timing requirements
 in the form of deadlines and resource requirements in the form of execution
 times.
 When queueing such augmented blocks and exposing the resulting structure,
 applications form a precedence graph of real-time jobs.
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RealTimeSystems"

\end_inset


\end_layout

\begin_layout Standard
Aggregating multiple blocks helps, when a single block is too small to warrant
 the overhead of metadata handling.
 GCD already features dispatch groups, which collect multiple blocks and
 track their joint completion.
 To delineate these notions, I use the following terminology:
\end_layout

\begin_layout Description
Block
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset


\begin_inset space \space{}
\end_inset

or
\begin_inset space \space{}
\end_inset

lambda
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
lambda
\end_layout

\end_inset

 designates a combined portion of code and captured variable state that
 is submitted to a dispatch queue.
 Block is the name for the GCD implementation, but I use the term lambda
 synonymously.
 The runtime library manages blocks within the application.
 By executing independent blocks on different threads, blocks become the
 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
unit of parallelism.
\end_layout

\end_inset


\end_layout

\begin_layout Description
Job
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
job
\end_layout

\end_inset

 denotes a work item described by metadata like a deadline or an execution
 time requirement.
 The application exposes jobs and the scheduler manages them globally.
 The term is similar in meaning to the one from the real-time field, although
 the latter is typically defined in the context of a task model.
 A formal definition of my task model follows in the next chapter.
 Jobs constitute the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
unit of scheduling.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Both concepts overlap considerably, especially if one job from the scheduler’s
 perspective is implemented by one block in the application.
 But as soon as jobs are aggregates of a group of blocks, it is useful to
 have two separate terms.
 Note that threads
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

although an important implementation detail
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

are not part of the essential vocabulary, because developers do not need
 to reason about them.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
To the best of my knowledge,
\end_layout

\end_inset

 the combination and mutual benefits of asynchronous lambdas and real-time
 jobs have not been explored yet.
 A different example of connecting real-time and programming concepts was
 the Comquad
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
comquad
\end_layout

\end_inset

 project, which introduced timing contracts
\begin_inset CommandInset citation
LatexCommand cite
key "Haertig:COMQUAD"

\end_inset

 into component-based development.
\end_layout

\begin_layout Standard
I propose to exploit the code’s block structure to attach real-time metadata
 and expose jobs to the scheduler for global management.
 As illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-mar:Cooperation-Blocks-Jobs"

\end_inset

, the scheduler allocates CPU time for each job.
 The application fills those reservations with life by running the associated
 code blocks.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\begin_inset Graphics
	filename Figures/2-Anatomy/Cooperation_Blocks_Jobs.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-mar:Cooperation-Blocks-Jobs"

\end_inset

Cooperation Between Blocks and Jobs
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Inside a Video Player
\end_layout

\begin_layout Standard
Studying FFplay
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

a simple yet fully featured video player
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

allows us to substantiate the abstract insights discussed above.
 FFplay
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
FFplay
\end_layout

\end_inset

 is a command line video player, which is part of the FFmpeg
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
FFmpeg
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "FFmpeg"
target "http://ffmpeg.org"

\end_inset


\end_layout

\end_inset

 is a media processing library with comprehensive support for decoding all
 major video formats.
\end_layout

\end_inset

 project and based on SDL
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Simple DirectMedia Layer"
target "http://www.libsdl.org"

\end_inset


\end_layout

\end_inset

 is a library for portable access to audio, video and input devices.
\end_layout

\end_inset

 for graphical output and sound.
 I use version 
\begin_inset Formula $0.11.1$
\end_inset

 of FFmpeg,
\begin_inset Foot
status open

\begin_layout Plain Layout
Git commit
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "39fe8033"
target "http://git.videolan.org/?p=ffmpeg.git;a=tree;h=6e8813a1c43a17b07e85af6872e86234d0167bcb;hb=39fe8033bbf94cac7935d749849fdf67ba8fc16a"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 released in June
\begin_inset space ~
\end_inset

2012.
\end_layout

\begin_layout Standard
I conduct all experiments on a 64-bit Ubuntu
\begin_inset space ~
\end_inset

Linux 
\begin_inset Formula $12.04.2$
\end_inset


\begin_inset space ~
\end_inset

LTS, running on a 2010
\begin_inset space ~
\end_inset

15''
\begin_inset space ~
\end_inset

MacBook
\begin_inset space ~
\end_inset

Pro
\begin_inset Foot
status open

\begin_layout Plain Layout
Model identifier: MacBookPro6,2
\end_layout

\end_inset

 equipped with a 
\begin_inset Formula $2.4\,\mathrm{GHz}$
\end_inset

 Intel Core
\begin_inset space ~
\end_inset

i5-
\begin_inset Formula $520\mathrm{M}$
\end_inset

 Arrandale and 
\begin_inset Formula $4\,\mathrm{GiB}$
\end_inset

 of 
\begin_inset Formula $1066\,\mathrm{MHz}$
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\mathrm{DDR}3$
\end_inset


\begin_inset space ~
\end_inset

SDRAM.
 This configuration is representative for a mid-range consumer notebook
 at the time of this writing.
 Reproducing the experiments is fully automated and all source code and
 scripts are available in a public source code repository.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://os.inf.tu-dresden.de/~mroi/git/thesis/lab
\end_layout

\end_inset


\begin_inset VSpace 1cm
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hfill
\backslash
begin{pspicture}(0.45in,0.45in)
\backslash
psbarcode{https://os.inf.tu-dresden.de/
\backslash
%7Emroi/git/thesis/lab}{width=0.5 height=0.5}{qrcode}
\backslash
end{pspicture}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
FFplay is designed
\end_layout

\end_inset

 according to the traditional multithreading paradigm.
 At the beginning of playback,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
video playback
\end_layout

\end_inset

 it initializes a pipeline with three stages.
 A dedicated thread services each stage in a loop, as illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:FFplay-Multithreaded-Player"

\end_inset

.
 This architecture offloads the bulk of work to background threads, keeping
 the main thread responsive.
 Thus, it typifies a well-behaving graphical user interface application
 that performs data processing.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/FFplay_Design.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:FFplay-Multithreaded-Player"

\end_inset

FFplay Multithreaded Video Player Design
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

input
\begin_inset space \space{}
\end_inset

stage
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
input stage
\end_layout

\end_inset

 reads the video file from disk, parses the stream and splits it into packets
 of compressed data, with one packet holding the data for one resulting
 frame of video.
 This stage is input-bound and requires little CPU time.
 When the input stage becomes delayed, buffering within the player helps
 the following stages to continue working.
\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

decoder
\begin_inset space \space{}
\end_inset

stage
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
decoder stage
\end_layout

\end_inset

 receives individual packets of compressed video data and decodes them to
 obtain the finished frames.
 This process is compute-intensive, especially for high resolution video
 streams.
 The computing time needed to decode one frame is dynamic and changes as
 the video progresses.
 A buffer to the final stage can compensate timing fluctuations, but when
 the system experiences high competing CPU load, catching up after a delay
 is difficult.
\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

output
\begin_inset space \space{}
\end_inset

stage
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
output stage
\end_layout

\end_inset

 triggers the display of decoded video frames at their proper presentation
 time.
 This stage interacts with physical reality, because it determines when
 the user sees which frame.
 Therefore, this stage has strict timing requirements, but does not generate
 much CPU load.
 To ensure portability, the SDL documentation discourages calling graphics
 functions from background threads.
\begin_inset CommandInset citation
LatexCommand cite
key "SDL:MultipleThreads"

\end_inset

 Therefore, execution of the output stage alternates between the dedicated
 per-stage thread and the main thread.
\end_layout

\begin_layout Standard
Two more threads deal with audio and subtitle decoding, but are ignored
 here because they do not add interesting new properties to the mix.
 The main thread runs the event handling loop responsible for reacting to
 user input and executing display updates.
 It forms the backbone of the application by giving the user control of
 the player and coordinating the pipeline to achieve the desired result.
 To always remain responsive, this thread never executes a long-running
 or blocking operation.
\end_layout

\begin_layout Standard
Data travels through queues, which help even out the varying execution time
 of decoding video frames and mitigate temporary interruptions in the threads’
 operation.
 The queues connect the stages and allow the threads to synchronize: The
 input stage acquires a free slot on the video queue and fills it with data
 it has read from the video file.
 The decoder stage consumes one packet from the video queue and fills an
 empty slot on the picture queue with a finished frame.
 The output stage removes a frame from the picture queue and waits until
 it needs to be displayed.
 Unlike the other stages, the output stage therefore self-suspends
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
self-suspension
\end_layout

\end_inset

 by sleeping.
 When the output stage is momentarily suspended and the queues fill up,
 the preceding stages will eventually block, when they do not find a free
 slot on their outgoing queues.
 The queues represent a dependency between the threads.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/Terminology.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-mar:Job-Terminology"

\end_inset

Terminology for the Course of Events Concerning a Job
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Each iteration of a stage represents a real-time job,
\end_layout

\end_inset

 for which we can calculate property measures.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-mar:Job-Terminology"

\end_inset

 illustrates the necessary terminology.
 An individual iteration of a stage starts by consuming an item from its
 incoming queue.
 This item originated from the previous stage, which inserted it into the
 queue earlier.
 We call this insertion point the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
submission time
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
submission time
\end_layout

\end_inset

 for this job.
 When the item has made it to the front of the queue, the beginning of the
 iteration marks the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
release time
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
release time
\end_layout

\end_inset

 of the job.
 When the iteration ends, the job 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
completes.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Classical real-time terminology
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RealTimeSystems"

\end_inset

 uses a slightly different meaning for the term release time.
 Here, it is a specific point in the flow of the running code.
 A job is released when execution reaches the next iteration.
 In the real-time sense, the release time is part of a formal task model
 and is a constraint or an assumption for the scheduler to consider.
\end_layout

\begin_layout Standard
Additionally, real-time literature often uses the terms arrival time
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
arrival time
\end_layout

\end_inset

 and release time synonymously.
 But originating from queueing theory, arrival time intuitively refers to
 the submission instant, because at this time the job arrives at the queue.
 To prevent confusion, I avoid the term arrival time altogether.
\end_layout

\begin_layout Standard
While the submission, release and completion times are names for important
 points in the actual code execution, a job’s 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset

 is a non-functional target property: The job should complete before its
 deadline.
 For FFplay, each data item ultimately results in a frame.
 The time when that frame must be ready for display marks the deadline of
 that data item.
\end_layout

\begin_layout Standard
After defining important events during the life of a job, we also assign
 names to interesting time intervals: The time between submission and release
 of a job is the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
look-ahead time,
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
look-ahead time
\end_layout

\end_inset

 the time between release and completion is the job’s 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
makespan.
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
makespan
\end_layout

\end_inset

 Preemption or blocking may occur during the makespan, resulting in an 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
execution time
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
execution time
\end_layout

\end_inset

 less than the makespan.
 The interval between release and deadline is the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
scheduling window
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
scheduling window
\end_layout

\end_inset

 and the difference between the scheduling window and the execution time
 is 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
slack time.
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
slack time
\end_layout

\end_inset

 Except for the look-ahead term, these definitions are in line with common
 real-time terminology.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
To confirm the different characteristics
\end_layout

\end_inset

 of the three threads involved in executing the stages, Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-tab:Characteristics-of-FFplay"

\end_inset

 contains an evaluation of FFplay showing the Hunger Games video
\begin_inset Foot
status open

\begin_layout Plain Layout
This video is a representative high definition movie trailer.
 For detailed video properties, see Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-tab:Test-Clips"

\end_inset

.
\end_layout

\end_inset

 with a resolution of 
\begin_inset Formula $1920\!\!\times\!\!816\,\mathrm{pixels}$
\end_inset

.
 The CPU load column shows the share of CPU time spent in that stage.
 Because FFplay idles for a portion of time, the loads do not sum up to
 
\begin_inset Formula $100\%$
\end_inset

.
 The table continues with the median execution time and its interquartile
 range (IQR)
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

the difference between the 
\begin_inset Formula $25\%$
\end_inset

 and the 
\begin_inset Formula $75\%$
\end_inset

 quantiles.
 These values help judge the weight and variability of the stages, while
 the average slack time indicates how time critical the stage is.
 A lower value signifies more critical work, because any delay greater than
 the slack time will lead to a deadline miss.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset CommandInset include
LatexCommand input
filename "Data/2-Anatomy/Characteristics.lyx"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-tab:Characteristics-of-FFplay"

\end_inset

Characteristics of FFplay Stages
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
The results emphasize the different properties of the three stages: Input
 exhibits low execution times because it merely shuttles data from disk
 to the queue.
 Decoding is compute-intensive and the execution time is varying considerably,
 as indicated by the interquartile range.
 The decode and output stages experience low slack times, illustrating their
 tight timing requirements.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
These differences in behavior
\end_layout

\end_inset

 and the interdependencies between the stages are only incidentally exposed
 to the CPU scheduler.
 The preceding measurement of thread characteristics require modifications
 to FFplay.
 Intimate knowledge about its inner workings guided the placement of custom
 taps in the player, which record the necessary job data.
 The scheduler otherwise only sees a bunch of threads that occasionally
 sleep or block, followed by smaller or larger bursts of CPU activity.
 No notion of individual stage iterations, no dependency information of
 a thread waiting for the work of another, and no knowledge of timing requiremen
ts progresses down to the scheduler.
\end_layout

\begin_layout Standard
A key concept of 
\noun on
Atlas
\noun default
 is the explicit handover of such data to the scheduler.
 However, the solution should not be specific to video players in general
 or FFplay in particular.
 Instead, I modify FFplay to organize its work using the asynchronous lambdas
 programming style outlined earlier in this chapter.
 The integration between application and scheduler can then be implemented
 generically in the runtime library managing the asynchronous execution
 of the lambdas.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Processing pipelines
\end_layout

\end_inset

 such as FFplay’s engine lend themselves well to the queue-based dispatching
 of work in the asynchronous lambda style.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "2-fig:Changing-FFplay"

\end_inset

 outlines how I adapted FFplay’s loop-based implementations of the player
 stages to block-based execution using Grand Central Dispatch.
 FFplay’s main logic resides in a single file called 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
ffplay.c
\end_layout

\end_inset


\end_layout

\end_inset

 and I needed to modify or add 75 source lines to adapt the programming
 style, mostly converting thread management to queue handling and restructuring
 stage initialization code.
 This change constitutes less than 
\begin_inset Formula $5\%$
\end_inset

 of the 2100 line file.
 Additionally, the tens of thousands of source lines from FFmpeg libraries
 which FFplay uses for video decoding remain unchanged, making this a small
 change overall.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement t
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="32col%" special="@{}>{\centering}p{0.32\columnwidth}">
<column alignment="center" valignment="top" width="0pt">
<column alignment="left" valignment="top" width="35col%">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
lstparams "aboveskip=0pt,belowskip=0pt"
inline false
status open

\begin_layout Plain Layout

void input_stage() {
\end_layout

\begin_layout Plain Layout

	initialize_input();
\end_layout

\begin_layout Plain Layout

	while (1} {
\end_layout

\begin_layout Plain Layout

		pkt = read_input();
\end_layout

\begin_layout Plain Layout

		enqueue(video_queue, pkt);
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void decoder_stage() {
\end_layout

\begin_layout Plain Layout

	initialize_decoder();
\end_layout

\begin_layout Plain Layout

	while (1) {
\end_layout

\begin_layout Plain Layout

		pkt = dequeue(video_queue);
\end_layout

\begin_layout Plain Layout

		frame = decode(pkt);
\end_layout

\begin_layout Plain Layout

		enqueue(pict_queue, frame);
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void output_stage() {
\end_layout

\begin_layout Plain Layout

	initialize_output();
\end_layout

\begin_layout Plain Layout

	while (1) {
\end_layout

\begin_layout Plain Layout

		frame = dequeue(pict_queue);
\end_layout

\begin_layout Plain Layout

		time = display_time(frame);
\end_layout

\begin_layout Plain Layout

		wait_until(time);
\end_layout

\begin_layout Plain Layout

		display(frame);
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void start_playback() {
\end_layout

\begin_layout Plain Layout

	thread_create(input_stage);
\end_layout

\begin_layout Plain Layout

	thread_create(decoder_stage);
\end_layout

\begin_layout Plain Layout

	thread_create(output_stage);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
lstparams "aboveskip=0pt,belowskip=0pt"
inline false
status open

\begin_layout Plain Layout

void input_stage() {
\end_layout

\begin_layout Plain Layout

	pkt = read_input();
\end_layout

\begin_layout Plain Layout

	enqueue(video_queue, pkt);
\end_layout

\begin_layout Plain Layout

	dispatch_async(^{ decoder_stage(); });
\end_layout

\begin_layout Plain Layout

	dispatch_async(^{ input_stage(); });
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void decoder_stage() {
\end_layout

\begin_layout Plain Layout

	pkt = dequeue(video_queue);
\end_layout

\begin_layout Plain Layout

	frame = decode(pkt);
\end_layout

\begin_layout Plain Layout

	enqueue(pict_queue, frame);
\end_layout

\begin_layout Plain Layout

	dispatch_async(^{ output_stage(); });
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void output_stage() {
\end_layout

\begin_layout Plain Layout

	frame = dequeue(pict_queue);
\end_layout

\begin_layout Plain Layout

	time = display_time(frame);
\end_layout

\begin_layout Plain Layout

	wait_until(time);
\end_layout

\begin_layout Plain Layout

	display(frame);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void start_playback() {
\end_layout

\begin_layout Plain Layout

	initialize_input();
\end_layout

\begin_layout Plain Layout

	initialize_decoder();
\end_layout

\begin_layout Plain Layout

	initialize_output();
\end_layout

\begin_layout Plain Layout

	dispatch_async(^{ input_stage(); });
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
loop-based implementation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
block-based implementation
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
non-default float placement
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:Changing-FFplay"

\end_inset

Changing FFplay to Asynchronous Lambdas
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Developers are naturally reluctant
\end_layout

\end_inset

 to rewriting applications and would rather spend their time adding new
 features.
 However, in today’s world of scaling down to mobile devices on one end
 and scaling out to massive parallelism and the cloud on the other, applications
 are already under constant pressure to evolve.
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:ParallelJungle"

\end_inset

 This chapter has motivated the move to asynchronous lambdas as a recent
 trend, because they simplify development of parallel and responsive code.
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 strives to simplify development of real-time code by using the same programming
 model.
 To that end, it exploits the program structure exposed by lambdas to provide
 information to the scheduler.
 The next chapter explains the real-time task model and how the interaction
 between blocks in the application and jobs in the scheduler is orchestrated.
 The scheduler interface expects assistance from applications, but delivers
 non-functional timeliness properties in return.
\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "3-chap:Real-Time"

\end_inset

Real Simple Real
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{-0.45mm}{
\end_layout

\end_inset

-
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

Time
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "Data/3-Real-Time/Values.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Many of today’s applications
\end_layout

\end_inset

 have intrinsic real-time characteristics.
 The term real-time
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
real-time
\end_layout

\end_inset

 describes a predictable relation between observable system behavior and
 physical time.
\begin_inset CommandInset citation
LatexCommand cite
key "Kopetz:RealTimeSystems"

\end_inset

 Therefore, such requirements naturally surface when computers interact
 with the real world, which most application do through their user interface.
 In this work, I target interactive systems,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
interactive systems
\end_layout

\end_inset

 so examples operating along this cyber-physical boundary are:
\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset

Timely delivery of system output, such as
\begin_inset VSpace -8pt
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

speedy updates of user interface elements,
\end_layout

\begin_layout Itemize
smooth user interface animations, and
\end_layout

\begin_layout Itemize
uninterrupted video and sound playback.
\end_layout

\begin_layout Plain Layout
Timely reaction to human input, such as
\begin_inset VSpace -8pt
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

classical keyboard and mouse interaction,
\end_layout

\begin_layout Itemize
gesture tracking with touchscreen or video camera, and
\end_layout

\begin_layout Itemize
speech recognition.
\end_layout

\end_inset


\end_layout

\begin_layout Full Width
\noindent
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\noindent
I evaluate 
\noun on
Atlas
\noun default
 with user interaction, video playback, and gesture tracking workloads.
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

I contribute a task model and a layered scheduler interface which allows
 applications to express timing and resource requirements.
 The developer-facing part of the interface only asks for parameters from
 the application domain, which simplifies programming.
 The scheduler-facing part provides look-ahead information on future application
 behavior.
 A runtime library employs machine learning to mediate between the two layers.
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

I claim that 
\noun on
Atlas
\noun default
 is uniquely able to anticipate deadline misses before they occur.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
Within this chapter, I restrict all discussions and experiments to a single
 core scenario.
 My evaluation platform is a homogeneous multicore machine, so I always
 pin the relevant threads to the same core.
 An outlook toward a multicore extension of 
\noun on
Atlas
\noun default
 follows in the chapter 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset CommandInset ref
LatexCommand nameref
reference "5-chap:The-Road-Ahead"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
On the following pages,
\end_layout

\end_inset

 I will first motivate the need for real-time programming by explaining
 pervasive time-critical operations.
 I continue with insights on existing scheduler interfaces and their shortcoming
s, before describing and evaluating the design of 
\noun on
Atlas
\noun default
.
 The chapter closes with a discussion of previous research results and how
 they relate to 
\noun on
Atlas
\noun default
.
\end_layout

\begin_layout Section
The Need for Real-Time
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
Timing requirements
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset

 in end-user systems emerge for one of two reasons, illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Timing-Requirements"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

the system autonomously executes a workload that requires timely output
 of results or
\end_layout

\begin_layout Itemize
the user interacted with the system and expects a timely response.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Timing_Requirements.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Timing-Requirements"

\end_inset

Sources of Timing Requirements
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Continuous media
\end_layout

\end_inset

 is a real-time application with natural deadlines dictated directly by
 the processed workload.
 Video playback exhibits typical frame rates
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
frame rate
\end_layout

\end_inset

 between 24 and 60 frames per second, so frames must be displayed at 
\begin_inset Formula $16.7$
\end_inset

 to 
\begin_inset Formula $41.7\,\mathrm{ms}$
\end_inset

 intervals.
 Because users are accustomed to stutter-free movie experiences from cinema
 and television, providing high-quality video playback on general-purpose
 computers has been a subject of previous research regarding task models
\begin_inset CommandInset citation
LatexCommand cite
key "Ditze:MPEG_RT"

\end_inset

, execution time analysis
\begin_inset CommandInset citation
LatexCommand cite
key "Altenbernd:MPEG-WCET"

\end_inset

 and quality of service.
\begin_inset CommandInset citation
LatexCommand cite
key "Isovic:QoS_Video"

\end_inset


\end_layout

\begin_layout Standard
I designed 
\noun on
Atlas
\noun default
 with video in mind and it solves the problem of providing temporal guarantees
 to high-throughput dynamic applications such as video decoding.
 However, 
\noun on
Atlas
\noun default
 is not a video-specific solution, but also applies to other workloads.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
User interface code
\end_layout

\end_inset

 is of the second type.
 Timing requirements are driven by usability
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
usability
\end_layout

\end_inset

 considerations and follow a 
\begin_inset Formula $0.1$
\end_inset

/
\begin_inset Formula $1$
\end_inset

/
\begin_inset Formula $10$
\end_inset


\begin_inset space ~
\end_inset

second cadence:
\begin_inset CommandInset citation
LatexCommand cite
key "Card:RealTimeUI"

\end_inset


\end_layout

\begin_layout Standard
When a user explores an application by scrolling through data views or operating
 controls, visual feedback like updating the scroll view or rendering a
 button in pressed state should feel immediate, giving the user confidence
 that he is in charge.
 Interface changes may involve updating data representations, revealing
 interface panels, or opening popup-windows.
 The user perceives those changes as immediate, if the response time stays
 under 
\begin_inset Formula $100\,\mathrm{ms}$
\end_inset

.
 This limit becomes even tighter for touchscreen devices, where users operate
 items on the screen without the indirection of a mouse.
 Any interface lag will break the user’s perception, that the app “sticks
 to his finger.”
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:FastFluid"

\end_inset

 Animation can accompany the interface state change to support the user’s
 mental transition.
 Such aids should run timely and smoothly.
\end_layout

\begin_layout Standard
Whenever an operation runs longer than one second, the application should
 show a progress indicator.
 Otherwise, users start to wonder whether they accidentally missed the button
 and may click again.
 After ten seconds, users get bored waiting and switch to a different task.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Virtually all desktop applications
\end_layout

\end_inset

 perform user interface activities.
 But even though developers are aware of the need for responsiveness, timing
 requirements are hidden deep within the application and are not expressed
 to the scheduler.
 Typical frameworks for graphical user interfaces perform all screen updates
 from the main thread, so all the previously mentioned deadline classes
 conflate on one thread, impossible to distinguish for the scheduler.
\end_layout

\begin_layout Standard
I believe real-time programming can help with these problems and should
 become the default rather than the rare special case it is today.
 
\noun on
Atlas
\noun default
 can help pave the way by providing a simple scheduler interface.
\end_layout

\begin_layout Section
Talking to Schedulers
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Order_Matters.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Order-Matters"

\end_inset

Order Matters
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Real-time scheduling is about ordering work so that its execution meets
 previously negotiated timing constraints.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Order-Matters"

\end_inset

 illustrates, how order matters with time: Two jobs may come with different
 deadlines
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset

 such that one potential order violates the earlier deadline of job
\begin_inset space ~
\end_inset

B, while another order satisfies both deadlines.
 The scheduler should recognize this advantage of the second ordering and
 pick job
\begin_inset space ~
\end_inset

B first.
 To make this decision, it needs prior knowledge on both jobs’ deadlines
 and execution times.
 How applications can communicate their timing and resource requirements
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset

 to the system and what guarantees they receive in return are important
 aspects of scheduler design.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Solution_Spectrum.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Solution-Spectrum"

\end_inset

Real-Time Solution Spectrum
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Existing solutions
\end_layout

\end_inset

 cover a spectrum from strictly regulated to loosely managed platforms.
 As pictured in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Solution-Spectrum"

\end_inset

, the strict regulations are harder to program against, but yield strong
 guarantees, whereas the loosely organized systems trade weaker guarantees
 for simpler programming.
 To motivate the 
\noun on
Atlas
\noun default
 design, I describe the two extremes of this spectrum and discuss their
 downsides.
 A comparison of 
\noun on
Atlas
\noun default
 with other points in this solution space follows in a section on related
 work at the end of this chapter.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Fair CPU sharing
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
fair sharing
\end_layout

\end_inset

sits at the simplicity end of the spectrum.
 All of today’s commodity operating systems run almost exclusively on this
 policy.
 The Completely Fair Scheduler
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
completely fair scheduler
\end_layout

\end_inset

 (CFS) is the default scheduler on Linux
\begin_inset CommandInset citation
LatexCommand cite
key "Jones:InsideCFS"

\end_inset

 and is also used pervasively on Android.
\begin_inset CommandInset citation
LatexCommand cite
key "Maia:AndroidRT"

\end_inset

 The advantage of fair sharing is the lack of a complicated interface or
 task model.
 In fact, a developer has to do nothing to get decent behavior for his applicati
on.
 The scheduler distributes the CPU evenly across all ready threads to ensure
 that all of them make equal progress.
\end_layout

\begin_layout Standard
Users however do not care whether their applications receive equal shares,
 they simply want the right thing to happen at the right time.
 The fair share model is a good abstraction for performance isolation, but
 it may be the wrong abstraction for applications with timing requirements.
 The scheduler disregards timing requirements, because developers have no
 meaningful way to express them.
\end_layout

\begin_layout Standard
An experiment shows this disadvantage: While playing the Hunger Games video
\begin_inset Foot
status open

\begin_layout Plain Layout
This video is a representative high definition movie trailer.
 For detailed video properties, see Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-tab:Test-Clips"

\end_inset

.
\end_layout

\end_inset

 in FFplay, a competing load of ten CPU-hogging processes
\begin_inset Foot
status open

\begin_layout Plain Layout
Their complete source code:
\end_layout

\begin_layout Plain Layout
\begin_inset listings
inline true
status open

\begin_layout Plain Layout

int main(void) 
\backslash
{ while (1); 
\backslash
}
\end_layout

\end_inset


\end_layout

\end_inset

 starts one minute into playback.
 The CPU hoggers simulate a compute-intensive background activity.
 Linux’ default scheduler is used, but all threads are pinned to the same
 core of the 
\begin_inset Formula $2.4\,\mathrm{GHz}$
\end_inset

 Intel Core
\begin_inset space ~
\end_inset

i5 processor.
 Due to the scheduler’s fairness policy, each thread receives an equal share,
 squeezing the player down to 
\begin_inset Formula $\frac{1}{10+1}=9\%$
\end_inset

 of CPU time.
\begin_inset Foot
status open

\begin_layout Plain Layout
Counting FFplay as one thread is reasonable, because only its decoder thread
 is CPU intensive.
\end_layout

\end_inset

 This share is insufficient to decode the video, so frames are delayed.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Video-Smoothness"

\end_inset

 plots the time interval between adjacent frames over the runtime of the
 video, illustrating the user-perceived smoothness of the playback.
 The grey areas mark the competing background activity.
 Ideally, the graph should show a flat line at 
\begin_inset Formula $41.7\,\mathrm{ms}$
\end_inset

, corresponding to a rate of 24 frames per second.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Background_CFS_nice.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Video-Smoothness"

\end_inset

Video Smoothness with Competing Background Load
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
As soon as the background load starts, video quality suffers, because its
 timing requirements are no longer satisfied.
 Nice levels
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
nice level
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Unix:Nice"

\end_inset

 alleviate the problem, but cannot fundamentally solve it.
 A thread with a lower nice level receives a larger CPU share, but the actual
 time available to each thread depends on the number of competing threads
 and their nice levels.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Video-Smoothness"

\end_inset

 includes an experiment running FFplay at nice level
\begin_inset space ~
\end_inset


\begin_inset Formula $-5$
\end_inset

.
\begin_inset Foot
status open

\begin_layout Plain Layout
Only the root user is allowed to run applications with negative nice levels.
\end_layout

\end_inset

 The situation improves, but video quality is still not satisfying.
 Choosing the perfect nice level would require global knowledge of all threads
 in the system and their execution behavior.
 Therefore, nice levels are an inadequate interface to specify application
 timing requirements, because they rely on information an individual application
 does not have.
\end_layout

\begin_layout Standard
For the design of 
\noun on
Atlas
\noun default
, we learn that applications want to specify their timing needs in a way
 that requires no contextual knowledge of the surrounding system.
 
\noun on
Atlas
\noun default
 should meet those timing requirements even at the expense of fairness.
 The biggest strength of fair sharing
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

it is simple because it has no interface and it is practical because it
 exhibits useful default behavior
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

is also its biggest weakness: There is nothing the developer must do to
 use it, but at the same time, there is nothing the developer can do if
 things go wrong.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Periodic_Task.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Periodic-Task-Model"

\end_inset

Periodic Task Model
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The classical periodic task model
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
periodic task model
\end_layout

\end_inset

is diametrically opposed to the fair sharing model in our spectrum of solutions.
 Developers have to follow a strict programming regime, but the system’s
 runtime behavior will be predictable.
 Periodic tasks as illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Periodic-Task-Model"

\end_inset

 describe a chain of jobs with equal execution time 
\begin_inset Formula $e$
\end_inset

.
 Individual job instances must respect a minimum inter-arrival separation
 time, more commonly referred to as their period 
\begin_inset Formula $p$
\end_inset

.
 Each job meets an implicit deadline at the beginning of the next period,
 so jobs cannot overlap.
 This serial arrangement is the only inter-job dependency the model allows.
 Jobs from different tasks have to be independent, jobs may not block or
 self-suspend and must be fully preemptible.
\end_layout

\begin_layout Standard
Following these rigid rules enables strong guarantees of system behavior.
 Aggregating all the information and assumptions about the jobs, an admission
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
admission
\end_layout

\end_inset

 test can be performed.
 This test determines
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

either offline at design time or online while the system runs
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

whether the task set can be scheduled such that all tasks receive their
 requested CPU share of 
\begin_inset Formula $\:\nicefrac{e}{p}\:$
\end_inset

 and jobs always finish before their deadline, even in worst-case conditions.
 The task set and resulting schedule are then called 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
feasible
\end_layout

\end_inset

.
 The Rate-Monotonic Scheduling
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
rate-monotonic scheduling
\end_layout

\end_inset

 algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RMS"

\end_inset

 provides such a feasibility
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
feasibility
\end_layout

\end_inset

 test for periodic tasks on a single CPU.
 At runtime, it only needs a fixed priority scheduler to enforce the timeliness
 guarantees.
\end_layout

\begin_layout Standard
The strictness of the periodic task model limits application development.
 Complex real-time loads in interactive systems may not easily adhere to
 a minimum inter-arrival distance or a constant execution time of jobs.
\begin_inset CommandInset citation
LatexCommand cite
key "Baiceanu:VideoScheduling"

\end_inset

 Varying execution times have to be admitted with their theoretical worst
 case.
 For a dynamic workload like video playback, this worst-case planning leads
 to infeasible CPU reservations way higher than the actual demand.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\begin_inset Graphics
	filename Data/3-Real-Time/RMS_Admission.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:RMS-Below-Worst-Case"

\end_inset

Periodic Admission Below Worst-Case
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Extensions to the periodic task model
\end_layout

\end_inset

 as in Quality Rate-Monotonic Scheduling
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
quality rate-monotonic scheduling
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Hamann:QRMS"

\end_inset

 allow to admit tasks with less than their worst-case execution time, resulting
 in a portion of deadline misses at runtime.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:RMS-Below-Worst-Case"

\end_inset

 plots the expected deadline misses for the Sintel video
\begin_inset Foot
status open

\begin_layout Plain Layout
This video is CPU intensive to decode.
 For detailed video properties, see Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-tab:Film-Clips"

\end_inset

.
\end_layout

\end_inset

 over the execution time reserved per period.
 The period is a constant 
\begin_inset Formula $p\!=\!41.7\,\mathrm{ms}$
\end_inset

, so the execution time directly corresponds to a CPU reservation 
\begin_inset Formula $\:\nicefrac{e}{p}$
\end_inset

, given in percent.
 Buffering in the player is disregarded, because the task model disallows
 overlapping scheduling windows.
 The right end of the graph shows a worst-case admission, which would result
 in no deadline misses, but its required CPU share of almost 
\begin_inset Formula $200\%$
\end_inset

 is impossible to accommodate on a single CPU.
 In fact, all reservations greater than 
\begin_inset Formula $100\%$
\end_inset

 are infeasible, so even the highest possible reservation only guarantees
 
\begin_inset Formula $\RMSBestAdmission$
\end_inset

 of the deadlines.
\end_layout

\begin_layout Standard
At runtime, the player will of course consume much less than the worst-case
 most of the time, so a slack reclaiming
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
slack reclaiming
\end_layout

\end_inset

 strategy
\begin_inset CommandInset citation
LatexCommand cite
key "Caccamo:SlackReclaiming"

\end_inset

 can redistribute the extra time to other threads.
 However, such slack is not guaranteed and threads with a reservation less
 than their worst-case may not receive enough time when they need it.
\end_layout

\begin_layout Standard
We learn that the periodic task model is inflexible in describing timing
 requirements and pessimistic in describing resource requirements.
 
\noun on
Atlas
\noun default
 should offer more flexible reservations than periods with a constant job
 execution time.
 Instead, we want 
\noun on
Atlas
\noun default
 to accommodate jobs dynamically according to their actual need, thus improving
 support for highly dynamic applications like video decoding.
\end_layout

\begin_layout Standard
The main advantage of the periodic task model is its infinite clairvoyance.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
clairvoyance
\end_layout

\end_inset

 The scheduling algorithm can make strong assumptions on the tasks’ future
 behavior and can use them to provide an admission test.
 Once admitted, jobs are guaranteed to receive their reservations before
 the deadlines, but with worst-case reservations, only few tasks can be
 admitted.
 Developers must take responsibility for adhering to the task model and
 not violating its assumptions.
\end_layout

\begin_layout Section
Designing 
\noun on
Atlas
\end_layout

\begin_layout Standard
The discussion of existing scheduling interfaces and their advantages and
 shortcomings condenses into a set of design constraints for 
\noun on
Atlas
\noun default
.
 We want to find a middle ground between simplicity for programmers and
 strong real-time guarantees.
\end_layout

\begin_layout Enumerate

\noun on
Atlas
\noun default
 shall allow developers to express timing requirements,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset

 otherwise we cannot ask the scheduler to respect them.
\begin_inset Newline newline
\end_inset

Contrast this to fair sharing,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
fair sharing
\end_layout

\end_inset

 which does not convey any timing requirements and thus fails to meet applicatio
ns’ timeliness
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timeliness
\end_layout

\end_inset

 needs.
\end_layout

\begin_layout Enumerate

\noun on
Atlas
\noun default
 shall allow a context-independent specification of resource requirements.
\begin_inset Newline newline
\end_inset

Fair sharing offers nice levels, which alter a thread’s sharing weight relative
 to the surrounding load.
 Periodic tasks ask the developer for an execution time, which depends on
 the target hardware and the user-provided workload.
 Both thus require information the developer does not have.
\end_layout

\begin_layout Enumerate

\noun on
Atlas
\noun default
 shall put timeliness
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timeliness
\end_layout

\end_inset

 before fairness.
\begin_inset Newline newline
\end_inset

Fair sharing tries to assign the CPU equally to all ready threads.
 As shown by the video player experiment, this behavior is not necessarily
 in the user’s best interest.
\end_layout

\begin_layout Enumerate

\noun on
Atlas
\noun default
 shall not refuse work.
\begin_inset Newline newline
\end_inset

Scheduling algorithms for hard deadlines must reject new work when they
 cannot guarantee real-time performance.
 
\noun on
Atlas
\noun default
 targets firm
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
firm deadline
\end_layout

\end_inset

 and soft deadlines
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
soft deadline
\end_layout

\end_inset

 and can afford to overload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
overload
\end_layout

\end_inset

 the system if the user demands too much.
\end_layout

\begin_layout Enumerate

\noun on
Atlas
\noun default
’ task model and programming interface shall be flexible and insightful.
\begin_inset Newline newline
\end_inset

Fair sharing offers perfect flexibility, because it does not impose any
 rules on application behavior.
 The periodic task model is rigid, but offers infinite clairvoyance of the
 task’s future behavior.
\end_layout

\begin_layout Standard
I will now tick off these properties by explaining the architectural building
 blocks of 
\noun on
Atlas
\noun default
.
\end_layout

\begin_layout Description
Deadlines
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset

 are a natural way to express timing requirements.
 Developers know about timing constraints, because they are part of the
 application’s problem domain.
 The same thread may execute real-time jobs with different deadlines, so
 the scheduler cannot generally guess deadlines by observing the thread.
 Black-box heuristics may improve unmodified applications,
\begin_inset CommandInset citation
LatexCommand cite
key "Cucinotta:Self-Tuning"

\end_inset

 but programmatically exposing deadlines provides added value to the scheduler.
\end_layout

\begin_layout Description
Execution
\begin_inset space \space{}
\end_inset

times
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
execution time
\end_layout

\end_inset

 allow the scheduler to allocate time for jobs,
\begin_inset CommandInset citation
LatexCommand cite
key "Mercer:CapacityReserve"

\end_inset

 calculate a schedule, and anticipate deadline misses.
 However, execution times are hard to obtain for developers because they
 depend on the end-user hardware and the workload.
 
\noun on
Atlas
\noun default
 resolves this impedance mismatch with an indirection: An estimator between
 the application and the system-level scheduler decouples the interface
 as seen by the developer from the lower-level interface of the scheduler.
 Developers provide 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

 to the estimator, which uses machine learning to infer execution time predictio
ns.
\begin_inset Foot
status open

\begin_layout Plain Layout
This aspect inspired the “
\noun on
At
\noun default
” when naming 
\noun on
Atlas
\noun default
 the Auto-Training Look-Ahead Scheduler.
\end_layout

\end_inset


\end_layout

\begin_layout Description
Urgency is the primary criterion for task selection by the scheduler.
 Fairness is strictly a secondary concern.
 I postulate that users do not care about fairness as long as all applications
 meet their timing requirements.
 
\noun on
Atlas
\noun default
 considers fairness only in overload situations when time constraints are
 jeopardized.
 In underloaded systems, applications may receive disproportionate CPU shares
 to meet deadlines.
\end_layout

\begin_layout Description
Overload
\begin_inset space \space{}
\end_inset

Detection replaces traditional real-time admission, which uses a priori
 information to prevent overload.
 I object to overruling a user decision, so 
\noun on
Atlas
\noun default
 will never reject work.
 However, I demonstrate later in this chapter that 
\noun on
Atlas
\noun default
 can detect overload situations before they occur.
 The chapter 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand nameref
reference "4-chap:Adaptivity"

\end_inset


\end_layout

\end_inset

 discusses how to coordinate workload adaptation to mitigate overload dynamicall
y.
\end_layout

\begin_layout Description
Look-Ahead replaces the infinite clairvoyance offered by periodic tasks.
 
\noun on
Atlas
\noun default
 opts for an explicit submission of future jobs without constraining the
 inter-arrival distance or demanding non-overlapping scheduling windows.
 The 
\noun on
Atlas
\noun default
 task model is flexible, but compromises on the guarantees it can make.
\end_layout

\begin_layout Standard
Specifying deadlines and submitting jobs are an application responsibility,
 because only the developer has the necessary domain knowledge.
 Execution times even depend on the workload the application is currently
 processing, like the video the user chose to play.
 However, distributing CPU time requires global supervision, because jobs
 from different applications must be ordered to respect their individual
 time constraints.
 Therefore, application components must work with the global scheduler in
 a unified solution.
\end_layout

\begin_layout Section
End-to-End Integration
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Verical_Integration_Overview.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Vertical-Integration-Timeliness"

\end_inset

Vertical Integration for Timeliness
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Vertical-Integration-Timeliness"

\end_inset

 illustrates the cooperation between the 
\noun on
Atlas
\noun default
 layers to provide timeliness properties to applications: Metrics collected
 from the workload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload
\end_layout

\end_inset

 help a machine learning component understand the dependency between processed
 data and job execution time.
 Execution time predictions follow from the metrics.
 The application propagates these predictions together with deadlines to
 the scheduler
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
scheduler
\end_layout

\end_inset

 before the job runs, offering a limited look into the future.
 The scheduler orders jobs from all application to provide timely execution.
 Application and scheduler stay in sync about which job is currently active,
 allowing the application to associate the right work with each job to ensure
 timely processing.
\end_layout

\begin_layout Standard
Throughout the following explanation of the 
\noun on
Atlas
\noun default
 architecture and design, I will repeat Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Vertical-Integration-Timeliness"

\end_inset

 to highlight the described component.
 With the exception of the asynchronous lambda layer, the architecture was
 previously published
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:ATLAS"

\end_inset

 and select text in the task model, interfaces, and prediction sections
 may have been copied verbatim from this paper.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Architectural_Overview.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Architectural-Overview"

\end_inset

Architectural Overview
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The architectural overview
\end_layout

\end_inset

 in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Architectural-Overview"

\end_inset

 reflects the conceptual layers just discussed.
 Applications inspect their workload and talk to a local estimator
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
estimator
\end_layout

\end_inset

 component, which is linked to the application as a library.
 This component implements the 
\noun on
Atlas
\noun default
 interface as seen by the application developer.
 It remembers submitted jobs in a local queue until they have run to completion.
\end_layout

\begin_layout Standard
The per-application estimator also forwards all its jobs to the system-wide
 scheduler, which queues them for execution.
 Because I think the estimator interface is simpler, developers should not
 need to use the scheduler interface directly.
 However, direct access to the scheduler is not prohibitive for functionality
 or security.
\end_layout

\begin_layout Standard
The estimator component queues the jobs solely to remember the workload
 metrics and the application code associated with the job.
 
\noun on
Atlas
\noun default
 does not employ hierarchical scheduling.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
hierarchical scheduling
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Regehr:HLS"

\end_inset

 Instead, the passing of job descriptions to the system-wide scheduler enables
 comprehensive scheduling decisions in one place.
 The applications then execute according to those decisions.
\end_layout

\begin_layout Standard
The two interface layers use two different kinds of job descriptions 
\begin_inset Formula $J'$
\end_inset

 and 
\begin_inset Formula $J$
\end_inset

.
 I first formalize the task model, before I explain the interface operations
 and their integration into the application runtime.
\end_layout

\begin_layout Section
Task Model and Interfaces
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 runs a finite set 
\begin_inset Formula $T=\{\tau_{i}\mid i=1,\ldots,n\}$
\end_inset

 of tasks 
\begin_inset Formula $\tau_{i}$
\end_inset

.
 The task set is dynamic, because applications start and stop at the user’s
 discretion.
 Each task 
\begin_inset Formula $\tau_{i}$
\end_inset

 is a set 
\begin_inset Formula $\tau_{i}=\{\, J_{i,j}\mid j=1,\ldots,m\}$
\end_inset

 of aperiodic jobs
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
aperiodic jobs
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
job
\end_layout

\end_inset

 
\begin_inset Formula $J_{i,j}$
\end_inset

.
 While theoretically unbounded, at any given time the number of jobs per
 task is finite, because we do not use a periodic task model, where an infinite
 set of jobs is known a priori.
 In the following, 
\begin_inset Formula $i$
\end_inset

 typically denotes the task number and 
\begin_inset Formula $j$
\end_inset

 the job number within the task.
 At most one job per task can be running and jobs execute in arrival order.
 Therefore, tasks are an abstract concept to describe inter-job dependencies.
\end_layout

\begin_layout Standard
At the scheduler level, each job is described as a pair 
\begin_inset Formula $J_{i,j}=(e_{i,j},d_{i,j})$
\end_inset

 of an estimated execution time
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
execution time
\end_layout

\end_inset

 
\begin_inset Formula $e_{i,j}$
\end_inset

 and an absolute deadline
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset

 
\begin_inset Formula $d_{i,j}$
\end_inset

.
 Applications can release jobs whenever they want, no minimum inter-release
 time and consequently no maximum time demand can be assumed.
 This design decision is in line with the goal of a flexible task model
 at the expense of a formal feasibility analysis.
\end_layout

\begin_layout Standard
While the deadlines 
\begin_inset Formula $d_{i,j}$
\end_inset

 are provided by the application developer directly, the execution times
 
\begin_inset Formula $e_{i,j}$
\end_inset

 are not.
 The application provides its estimator with job descriptions 
\begin_inset Formula $J'_{i,j}=(\underline{m}_{i,j},d_{i,j})$
\end_inset

 consisting of a vector 
\begin_inset Formula $\underline{m}_{i,j}$
\end_inset

 of workload metrics
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

 and the deadline as seen by the scheduler.
 From the metrics, the estimator derives approximate execution times.
 It can provide these estimates before the job executes.
 Workload metrics are a tuple of positive real numbers describing the computatio
nal weight of the workload.
 The estimator expects at least a subset of them to correlate positively
 with the execution time.
 Details on the metrics and examples for their use follow later in this
 chapter.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The estimator
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
estimator
\end_layout

\end_inset

collects job descriptions in local job queues and predicts the per-job execution
 times.
 It trains itself using the application-provided metrics and a history of
 measured actual execution times of past jobs.
 With the predicted execution times, the estimator forwards for each of
 its jobs 
\begin_inset Formula $J'_{i,j}$
\end_inset

 a translated job 
\begin_inset Formula $J_{i,j}$
\end_inset

 to the scheduler.
 The estimator exposes the following three interface primitives:
\end_layout

\begin_layout Description
submit(
\begin_inset Formula $i$
\end_inset

,
\begin_inset space \space{}
\end_inset


\begin_inset Formula $J'_{i,j}\,$
\end_inset

) As soon as an application learns about a job it needs to perform, it should
 register the job with 
\noun on
Atlas
\noun default
.
 The application announces an identifier 
\begin_inset Formula $i$
\end_inset

 of the task this job belongs to and a job description 
\begin_inset Formula $J'_{i,j}=(\underline{m}_{i,j},d_{i,j})$
\end_inset

 that includes a deadline 
\begin_inset Formula $d_{i,j}$
\end_inset

 and a vector 
\begin_inset Formula $\underline{m}_{i,j}$
\end_inset

 of workload metrics.
 When a job is submitted, the estimator uses 
\begin_inset Formula $\underline{m}_{i,j}$
\end_inset

 and its internal training state to predict the job's execution time 
\begin_inset Formula $e_{i,j}$
\end_inset

 and forwards the resulting job 
\begin_inset Formula $J_{i,j}=(e_{i,j},d_{i,j})$
\end_inset

 to the scheduler.
 It keeps the job 
\begin_inset Formula $J'_{i,j}$
\end_inset

 in its local queue to automatically train the estimation once the actual
 execution time of the job is known.
\end_layout

\begin_deeper
\begin_layout Standard
Applications can submit jobs long before actual execution begins and should
 do so as early as possible to allow the scheduler to look into the future.
 By submitting a job 
\begin_inset Formula $J'_{i,j}$
\end_inset

 an application promises the following: As soon as the work of all previously
 submitted jobs 
\begin_inset Formula $J'_{i,k<j}$
\end_inset

 within task 
\begin_inset Formula $\tau_{i}$
\end_inset

 is finished, the application will, when given CPU time, start working on
 the submitted job 
\begin_inset Formula $J'_{i,j}$
\end_inset

.
 In other words, there is no extra work performed between 
\begin_inset Formula $J'_{i,j-1}$
\end_inset

 and 
\begin_inset Formula $J'_{i,j}$
\end_inset

 that the submitted jobs do not cover.
 This way, the estimator and scheduler are aware of all work the application
 performs within a task 
\begin_inset Formula $\tau_{i}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Description
next(
\begin_inset space \thinspace{}
\end_inset

) Because jobs execute back to back within a task, this primitive notifies
 the estimator that the current job 
\begin_inset Formula $J'_{i,j}$
\end_inset

 within task 
\begin_inset Formula $\tau_{i}$
\end_inset

 completed and that the next job 
\begin_inset Formula $J'_{i,j+1}$
\end_inset

 should start.
 The identity of the caller invoking 
\emph on
next
\emph default
 implicitly determines the task number 
\begin_inset Formula $i$
\end_inset

.
 The estimator is trained with the actual execution time 
\begin_inset Formula $t_{i,j}$
\end_inset

 of the just finished job and the metrics vector 
\begin_inset Formula $\underline{m}_{i,j}$
\end_inset

 stored during 
\emph on
submit
\emph default
.
 Then the execution time measurement for 
\begin_inset Formula $t_{i,j+1}$
\end_inset

 starts.
 The 
\emph on
next
\emph default
 primitive also informs the scheduler of the job switch.
\end_layout

\begin_layout Description
cancel(
\begin_inset Formula $i$
\end_inset

,
\begin_inset space \space{}
\end_inset


\begin_inset Formula $j$
\end_inset

) Applications can revoke a previously submitted job 
\begin_inset Formula $J_{i,j}$
\end_inset

 of task 
\begin_inset Formula $\tau_{i}$
\end_inset

.
 This operation mainly serves technical purposes: A video player would use
 
\emph on
cancel
\emph default
 when the user stops playback midway in the video.
 I do not consider job cancelation in this chapter, but it is important
 for overload mitigation, which I discuss in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Adaptivity"

\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Should we replace “cancel” with “update”?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The CPU scheduler
\end_layout

\end_inset

 resides in the Linux kernel.
 
\noun on
Atlas
\noun default
 modifies the kernel’s interface to add three new system calls:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
system call
\end_layout

\end_inset


\end_layout

\begin_layout Description
atlas_submit notifies the scheduler about a new job.
 The 
\emph on
submit
\emph default
 primitive employs the 
\emph on
atlas_submit
\emph default
 system call to pass the estimated execution time and the application-provided
 deadline to the kernel.
 The kernel also receives the thread identifier of the submission target.
 This information is necessary, because a thread can submit new jobs to
 threads other than itself.
 This is useful for producer-consumer scenarios, where the producer thread
 will submit jobs for the consumer thread.
\end_layout

\begin_layout Description
atlas_next is used by the 
\emph on
next
\emph default
 primitive to inform the scheduler that the thread is now ready to begin
 the next job.
 No parameters are necessary, because 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout

\emph on
atlas_next
\end_layout

\end_inset

 always affects the calling thread.
 If the scheduler decides to run a different thread instead, the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout

\emph on
atlas_next
\end_layout

\end_inset

 system call blocks until the scheduler picks the caller again.
\end_layout

\begin_layout Description
atlas_cancel removes a job from the kernel’s schedule.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Look-ahead knowledge
\end_layout

\end_inset

 can build up in the scheduler, when jobs are submitted early before their
 execution.
 This course of action aligns with the programming paradigm of asynchronous
 lambdas, which I described in the previous chapter.
 This style of organizing applications encourages developers to submit blocks
 of work to a queueing runtime library for asynchronous execution.
\end_layout

\begin_layout Section
Lambdas with Deadlines
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Verical_Integration_Application.svg

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Integration of the 
\noun on
Atlas
\noun default
 primitives with an asynchronous lambda runtime helps to reduce the development
 overhead of adding real-time support to such modern desktop applications.
 Therefore, I implement a subset of the Grand Central Dispatch
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
grand central dispatch
\end_layout

\end_inset

 (GCD) infrastructure with built-in 
\noun on
Atlas
\noun default
 support.
\begin_inset Foot
status open

\begin_layout Plain Layout
Because of its high degree of optimization, the official GCD implementation
 is complex.
 Reimplementing a GCD subset was easier than modifying the actual GCD library
 and suffices to show the viability of my approach.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The key GCD function call is 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_async(q, b)
\end_layout

\end_inset


\end_layout

\end_inset

.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatchRef"

\end_inset

 It submits block
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset

 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
b
\end_layout

\end_inset

 to a queue
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
dispatch queue
\end_layout

\end_inset

 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
q
\end_layout

\end_inset

.
 The GCD runtime will execute the block later at its own convenience using
 an automatically managed background thread.
 When submitting to a serial queue, only the order of block execution is
 known.
 No assumptions about the completion time of blocks can be made.
 
\noun on
Atlas
\noun default
 integration can change that.
 I augmented 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_async
\end_layout

\end_inset


\end_layout

\end_inset

 with a job description containing three additional arguments:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

the absolute deadline,
\end_layout

\begin_layout Itemize
the size of the metrics vector, and
\end_layout

\begin_layout Itemize
an array holding the metrics.
\end_layout

\begin_layout Standard
The signature of the resulting new function is:
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

typedef struct {
\end_layout

\begin_layout Plain Layout

	double deadline;
\end_layout

\begin_layout Plain Layout

	size_t metrics_count;
\end_layout

\begin_layout Plain Layout

	const double *metrics;
\end_layout

\begin_layout Plain Layout

} atlas_job_t;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

void
\end_layout

\begin_layout Plain Layout

dispatch_async_atlas(dispatch_queue_t queue,
\end_layout

\begin_layout Plain Layout

                     atlas_job_t job,
\end_layout

\begin_layout Plain Layout

                     dispatch_block_t block);
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
The block remains the last argument, which improves readability when writing
 block code inline.
\end_layout

\begin_layout Standard
The implementation of 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
\noindent
dispatch_async_atlas
\end_layout

\end_inset


\end_layout

\end_inset

 enqueues the block in the dispatch queue and calls 
\emph on
submit
\emph default
 to inform the 
\noun on
Atlas
\noun default
 estimator about a new job 
\begin_inset Formula $J'_{i,j}$
\end_inset

 with the given deadline and metrics.
 The dispatch queue corresponds to the task 
\begin_inset Formula $\tau_{i}$
\end_inset

.
 The estimator predicts the execution time for the job and forwards it to
 the scheduler.
\end_layout

\begin_layout Standard
In my prototype, every dispatch queue comes with an associated worker thread.
 It runs an endless loop, where it first calls the 
\emph on
next
\emph default
 primitive, which can block until the scheduler wants the next job to start.
 When 
\emph on
next
\emph default
 returns, the worker dequeues the next block and executes it.
 After the block completes, its measured execution time trains the estimator.
\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Job-Lifetime"

\end_inset

 summarizes the lifetime of a job from initial submission to final execution.
 The interplay between asynchronous runtime, estimator, and system-wide
 scheduler ensure, that the timely release of jobs in the kernel translates
 to timely processing of the application workload.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Job_Lifetime.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Job-Lifetime"

\end_inset

A Job’s Life Through the Interface Layers
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Queues and estimators
\end_layout

\end_inset

 are orthogonal in my implementation, allowing the programmer to submit
 any block to any queue.
 The queue is specified explicitly in the first parameter of 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\noindent
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
\noindent
dispatch_async_atlas
\end_layout

\end_inset


\end_layout

\end_inset

.
 The correct execution time estimator is chosen automatically based on the
 identity of the block.
 This separation allows developers to freely organize queues and blocks
 to fit the application.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Being a research prototype,
\end_layout

\end_inset

 my 
\noun on
Atlas
\noun default
 implementation is subject to the following limitations and assumptions:
\end_layout

\begin_layout Itemize
Other than the official GCD library, my reimplementation of the queueing
 infrastructure only supports independent serial queues.
 I indicate an extension for parallel queues in the chapter 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand nameref
reference "5-chap:The-Road-Ahead"

\end_inset


\end_layout

\end_inset

.
 The official GCD interface also provides functions to suspend and resume
 queues or organize them in parent-child relationships.
 The 
\noun on
Atlas
\noun default
 concept does not technically prevent completing the implementation, but
 the implemented subset is sufficient to demonstrate my approach.
\end_layout

\begin_layout Itemize
One worker thread is statically allocated for each dispatch queue.
 The worker threads could be dynamically stopped when the queues are idle
 and restarted on demand, but my implementation is simpler and not wasteful,
 because the worker of an empty queue will not needlessly burn CPU time,
 but blocks in the kernel when calling 
\emph on
atlas_next
\emph default
.
\end_layout

\begin_layout Itemize
Consecutive submissions to the same queue must have non-decreasing deadlines.
 This limitation originates from the implementation of the 
\noun on
Atlas
\noun default
 kernel scheduler.
 The kernel sorts jobs by their deadline, which means applications have
 to match their job management, or the job order will differ.
 The semantics of serial queues dictate submit-order execution anyway, so
 this limitation is acceptable.
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 also assumes deadlines and metrics to be available at job submission time.
 This assumption is not an artifact of my implementation, but is fundamental
 to the concept.
 
\noun on
Atlas
\noun default
 needs the metrics at submission time, because the estimator derives an
 execution time prediction from them.
 This estimate together with the deadline informs the scheduler about the
 timing and resource requirements of the job.
\end_layout

\begin_layout Standard
Applications, where deadlines or metrics emerge while the job is already
 running are unsuitable for 
\noun on
Atlas
\noun default
.
 It may help to split work into multiple jobs, starting with the first job
 until the deadline is known and then submitting a follow-up job with that
 deadline.
 However, this limitation was not impeding my experiments so I presume it
 does not hinder 
\noun on
Atlas
\noun default
’ applicability.
 A detailed explanation on my test workloads and how I adapted them for
 
\noun on
Atlas
\noun default
 follows later in this chapter.
\end_layout

\begin_layout Section
Execution Time Prediction
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Verical_Integration_Workload.svg

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 uses workload metrics
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

 from the application domain instead of calling on developers to provide
 actual execution times.
 Applications provide the metrics as part of each job description 
\begin_inset Formula $J'_{i,j}$
\end_inset

 in a vector 
\begin_inset Formula $\underline{m}_{i,j}$
\end_inset

 of real numbers to their estimator.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
estimator
\end_layout

\end_inset

 The estimator assumes a subset of metrics to have a positive linear correlation
 with the job execution time.
 Badly correlated elements will be filtered out automatically to improve
 numerical stability.
\end_layout

\begin_layout Standard
The developer should choose metrics on a “larger value means more work”
 basis.
 Expected iteration counts of loops or the expected number of times an expensive
 function is called are good candidates.
 Metrics vectors for different instances of the same block must be compatible,
 that is, the same metric must be delivered in the same vector element.
 Accordingly, the vectors also deliver the same number of metrics 
\begin_inset Formula $l_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
A linear auto-regressive predictor
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
linear auto-regressive predictor
\end_layout

\end_inset

produces execution time estimates from the metrics.
 The problem formalization is based on previous work,
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Predict"

\end_inset

 but the implementation presented here removes the need for an offline training
 phase.
 A new mathematical apparatus continuously updates and stabilizes online.
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 maintains an independent estimator state for each kind of block submitted
 with 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_async_atlas
\end_layout

\end_inset


\end_layout

\end_inset

.
 However, for clarity, I omit an index discriminating different estimators
 on the variables below.
 The index would be identical for all variables and would only clutter the
 explanation.
\end_layout

\begin_layout Standard
The estimator conceptually collects a history of metrics vectors in a metrics
 matrix 
\begin_inset Formula $M$
\end_inset

, where each individual vector 
\begin_inset Formula $\underline{m}_{j}$
\end_inset

 contributes a row of the matrix.
\begin_inset Foot
status open

\begin_layout Plain Layout
Capital letters denote matrices, underlined letters denote vectors.
\end_layout

\end_inset

 All elements are real values.
 For jobs already executed, the estimator also knows the actual, measured
 execution times 
\begin_inset Formula $t_{j}$
\end_inset

 of the jobs and collects them in a column vector 
\begin_inset Formula $\underline{t}$
\end_inset

.
 To predict execution times of future jobs, the estimator uses this history
 to obtain a coefficient vector
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
coefficient vector
\end_layout

\end_inset

 
\begin_inset Formula $\underline{x}$
\end_inset

 that approximates the execution times when applied to past metrics:
\begin_inset Formula 
\[
M\underline{x}\approx\underline{t}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
The number 
\begin_inset Formula $l$
\end_inset

 of metrics per job is expected to be small compared to the number of jobs
 
\begin_inset Formula $k$
\end_inset

, so the linear equation has more rows than columns.
 The equation is therefore overdetermined, so we reformulate it as a linear
 least squares problem:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
linear least squares problem
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\left\Vert \underline{z}\right\Vert _{2}$
\end_inset

 is the Euclidean Norm of 
\begin_inset Formula $\underline{z}$
\end_inset

.
\end_layout

\end_inset


\begin_inset Formula 
\[
\left\Vert M\underline{x}-\underline{t}\right\Vert _{2}\rightarrow\min_{\underline{x}}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
Given such coefficients 
\begin_inset Formula $\underline{x}$
\end_inset

 and a metrics vector 
\begin_inset Formula $\underline{m}$
\end_inset

 of a new job description 
\begin_inset Formula $J'$
\end_inset

, the estimator can calculate the execution time prediction as a dot product
 of both:
\begin_inset Formula 
\[
e=\underline{m}\cdot\underline{x}
\]

\end_inset

This estimated time is forwarded to the system scheduler.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
QR decomposition
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
QR
\end_layout

\end_inset

 decomposition
\end_layout

\end_inset

is the textbook solution
\begin_inset CommandInset citation
LatexCommand cite
key "Stoer:Numerics"

\end_inset

 for linear least squares problems.
 Let 
\begin_inset Formula $M$
\end_inset

 have 
\begin_inset Formula $k$
\end_inset

 rows and 
\begin_inset Formula $l$
\end_inset

 columns, with 
\begin_inset Formula $k>l$
\end_inset

.
 
\begin_inset Formula $M$
\end_inset

 is decomposed into an orthogonal real 
\begin_inset Formula $k\times k$
\end_inset

 matrix 
\begin_inset Formula $Q$
\end_inset

 and a real 
\begin_inset Formula $k\times l$
\end_inset

 matrix 
\begin_inset Formula $R$
\end_inset

, such that 
\begin_inset Formula $M=QR$
\end_inset

 holds.
 
\begin_inset Formula $R$
\end_inset

 has the form
\begin_inset Formula 
\[
R=\begin{pmatrix}\hat{R}\\
0
\end{pmatrix}\begin{array}{l}
\left\} \; l\right.\\
\left\} \; k-l\right.
\end{array}
\]

\end_inset

with 
\begin_inset Formula $\hat{R}$
\end_inset

 being a real 
\begin_inset Formula $l\times l$
\end_inset

 upper triangular matrix.
 Similarly dividing the 
\begin_inset Formula $Q$
\end_inset

-transformed vector of measured execution times
\begin_inset Formula 
\[
\underline{c}:=Q^{T}\underline{t}=\begin{pmatrix}\underline{\hat{c}}\\
\underline{c_{R}}
\end{pmatrix}\begin{array}{l}
\left\} \; l\right.\\
\left\} \; k-l\right.
\end{array}
\]

\end_inset

and applying the orthogonality of 
\begin_inset Formula $Q$
\end_inset

 yields a solution for the linear least square problem:
\begin_inset Formula 
\begin{gather*}
\bigl\Vert M\underline{x}-\underline{t}\bigr\Vert_{2}=\bigl\Vert\hat{R}\underline{x}-\underline{\hat{c}}\bigr\Vert_{2}+\bigl\Vert\underline{c_{R}}\bigr\Vert_{2}\rightarrow\min_{\underline{x}}\\
\mathrm{iff}\\
\hat{R}\underline{x}=\underline{\hat{c}}
\end{gather*}

\end_inset

This equation is easily solved by back-substitution, because 
\begin_inset Formula $\hat{R}$
\end_inset

 is upper triangular.
 The resulting 
\begin_inset Formula $\underline{x}$
\end_inset

 is unique, if 
\begin_inset Formula $M$
\end_inset

 has full rank.
 The residual error of the least squares fit is 
\begin_inset Formula $\left\Vert \underline{c}_{R}\right\Vert _{2}$
\end_inset

.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\left\Vert \underline{c}_{R}\right\Vert _{2}^{2}$
\end_inset

 is also called the residual sum of squares.
\end_layout

\end_inset

 The transformation of 
\begin_inset Formula $M$
\end_inset

 and 
\begin_inset Formula $\underline{t}$
\end_inset

 into 
\begin_inset Formula $R$
\end_inset

 and 
\begin_inset Formula $\underline{c}$
\end_inset

 and thereby into 
\begin_inset Formula $\hat{R}$
\end_inset

 and 
\begin_inset Formula $\underline{\hat{c}}$
\end_inset

 can be unified into one step:
\begin_inset Formula 
\begin{gather*}
R=Q^{T}M\quad\mathrm{and}\quad\underline{c}=Q^{T}\underline{t}\\
\mathrm{iff}\\
\left(R,\underline{c}\right)=Q^{T}\left(M,\underline{t}\right)
\end{gather*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
Therefore, the approach to determine 
\begin_inset Formula $\underline{x}$
\end_inset

 is to merge metrics and measured execution times into a single two-dimensional
 array and transform it as a whole.
 The resulting array holds 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

 as illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Structure-LLSP"

\end_inset

.
 It represents the upper triangular system 
\begin_inset Formula $\hat{R}\underline{x}=\underline{\hat{c}}$
\end_inset

 yielding 
\begin_inset Formula $\underline{x}$
\end_inset

.
 Note that this system has a constant size of 
\begin_inset Formula $l$
\end_inset

 rows, independent of the number of rows 
\begin_inset Formula $k$
\end_inset

 collected in 
\begin_inset Formula $M$
\end_inset

 and 
\begin_inset Formula $\underline{t}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/LLSP_System.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Structure-LLSP"

\end_inset

Structure of the Linear Least Squares Solution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Advancing from concept to implementation,
\end_layout

\end_inset

 we want an estimator that continuously calculates the solution 
\begin_inset Formula $\underline{x}$
\end_inset

 at runtime, without an offline training phase.
 A naïve implementation would remember the entire history of metrics and
 measured execution times and repeatedly solve the complete linear least
 squares problem to obtain an updated coefficient vector 
\begin_inset Formula $\underline{x}$
\end_inset

.
 This method is called batch computation.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
batch computation
\end_layout

\end_inset

 As jobs are executed, new metrics vectors 
\begin_inset Formula $\underline{m}$
\end_inset

 and measured execution times 
\begin_inset Formula $t$
\end_inset

 add more rows to the problem, so the computation required to update 
\begin_inset Formula $\underline{x}$
\end_inset

 would unboundedly increase over time.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/LLSP_Update.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Updating-LLSP"

\end_inset

Updating the Linear Least Squares Solution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Literature on numerical algorithms however offers updating solutions,
\begin_inset CommandInset citation
LatexCommand cite
key "Schwetlick:Numerics"

\end_inset

 preventing this unbounded growth: Given an upper triangular system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n\right)}$
\end_inset

, which solves a linear least square problem 
\begin_inset Formula $\bigl(M,\underline{t}\bigr)^{\left(n\right)}$
\end_inset

, a new job adds a new row to the metrics matrix and the vector of measured
 execution times.
 The resulting new problem is 
\begin_inset Formula $\bigl(M,\underline{t}\bigr)^{\left(n+1\right)}$
\end_inset

.
 The system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n+1\right)}$
\end_inset

 which solves this new problem can be calculated from the previous solution
 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n\right)}$
\end_inset

 and the newly added row alone, without the need for the entire 
\begin_inset Formula $\bigl(M,\underline{t}\bigr)^{\left(n\right)}$
\end_inset

: As shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Updating-LLSP"

\end_inset

, the new row is appended to 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n\right)}$
\end_inset

, shifting the previous values down one row.
 Givens rotations
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
givens rotation
\end_layout

\end_inset

 are applied to zero the subdiagonal elements, turning the matrix into upper
 triangular form again.
 The coefficients 
\begin_inset Formula $\underline{x}$
\end_inset

 are then solved by back-substitution in the resulting system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n+1\right)}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
A single Givens rotation
\end_layout

\end_inset

 is a rotation in a plane defined by two standard basis vectors.
 Regarding the linear least squares problem as a set of column vectors,
 the solution 
\begin_inset Formula $\underline{x}$
\end_inset

 describes a linear combination of the first 
\begin_inset Formula $l$
\end_inset

 vectors that approximates the execution times vector.
\end_layout

\begin_layout Standard
Rotating a matrix can align a selected vector with one of the basis vectors,
 zeroing one of its coordinates.
 Consequently, a Givens rotation can zero any matrix element other than
 diagonal elements.
 When zeroing the element at row 
\begin_inset Formula $i$
\end_inset

 and column 
\begin_inset Formula $j$
\end_inset

 (
\begin_inset Formula $i\neq j$
\end_inset

), only the rows 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 of the matrix change.
 Because we rotate in the plane defined by the 
\begin_inset Formula $i\mathrm{\text{’th}}$
\end_inset

 and 
\begin_inset Formula $j\mathrm{\text{’th}}$
\end_inset

 standard basis vector, all other coordinates remain the same, thus all
 other rows are unaffected.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Givens-Rotation"

\end_inset

 illustrates a single Givens rotation.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Givens_Rotation.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Givens-Rotation"

\end_inset

Effect of a Single Givens Rotation
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Subsequently applying Givens rotations to all subdiagonal elements transforms
 a matrix to its upper triangular form 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

, affording back-substitution calculation of 
\begin_inset Formula $\underline{x}$
\end_inset

.
 Because the 
\begin_inset Formula $l$
\end_inset

 metrics columns and the rightmost execution times column 
\begin_inset Formula $\underline{\hat{c}}$
\end_inset

 are transformed alike, the rotations are neutral to the linear least squares
 solution.
 The scalar in the lower right of 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

 contains the residual error as shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Structure-LLSP"

\end_inset

.
\end_layout

\begin_layout Standard
In summary, the estimator starts with an all-zero system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(0\right)}$
\end_inset

 and repeatedly adds new rows 
\begin_inset Formula $\bigl(\underline{m}_{j},t_{j}\bigr)$
\end_inset

 consisting of application-provided metrics 
\begin_inset Formula $\underline{m}_{j}$
\end_inset

 and measured execution times 
\begin_inset Formula $t_{j}$
\end_inset

 to the current system.
 Applying 
\begin_inset Formula $l+1$
\end_inset

 Givens rotations keeps the system in upper triangular form.
\begin_inset CommandInset citation
LatexCommand cite
key "Chambers:RegressionUpdating"

\end_inset

 With this updating estimator, only the current value of the constant-size
 system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

 needs to be stored, the ever-growing matrix 
\begin_inset Formula $M$
\end_inset

 and vector 
\begin_inset Formula $\underline{t}$
\end_inset

 need not be stored, because new rows are directly merged into 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

.
 The time complexity
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
time complexity
\end_layout

\end_inset

 is in 
\begin_inset Formula $\mathcal{O}\bigl(l^{2}\bigr)$
\end_inset

, because 
\begin_inset Formula $l+1$
\end_inset

 Givens rotations are applied, each affecting at most 
\begin_inset Formula $2\bigl(l+1\bigr)$
\end_inset

 nonzero matrix elements.
\end_layout

\begin_layout Section
Numerical Stability
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
As I gained practical experience with the described execution time estimator,
 I observed two numerical problems:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

inflexibility
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
inflexibility
\end_layout

\end_inset

 because of a large amount of previously trained values and
\end_layout

\begin_layout Itemize
instability
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
instability
\end_layout

\end_inset

 because of overfitting
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
overfitting
\end_layout

\end_inset

 to previously trained values.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Both problems are related, because they are instances of the same fundamental
 conflict: The estimator accumulates knowledge of past job executions and
 calculates a coefficient vector 
\begin_inset Formula $\underline{x}$
\end_inset

 that approximates this history well.
 However, our intention is to use the estimator as a predictor in a Model
 Predictive Control
\begin_inset CommandInset citation
LatexCommand cite
key "Maciejowski:ModelPredictiveControl"

\end_inset

 setup to direct scheduling.
 We want good approximations for future execution times; we actually do
 not care how well it models the past.
 Therefore, two independent heuristics dampen the influence of the past
 to mitigate the two problems mentioned.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The increasing inflexibility
\end_layout

\end_inset

 stems from the estimator always considering all past jobs equally.
 The solution closes in on a global fit over the entire history and considers
 new information with decreasing significance.
 Because the workload metrics never cover the full complexity of the execution
 time fluctuations, the estimator should maintain a moving average fit,
 placing more emphasis on recent application behavior than on the distant
 past.
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 incorporates an 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
aging factor
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
aging factor
\end_layout

\end_inset

 
\begin_inset Formula $a$
\end_inset

 in the updating predictor.
 Before adding a new row 
\begin_inset Formula $\bigl(\underline{m}_{j},t_{j}\bigr)$
\end_inset

 to the predictor, the current system is multiplied with a scalar factor
 
\begin_inset Formula $1-a$
\end_inset

.
 This factor downscales the complete system and is therefore neutral to
 the solution.
\begin_inset Foot
status open

\begin_layout Plain Layout
The alternative implementation of emphasizing the new row with a scalar
 factor 
\begin_inset Formula $1+a$
\end_inset

 is not stable, because it causes unbounded growth of the matrix elements.
\end_layout

\end_inset

 It reduces the influence of the previous knowledge and allows the solution
 to remain flexible and lean towards the newly acquired row.
 The scalar multiplication has a time complexity of 
\begin_inset Formula $\mathcal{O}\bigl(l^{2}\bigr)$
\end_inset

, so the aging factor approach does not increase the complexity of the update
 step.
\end_layout

\begin_layout Standard
The aging factor is the first tunable parameter of the predictor.
 It adjusts the relative weight of past knowledge against new information.
 Because any past behavior of the application may resurface, I argue that
 the aging effect should be small and only allow for slow adaptation in
 a long-term moving average style.
 I use a value of 
\begin_inset Formula $a=0.01$
\end_inset

 and I experiment with different factors in a video decoding case study
 below.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Overfitting
\end_layout

\end_inset

 occurs when the linear least squares problem contains redundant metrics.
 These metrics can show unsystematic correlation with previously trained
 values and skew the resulting coefficients.
 Such a solution models past values better than a solution without redundancies,
 but it generates unstable predictions for future behavior.
\end_layout

\begin_layout Standard
An example helps to understand this effect: Two jobs are submitted with
 two metrics each: 
\begin_inset Formula $\left(1,1\right)$
\end_inset

 for the first job and 
\begin_inset Formula $\left(3,3.00001\right)$
\end_inset

 for the second job.
 The two metrics strongly correlate, so one of them can be considered redundant.
 The measured execution times are 
\begin_inset Formula $1$
\end_inset

 for the first job and 
\begin_inset Formula $3.01$
\end_inset

 for the second job.
 Intuitively, the execution time appears to follow both metrics with some
 small error.
 We should ignore one of the redundant metrics and use the other for prediction.
 But mathematically, we solve the following system of equations:
\begin_inset Formula 
\[
\begin{array}{ccccc}
x_{1} & + & x_{2} & = & 1\\
3x_{1} & + & 3.00001x_{2} & = & 3.01
\end{array}
\]

\end_inset

The solution is 
\begin_inset Formula $x_{1}=-999,\: x_{2}=1000$
\end_inset

.
 For a next job with the metrics 
\begin_inset Formula $\left(1,1.01\right)$
\end_inset

, we would intuitively expect a prediction around 
\begin_inset Formula $1$
\end_inset

, but the calculated coefficients say 
\begin_inset Formula $11$
\end_inset

, an unstable prediction due to overfitting.
\end_layout

\begin_layout Standard
I approached this problem before
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Beleg"

\end_inset

 and devised a strategy based on dropping redundant metrics before solving
 the reduced system.
 This method however operates offline with full knowledge of the complete
 linear least squares problem 
\begin_inset Formula $\bigl(M,\underline{t}\bigr)$
\end_inset

.
 
\noun on
Atlas
\noun default
’ updating predictor requires online stabilization and only has access to
 the aggregated upper triangular 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

 system.
 I independently developed a solution, which turned out to be similar to
 subset regression algorithms from statistics literature.
\begin_inset CommandInset citation
LatexCommand cite
key "Clarke:SubsetRegression"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The online metrics dropping algorithm
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
metrics dropping
\end_layout

\end_inset

runs in two phases: At first, it scans all metrics to figure out which are
 significant for the result and which are redundant.
 It then reorganizes the current 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

 so a reduced result 
\begin_inset Formula $\underline{\tilde{x}}$
\end_inset

 can be calculated, which ignores the redundant metrics and is based only
 on the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
stable subset
\end_layout

\end_inset

.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
stable subset
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The scan for redundant metrics successively drops the rightmost metrics
 column and recalculates the residual error 
\begin_inset Formula $c_{R}$
\end_inset

.
 Because of the nature of a linear least squares solution, the residual
 error increases with each dropped column.
 However, a metric that does not contribute significantly will cause only
 a minor increase of the residual error.
 The predictor therefore considers a metric redundant, if its contribution
 increases 
\begin_inset Formula $c_{R}$
\end_inset

 by less than 
\begin_inset Formula $10\%$
\end_inset

.
 This 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
column contribution threshold
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
column contribution threshold
\end_layout

\end_inset

 is the second tunable parameter of the predictor.
 It allows trading prediction accuracy for better stability.
 I evaluate different thresholds in the video decoding case study below.
\end_layout

\begin_layout Standard
Because the rightmost column of 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

 always represents the measured execution times, dropping the rightmost
 metric means dropping the second column from the right.
 As Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Dropping-a-Column"

\end_inset

 shows, readjusting the matrix to upper triangular form requires only one
 Givens rotation, which changes just a single matrix element: the new residual
 error after dropping the column.
 The old residual error is zeroed by the Givens rotation.
 The implementation thus only touches the rightmost column when successively
 calculating the individual column contributions.
 Scanning through all metrics in this fashion applies 
\begin_inset Formula $l$
\end_inset

 Givens rotations, each affecting one element.
 The time complexity of this step is 
\begin_inset Formula $\mathcal{O}\bigl(l\bigr)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/LLSP_Drop.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Dropping-a-Column"

\end_inset

Dropping a Column to Determine Error Contribution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Dropping all of the metrics degenerates the matrix to a scalar value equivalent
 to the standard deviation of the measured execution times, the upper bound
 for the residual error of the linear least square solution.
 The complete scan yields a series of non-decreasing residual error values
 as illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Residual-Error"

\end_inset

.
 Metrics that only cause a sub-threshold increase in the residual error
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

like metrics two and five in the figure
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

are considered redundant and dropped in the second phase.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Residual_Error_Scan.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Residual-Error"

\end_inset

Residual Error When Dropping Columns
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
After the scan step,
\end_layout

\end_inset

 the predictor drops metrics that contribute below threshold.
 As we have seen, dropping from the right of the matrix is computationally
 lightweight.
 Therefore, the algorithm reorders the matrix by moving all to-be-dropped
 columns to the right.
 The column representing the measured execution times must stay in place,
 so all moves happen within the metrics columns.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/LLSP_Move.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Moving-a-Column"

\end_inset

Moving a To-Be-Dropped Column to the Right
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
An individual move operation pulls a column from its previous position and
 reinserts it further right.
 The first such move reinserts the column as the new rightmost metrics column.
 Any subsequent move reinserts the column left of the previously moved drop-colu
mn.
 After every move, the subdiagonal elements are zeroed with Givens rotations
 as shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Moving-a-Column"

\end_inset

, keeping the matrix in upper triangular form.
 The resulting matrix is not a temporary result, but actually replaces the
 previous system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n\right)}$
\end_inset

 and becomes the new 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)^{\left(n+1\right)}$
\end_inset

.
 The predictor remembers the column permutation, because new rows that are
 added to the system and solution coefficients derived from it must be equally
 permuted.
\end_layout

\begin_layout Standard
The worst-case time complexity of this reorganization is 
\begin_inset Formula $\mathcal{O}\bigl(l^{3}\bigr)$
\end_inset

: Imagine a matrix, where the left half of the metrics columns are to be
 dropped and the right half are to be kept.
 We will move 
\begin_inset Formula $\nicefrac{l}{2}$
\end_inset

 columns and for each move apply 
\begin_inset Formula $\nicefrac{l}{2}$
\end_inset

 Givens rotations, each affecting up to 
\begin_inset Formula $l+1$
\end_inset

 elements.
 However, the state of an individual column hopefully does not oscillate
 wildly between keeping and dropping.
 The video decoding case study shows that the column selection settles,
 which reduces the average case time complexity.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/3-Real-Time/LLSP_Reduced.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Reduced-Solution"

\end_inset

Reduced Solution with Three out of Five Metrics
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the new system 
\begin_inset Formula $\bigl(\hat{R},\underline{\hat{c}}\bigr)$
\end_inset

, all drop-columns are grouped together in a single run on the right-hand
 side of the matrix, followed only by the execution times column.
 A reduced solution 
\begin_inset Formula $\underline{\tilde{x}}$
\end_inset

 can now be calculated by performing back-substitution in a reduced system,
 where the dropped columns are removed and a matching number of rows are
 deleted from the bottom end of the system.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Reduced-Solution"

\end_inset

 visualizes such a reduced system.
 The solution 
\begin_inset Formula $\underline{\tilde{x}}$
\end_inset

 stems from the subset of significant metrics, so it is expected to produce
 a more stable prediction.
 The following case study examines and confirms this proposition.
\end_layout

\begin_layout Section
Case Study: Video Decoding
\end_layout

\begin_layout Standard
After the mathematical rundown of execution time prediction, I want to take
 a look at the bigger picture: How would a developer with specific knowledge
 in his application domain
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
domain knowledge
\end_layout

\end_inset

 adopt 
\noun on
Atlas
\noun default
? I continue using video playback as the example, because it is a highly
 dynamic workload that is challenging to estimate.
\begin_inset Foot
status open

\begin_layout Plain Layout
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "1-fig:Total-and-Zoomed"

\end_inset

 illustrates the variability of video decoding times.
 More examples follow later in this section.
\end_layout

\end_inset

 The case study provides a better understanding of the workload metrics
 and the behavior of the estimator.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
In the following discussion,
\end_layout

\end_inset

 we assume the role of a developer, who is familiar with the problem domain
 of the application, in this case video playback.
 Such knowledge is helpful to formulate the timing requirements and to come
 up with good candidate metrics for the execution time prediction.
\end_layout

\begin_layout Standard
For a video player, the time constraint is rather obvious: frames should
 complete decoding and display until a time instant dictated by video metadata,
 commonly a fixed frame rate.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
frame rate
\end_layout

\end_inset

 Although variable frame-rate video is possible,
\begin_inset Foot
status open

\begin_layout Plain Layout
Today’s video formats like the MPEG-
\begin_inset Formula $4$
\end_inset

 family support individual presentation time stamps (PTS) for each frame.
 This can improve compression efficiency for certain source material, for
 example cel-animated content.
\end_layout

\end_inset

 I limit this case study to constant frame rates.
\end_layout

\begin_layout Standard
I assume the video player has already adopted the asynchronous lambda style
 using GCD.
 I outlined the necessary changes to FFplay in the previous chapter 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand nameref
reference "2-chap:Anatomy"

\end_inset


\end_layout

\end_inset

.
 Employing 
\noun on
Atlas
\noun default
 is easiest when using the interface with the highest abstraction level:
 the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_async_atlas
\end_layout

\end_inset


\end_layout

\end_inset

 extension to GCD attaches deadlines and workload metrics to code blocks.
 Should the application structure demand it, direct access to the lower-level
 primitives of the estimator and scheduler is also possible.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="7">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="2.3cm">
<column alignment="left" valignment="top" width="4cm">
<column alignment="right" valignment="top" width="0pt">
<column alignment="right" valignment="top" width="0">
<column alignment="right" valignment="top" width="0">
<column alignment="left" valignment="top" width="0">
<column alignment="left" valignment="top" width="2.2cm">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Video (Source)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Content
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Resolution
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FPS
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Length
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Profile
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Encoding
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Black Swan (
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Apple Trailers"
target "http://trailers.apple.com/trailers/fox_searchlight/blackswan/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
movie trailer for “Black
\begin_inset space ~
\end_inset

Swan” (2010)
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $848\!\!\times\!\!352$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $24$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $126\,\mathrm{s}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Baseline
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x264, CBR, 
\begin_inset Formula $1500\,\mathrm{kbit/s}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Shore
\begin_inset Newline newline
\end_inset

(
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "FastVDO"
target "http://www.fastvdo.com/H.264.html"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
flight over a shoreline at dawn
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $740\!\!\times\!\!576$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $25$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $27\,\mathrm{s}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
High
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FastVDO
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Park Run
\begin_inset Newline newline
\end_inset

(
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Xiph Test Clip"
target "http://media.xiph.org/video/derf/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
man running in a park with trees, snow and water
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1280\!\!\times\!\!720$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $50$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10\,\mathrm{s}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
High
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x264, CBR, 
\begin_inset Formula $4\,\mathrm{Mbit/s}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Rush Hour
\begin_inset Newline newline
\end_inset

(
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Xiph Test Clip"
target "http://media.xiph.org/video/derf/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rush-hour in downtown Munich with heat haze
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1920\!\!\times\!\!1080$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $25$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $20\,\mathrm{s}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Main
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x264, CRF, rate
\begin_inset space ~
\end_inset

factor
\begin_inset space ~
\end_inset

23
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hunger Games
\begin_inset Newline newline
\end_inset

(
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Apple Trailers"
target "http://trailers.apple.com/trailers/lions_gate/thehungergames/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
movie trailer for “The Hunger
\begin_inset space ~
\end_inset

Games” (2012)
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1920\!\!\times\!\!816$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $24$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $155\,\mathrm{s}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
High
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x264, CRF, rate
\begin_inset space ~
\end_inset

factor
\begin_inset space ~
\end_inset

23
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace 15pt
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-tab:Test-Clips"

\end_inset

Properties of Test Videos for Experiments
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
To demonstrate the metrics selection,
\end_layout

\end_inset

 I selected the five demo videos in Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-tab:Test-Clips"

\end_inset

.
 They cover a typical range of resolutions, given in pixels, frame rates,
 given as frames per second (FPS), and coding profiles
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
coding profiles
\end_layout

\end_inset

, which declare a set of decoder features required by the video.
 I experiment with the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264
\end_layout

\end_inset

 video decoding standard,
\begin_inset CommandInset citation
LatexCommand cite
key "Wiegand:H264"

\end_inset

 because it is widely deployed and powers the majority of modern media applicati
ons from mobile video to HD and 
\begin_inset Formula $3\mathrm{D}$
\end_inset


\begin_inset space ~
\end_inset

Blu-ray discs.
 All test videos but one have been encoded by me with the x264
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
x264
\end_layout

\end_inset

 encoder.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "x264"
target "http://www.videolan.org/developers/x264.html"

\end_inset


\end_layout

\end_inset

 is a highly competitive open-source 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 encoder.
 At the time of this writing, it has won the previous six installments of
 the Annual MSU 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Video Codec Comparison"
target "http://www.compression.ru/video/codec_comparison/h264_2012/"

\end_inset

.
\end_layout

\end_inset

 The x264 version used here is git commit
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "37be5521"
target "http://git.videolan.org/?p=x264.git;a=tree;h=853628a3c38c6bc06b049ff9c74dc33c7f2a317f;hb=37be55213a39db40cf159ada319bd482a1b00680"

\end_inset


\end_layout

\end_inset

 from July 2012.
\end_layout

\end_inset

 The Shore video was encoded by the manufacturer of the commercial FastVDO
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
FastVDO
\end_layout

\end_inset

 encoder.
 I ignore audio, because its computational load is two orders of magnitude
 smaller than video decoding and its timing requirements are less strict,
 because the audio hardware takes care of sample buffering and timely output.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\begin_inset Graphics
	filename Data/3-Real-Time/CPU_Load_Player.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Relative-Time-Player"

\end_inset

Relative Execution Time of the Player Stages
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Video decoding
\end_layout

\end_inset

 is the biggest spender of CPU time during playback, as shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Relative-Time-Player"

\end_inset

.
 Therefore, an accurate prediction of the decoder jobs is vital for informed
 planning by the scheduler.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Decoding-Times"

\end_inset

 provides an overview of the decoding time per video frame, illustrating
 the variability within and across the test clips.
 However, when we run the same video twice, Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Decoding-Times-Repeat"

\end_inset

 demonstrates that decoding times of the two runs are strongly correlated,
 with a Pearson correlation of 
\begin_inset Formula $\DecodeRepeatCorrelation$
\end_inset

.
\end_layout

\begin_layout Standard
We conclude that the high variability of video decoding times does not stem
 from random influences, but is determined by the input data.
 This is not surprising given that modern video compression standards like
 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 have a bitstream format so complex we can consider it a domain-specific
 language to describe video frames.
 The video decoder is then a special-purpose interpreter for this language
 whose execution time inherently depends on the video bitstream
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
video bitstream
\end_layout

\end_inset

 it is processing.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Decoding_Times.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace -8pt
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Decoding-Times"

\end_inset

Decoding Time Behavior of Test Videos
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Decoding_Times_Repeat.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace -8pt
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Decoding-Times-Repeat"

\end_inset

Decoding Times of a Repeat Run
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
As a developer trying to benefit from 
\noun on
Atlas
\noun default
, a key obligation is to find workload metrics
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

 that allow the estimator to derive good predictions of the decoding time
 spent per frame.
 Intuitively, each metric should grow linearly with part of the computation.
 For example, if the computation involves a loop, the number of iterations
 is a good metric candidate.
 In the video case, the metrics should be acquired from the bitstream, because
 the decoding times strongly depend on the video and because the predictor
 needs access to the metrics of a frame before decoding begins.
 Metrics only available after decoding has finished are not helpful for
 prediction.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
To determine candidate metrics
\end_layout

\end_inset

 we need inside knowledge of the decoding process.
 I developed and published an approach for earlier video standards,
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Predict"

\end_inset

 which I subsequently also applied to 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264.
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Balancing"

\end_inset

 The method divides the decoding work into smaller steps that are easier
 to examine individually.
 I summarize the line of thought in the following paragraphs.
 Text may have been copied verbatim from the two mentioned papers.
\end_layout

\begin_layout Standard
First, we need an overview of the decoding steps and how they fit together.
 A domain expert knows that the building blocks connect as shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Decoder-Components"

\end_inset

.
 The entire chain of components executes once per frame.
 An inner loop iterates over the macroblocks within a frame.
 A macroblock
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
macroblock
\end_layout

\end_inset

 is a 16
\begin_inset Formula $\times$
\end_inset

16 pixel image tile that is stored consecutively in the bitstream.
 To form the final video frame the decoder arranges the macroblocks in raster
 scan order and applies post processing.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Decoder_Components.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
Decoding Steps
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "3-fig:Decoder-Components"

\end_inset

Decoding Steps
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

The numbering matches the description in the text.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace 3cm
\end_inset


\begin_inset Graphics
	filename Data/3-Real-Time/Times_Relative.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Relative-Time-Steps"

\end_inset

Relative Execution Time of the Decoding Steps
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Relative-Time-Steps"

\end_inset

 visualizes the relative weight of the execution times spent in the decoding
 steps.
 We observe that decompression and temporal prediction are the two heaviest
 contributors, followed by post processing.
 It is therefore most important to find highly correlating metrics for these
 parts.
 I now visit each decoding step and illustrate how a domain expert selects
 appropriate workload metrics.
 A detailed correlation breakdown follows after the discussion.
\end_layout

\begin_layout Enumerate
Bitstream Parsing
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
bitstream parsing
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nopagebreak 
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

The decoder reads and parses the bitstream representing the next frame and
 processes header information to prepare the following steps.
 The parsing effort scans the input data, so it obviously depends on the
 bitstream length of the compressed frame.
 In addition, each output pixel is represented in the bitstream and processed
 by the downstream steps, so the number of pixels in the final frame is
 another candidate metric.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Metrics-Parsing"

\end_inset

 shows that a linear fit of the per-frame pixel and bit counts sufficiently
 matches the execution time of the bitstream parsing step.
 Remember that this step accounts for a small fraction of total decoding
 time.
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Key.pdf

\end_inset


\end_layout

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Parsing.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Metrics-Parsing"

\end_inset

Metrics for Bitstream Parsing
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Decompression
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
decompression
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nopagebreak 
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 offers two different entropy coding schemes: the faster CAVLC
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
CAVLC
\end_layout

\end_inset


\end_layout

\end_inset

 and the more efficient CABAC,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
CABAC
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Marpe:CABAC"

\end_inset

 the latter is only available in the Main and High codec profiles.
 The decompression step operates on the bitstream to expand the payload
 and obtain the macroblock data.
 Thus, the bit count correlates with this step’s execution time as Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Metrics-Decompression"

\end_inset

 illustrates.
 Fortunately the match is visually tight, as this step is responsible for
 a large share of the overall decoding time.
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Decompression.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Metrics-Decompression"

\end_inset

Metrics for Decompression
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Spatial Prediction
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
spatial prediction
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nopagebreak 
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

The two prediction steps try to algorithmically fill the current macroblock
 by extrapolating from already decoded pixels of either the same frame or
 a previous frame.
 The bitstream only stores the residual error between prediction and actual
 image.
 Spatial prediction takes patterns from decoded pixels of the same frame
 and bleeds them into the area of the current macroblock.
 This process can use sub-block sizes of 4
\begin_inset Formula $\times$
\end_inset

4, 8
\begin_inset Formula $\times$
\end_inset

8, or 16
\begin_inset Formula $\times$
\end_inset

16 pixels, so we separately count occurrences of these block sizes.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Metrics-Spatial"

\end_inset

 demonstrates that a linear fit of those counts adequately matches the execution
 time.
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Spatial.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Metrics-Spatial"

\end_inset

Metrics for Spatial Prediction
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Temporal Prediction
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
temporal prediction
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nopagebreak 
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

This step is the second big contributor to the total decoding time.
 It extrapolates from previously decoded frames, called reference frames,
 compensating for any motion by shifting image content along a motion vector.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
motion vector
\end_layout

\end_inset

 Finding good metrics for this step is difficult, because its execution
 is exceptionally diverse.
 Not only can motion compensation operate with square and rectangular sub-blocks
 of different sizes, each block can also be shifted by a motion vector of
 full, half or quarter pixel accuracy.
 In addition, bi-predicted macroblocks target two reference frames.
 They employ two motion vectors for each sub-block and can apply arbitrary
 weighting factors to the contributions.
 The key idea to untangle these options is to count memory accesses to the
 reference frames.
 The filter operations for full, half and quarter pixel vectors read different
 amounts of reference pixels.
 Treating bi-predicted blocks as two blocks and rectangular sub-blocks as
 two smaller square blocks, we count reference pixel accesses for three
 sub-block sizes: 4
\begin_inset Formula $\times$
\end_inset

4, 8
\begin_inset Formula $\times$
\end_inset

8, and 16
\begin_inset Formula $\times$
\end_inset

16.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-mar:Metrics-Temporal"

\end_inset

 shows the resulting fit.
\end_layout

\begin_layout Enumerate
Inverse Transform
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
inverse transform
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nopagebreak 
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

For spatially or temporally predicted macroblocks, this step compensates
 the residual error between the prediction and the actual image.
 For self-contained macroblocks, the bitstream stores the image data directly.
 To exploit visual redundancy, the bitstream keeps all image data in a DCT-like
\begin_inset CommandInset citation
LatexCommand cite
key "Ahmed:DCT"

\end_inset

 two-dimensional frequency domain, which this decoding step transforms to
 the pixel domain.
 The transform can operate on two sub-block sizes of 4
\begin_inset Formula $\times$
\end_inset

4 and 8
\begin_inset Formula $\times$
\end_inset

8.
 Alternatively, a PCM encoding is available, where the bitstream contains
 the macroblock in a spatial encoding that does not need to be transformed.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Metrics-Transform"

\end_inset

 illustrates how the sub-block occurrence counts fit execution time.
 The remaining imprecision is inconsequential, because this step has a small
 influence on overall decoding time.
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Key.pdf

\end_inset


\end_layout

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Temporal.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Metrics-Temporal"

\end_inset

Metrics for Temporal Prediction
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Transform.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Metrics-Transform"

\end_inset

Metrics for Inverse Transform
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Post Processing
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
post processing
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nopagebreak 
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

The mandatory
\begin_inset Foot
status open

\begin_layout Plain Layout
Post processing was optional with previous MPEG-
\begin_inset Formula $4$
\end_inset

 coding standards.
 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 uses an in-loop deblocking filter that cannot be skipped.
\end_layout

\end_inset

 post processing step tries to reduce block artifacts by selective blurring
 of macroblock edges.
 Counting the number of treated edges results in the fit displayed in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Metrics-Post"

\end_inset

.
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Metrics_Post.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Metrics-Post"

\end_inset

Metrics for Post Processing
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
In summary, we have identified the following set of candidate metrics:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

number of pixels per frame
\end_layout

\begin_layout Itemize
number of CABAC-compressed bits
\end_layout

\begin_layout Itemize
number of CAVLC-compressed bits
\end_layout

\begin_layout Itemize
number of spatial sub-blocks of size 4
\begin_inset Formula $\times$
\end_inset

4
\end_layout

\begin_layout Itemize
number of spatial sub-blocks of size 8
\begin_inset Formula $\times$
\end_inset

8
\end_layout

\begin_layout Itemize
number of spatial sub-blocks of size 16
\begin_inset Formula $\times$
\end_inset

16
\end_layout

\begin_layout Itemize
reference frame accesses for temporal sub-blocks of size 4
\begin_inset Formula $\times$
\end_inset

4
\end_layout

\begin_layout Itemize
reference frame accesses for temporal sub-blocks of size 8
\begin_inset Formula $\times$
\end_inset

8
\end_layout

\begin_layout Itemize
reference frame accesses for temporal sub-blocks of size 16
\begin_inset Formula $\times$
\end_inset

16
\end_layout

\begin_layout Itemize
number of PCM-encoded macroblocks
\end_layout

\begin_layout Itemize
number of block transforms of size 4
\begin_inset Formula $\times$
\end_inset

4
\end_layout

\begin_layout Itemize
number of block transforms of size 8
\begin_inset Formula $\times$
\end_inset

8
\end_layout

\begin_layout Itemize
number of deblocked edges
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
To judge the quality of the selected metrics, Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-tab:Metrics-Correlation"

\end_inset

 analyses the Pearson correlation of the metrics with the measured execution
 times for each frame over all test videos.
 The table lists the decoding steps and their relative share of total decoding
 time.
 The selected metrics regression calculates a fit of the metrics we identified
 as reasonable for the respective step.
 This column numerically presents the correlation we have visually examined
 in the previous figures.
 The rightmost column regresses all thirteen metrics against the individual
 decoding steps and also the total decoding time per frame.
 As expected, the fit correlates better when more metrics are considered.
\end_layout

\begin_layout Standard
The tight correlation with the decoding time for complete frames proves
 that the metrics are well-chosen.
 However, the regression so far relies on perfect a-priori knowledge of
 all metrics and decoding times.
 The predictor in our video player however has to learn this information
 while the video is playing.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset CommandInset include
LatexCommand input
filename "Data/3-Real-Time/Metrics_Correlation.lyx"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-tab:Metrics-Correlation"

\end_inset

Pearson Correlation of Metrics Fitted to Per-Frame Execution Times
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
After analyzing the most time consuming player component in detail, I now
 explain how these insights practically apply to FFplay.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The video playback pipeline
\end_layout

\end_inset

 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
video playback
\end_layout

\end_inset

consists of three stages: the input stage reads the compressed video from
 disk, the decoder stage converts it to frames, which the output stage displays.
 These stages are connected by queues
\begin_inset Foot
status open

\begin_layout Plain Layout
These queues contain application data and should not be confused with GCD’s
 work queues.
\end_layout

\end_inset

 with a limited number of slots where elements wait for processing by the
 next stage.
\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:FFplay-Stage-Structure"

\end_inset

 shows one possible queue situation: the current length of the video queue
 
\begin_inset Formula $n_{video}$
\end_inset

 is three, the picture queue holds 
\begin_inset Formula $n_{picture}=1$
\end_inset

 decoded frame.
 FFplay’s default setup uses a five-slot video queue and a two-slot picture
 queue.
 The idea of these queues is to compensate for heavyweight frames which
 need more execution time in a stage than the frame interval allows.
 We therefore try to keep the queues filled by calculating deadlines accordingly.
 Remember that all 
\noun on
Atlas
\noun default
 deadlines are absolute deadlines.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To model how the pipeline advances, consider a situation where all queues
 are filled.
 Whenever the currently displayed frame expires, the next frame to show
 is taken from the picture queue.
 This free slot unblocks the decoder which can now enqueue a decoded frame
 and consume one packet of video bitstream from the video queue, thereby
 unblocking the input stage.
\end_layout

\begin_layout Standard
Our simple model of the pipeline progression therefore rests upon the absolute
 presentation time 
\begin_inset Formula $t_{frame}$
\end_inset

 of the currently displayed frame and the time interval 
\begin_inset Formula $\Delta_{frame}$
\end_inset

 between two consecutive frames.
 The former is available in the 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
frame_timer
\end_layout

\end_inset

 variable in FFplay.
 The latter is determined by the video frame rate,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
frame rate
\end_layout

\end_inset

 which dictates how long each frame shows up on screen.
 For simplicity, we assume that the queues advance by one frame in every
 
\begin_inset Formula $\Delta_{frame}$
\end_inset

 interval.
\end_layout

\begin_layout Standard
With these prerequisites, I modified the stages of FFplay as follows to
 enable 
\noun on
Atlas
\noun default
 scheduling:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/FFplay_Stages.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:FFplay-Stage-Structure"

\end_inset

FFplay Stage Structure
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

input
\begin_inset space \space{}
\end_inset

stage
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
input stage
\end_layout

\end_inset

 continuously reads packets off the video file from disk and enqueues them
 into the video queue.
 Thus, the input stage must submit new 
\noun on
Atlas
\noun default
 jobs for itself to read the next video packet and for the decoder stage
 to process the packets.
 The input stage needs a free slot on the video queue to proceed, so we
 set 
\begin_inset Formula $t_{frame}+\Delta_{frame}$
\end_inset

 as absolute deadline for the submitted input job.
\end_layout

\begin_deeper
\begin_layout Standard
The video packet associated with the decoder job first travels through the
 video queue and begins decoding after advancing 
\begin_inset Formula $n_{video}$
\end_inset

 slots.
 The decoder stage then requires one free slot on the picture queue.
 Thus, we establish 
\begin_inset Formula $t_{frame}+(n_{video}+1)\Delta_{frame}$
\end_inset

 as the deadline of the decoder job.
 However, because we enqueue the packet before submitting the job, the video
 queue is already extended to 
\begin_inset Formula $n_{video}'=n_{video}+1$
\end_inset

, so the deadline is actually set to 
\begin_inset Formula $t_{frame}+n_{video}'\Delta_{frame}$
\end_inset

.
\end_layout

\begin_layout Standard
Due to their small execution time relative to decoding, no metrics are supplied
 to the 
\noun on
Atlas
\noun default
 estimator for the input jobs.
 The decoder jobs carry the thirteen metrics discussed above, which the
 input stage obtains by parsing the video bitstream.
 Below, I evaluate design alternatives for the metrics and their extraction
 and the consequences for prediction accuracy.
\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:FFplay-Input-Stage"

\end_inset

 shows a pseudo-code representation of the input stage with 
\noun on
Atlas
\noun default
 modifications on top of the asynchronous lambda version.
 Remember that 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_async_atlas
\end_layout

\end_inset


\end_layout

\end_inset

 sends a new block
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset

 to the dispatch queue
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
dispatch queue
\end_layout

\end_inset

 designated by the first argument and also informs the scheduler about this
 new work by submitting the job
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
job
\end_layout

\end_inset

 given in the second argument.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void input_stage() {
\end_layout

\begin_layout Plain Layout

	/* instruct input stage to read next packet after this one */
\end_layout

\begin_layout Plain Layout

	atlas_job_t input_job = {
\end_layout

\begin_layout Plain Layout

		.deadline = frame_timer + frame_interval,
\end_layout

\begin_layout Plain Layout

		.metrics_count = 0,
\end_layout

\begin_layout Plain Layout

		.metrics = NULL
\end_layout

\begin_layout Plain Layout

	};
\end_layout

\begin_layout Plain Layout

	dispatch_async_atlas(input_queue, input_job, ^{ input_stage(); });
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	packet = read_input();
\end_layout

\begin_layout Plain Layout

	enqueue(video_queue, packet);
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	/* instruct decoder stage to process the video packet */
\end_layout

\begin_layout Plain Layout

	atlas_job_t decoder_job = {
\end_layout

\begin_layout Plain Layout

		.deadline = frame_timer + video_queue->length * frame_interval,
\end_layout

\begin_layout Plain Layout

		.metrics_count = 13,
\end_layout

\begin_layout Plain Layout

		.metrics = extract_metrics(packet)
\end_layout

\begin_layout Plain Layout

	};
\end_layout

\begin_layout Plain Layout

	dispatch_async_atlas(decoder_queue, decoder_job, ^{ decoder_stage(); });
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:FFplay-Input-Stage"

\end_inset

FFplay Input Stage Using the 
\noun on
Atlas
\noun default
 Interface
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

decoder
\begin_inset space \space{}
\end_inset

stage
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
decoder stage
\end_layout

\end_inset

 consumes compressed packets from the video queue, decodes them and places
 the finished frames onto the picture queue.
 A newly enqueued frame has to wait for the currently displayed frame to
 expire and for the 
\begin_inset Formula $n_{picture}$
\end_inset

 frames preceding it in the picture queue.
 Thus, its output stage invocation receives a deadline of 
\begin_inset Formula $t_{frame}+(n_{picture}+1)\Delta_{frame}$
\end_inset

.
 Again, enqueueing the frame before submitting the job increases the length
 of the picture queue to 
\begin_inset Formula $n_{picture}'=n_{picture}+1$
\end_inset

, resulting in an actual deadline of 
\begin_inset Formula $t_{frame}+n_{picture}'\Delta_{frame}$
\end_inset

.
 Because of the insignificant execution time of the output stage, the estimator
 receives no metrics.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:FFplay-Decoder-Stage"

\end_inset

 lists the resulting pseudo-code.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void decoder_stage() {
\end_layout

\begin_layout Plain Layout

	packet = dequeue(video_queue);
\end_layout

\begin_layout Plain Layout

	frame = decode(packet);
\end_layout

\begin_layout Plain Layout

	enqueue(picture_queue, frame);
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	/* instruct output stage to display the frame */
\end_layout

\begin_layout Plain Layout

	atlas_job_t output_job = {
\end_layout

\begin_layout Plain Layout

		.deadline = frame_timer + picture_queue->length * frame_interval,
\end_layout

\begin_layout Plain Layout

		.metrics_count = 0,
\end_layout

\begin_layout Plain Layout

		.metrics = NULL
\end_layout

\begin_layout Plain Layout

	};
\end_layout

\begin_layout Plain Layout

	dispatch_async_atlas(output_queue, output_job, ^{ output_stage(); });
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:FFplay-Decoder-Stage"

\end_inset

FFplay Decoder Stage Using the 
\noun on
Atlas
\noun default
 Interface
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

output
\begin_inset space \space{}
\end_inset

stage
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
output stage
\end_layout

\end_inset

 at the end of the video player pipeline finally displays the frames.
 It does not issue any new work and therefore remains unmodified.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
With these modifications
\end_layout

\end_inset

 to FFplay, any block submitted to any GCD
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
grand central dispatch
\end_layout

\end_inset

 queue is backed by an 
\noun on
Atlas
\noun default
 job and therefore real-time scheduled.
 On top of the changes discussed in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-chap:Anatomy"

\end_inset

 to enable asynchronous lambdas, the 
\noun on
Atlas
\noun default
 adoption touches 33
\begin_inset space ~
\end_inset

lines, less than 
\begin_inset Formula $2\%$
\end_inset

 of 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
ffplay.c
\end_layout

\end_inset


\end_layout

\end_inset

.
 The modifications are straightforward for a developer familiar with the
 codebase.
 The FFmpeg libraries remain unchanged.
\end_layout

\begin_layout Standard
Note that the application workload dictates only the final display deadline
 of the frames.
 Considering the application structure we manually inferred the intermediate
 deadlines to make maximum use of the queues, ensuring that later stages
 operate without being delayed.
 When I evaluate the overall scheduling behavior of 
\noun on
Atlas
\noun default
, I include results with later intermediate deadlines, allowing the queues
 to deplete in high load situations.
 
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Tease the (hopefully positive) result here.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Before evaluating the prediction quality of FFplay execution times, I want
 to bring up the following implementation details:
\end_layout

\begin_layout Itemize
Because SDL limits calls to graphics functions to the main thread,
\begin_inset CommandInset citation
LatexCommand cite
key "SDL:MultipleThreads"

\end_inset

 the output stage contains two parts: the first part runs from the GCD output
 queue on a background thread and manages the timing of frame display, the
 second part runs on the main thread and puts the image on screen.
 Therefore, the decoder stage emits two 
\noun on
Atlas
\noun default
 jobs, one for each part of the output stage.
 I ignore this technicality to simplify the evaluation.
\end_layout

\begin_layout Itemize
Due to inter-frame referencing, the display order of video frames can be
 different from their stream order.
 The decoder stage of FFplay calls a frame decode function from FFmpeg’s
 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
libavcodec
\end_layout

\end_inset


\end_layout

\end_inset

, which handles frame reordering in an internal pipeline.
 There are pipeline ramp-up and ramp-down effects at the beginning and end
 of a video, but in its steady state, the decoder emits one decoded frame
 for each delivered bitstream packet.
\end_layout

\begin_layout Itemize
As a consequence of absolute deadlines the application and the kernel scheduler
 must agree on a common time reference.
 
\noun on
Atlas
\noun default
 uses the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
CLOCK_MONOTONIC
\end_layout

\end_inset


\end_layout

\end_inset

 facility which is available on Linux as part of the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
clock_gettime
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Unix:Clock_Gettime"

\end_inset

 system call.
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
system call
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
On 64-bit Linux, 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
clock_gettime
\end_layout

\end_inset


\end_layout

\end_inset

 does not transition into the kernel, but executes in user space thanks
 to the 
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "kernel’s vDSO facility"
target "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/plain/Documentation/ABI/stable/vdso?id=28a33cbc24e4256c143dce96c7d93bf423229f92"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset

 One second elapsing on this clock
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
clock
\end_layout

\end_inset

 always corresponds to one second in physical reality.
 The clock offers nanosecond granularity and is unaffected by clock adjustments,
 leap seconds or time zone changes.
 The starting point is at an unspecified time in the past, so the clock
 does not bear a meaningful relation to wallclock time.
 This limitation is unproblematic for the intended use.
\end_layout

\begin_layout Itemize
Training the predictor requires measuring the execution time of individual
 jobs.
 However, simply subtracting the job’s release time from its completion
 time calculates the makespan instead of the execution time, the difference
 being interruptions due to blocking or preemption.
 To measure time spent within a job, 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
clock_gettime
\end_layout

\end_inset


\end_layout

\end_inset

 provides the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
CLOCK_THREAD_CPUTIME_ID
\end_layout

\end_inset


\end_layout

\end_inset

 flavor.
 This thread-specific clock only ticks, when the corresponding thread executes.
\end_layout

\begin_layout Itemize
Thanks to the numerical enhancements presented earlier, the 
\noun on
Atlas
\noun default
 predictor automatically selects a stable subset from the metrics given
 to it.
 Therefore, we can always supply additional metrics without harming the
 prediction quality.
 As a convenience to the programmer, the 
\noun on
Atlas
\noun default
 runtime library always adds a constant metric of one before passing the
 metrics to the linear solver.
 This 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
one-metric
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
one-metric
\end_layout

\end_inset

 catches any constant-time contribution to execution time.
 Especially when the developer passes no metrics, like I did for the input
 and output stages of FFplay, this behind-the-scenes addition enables the
 predictor to extrapolate future execution times from previously measured
 execution times.
 Otherwise, the predictor would always return zero for jobs with no metrics.
\end_layout

\begin_layout Itemize
When an 
\noun on
Atlas
\noun default
-enabled application is launched, the predictor always starts off from an
 empty state with no knowledge about job execution times.
 Before it has seen the first job executions, it cannot make any predictions
 and consequently returns zero.
 After the first jobs passed, the initial predictions may be less accurate
 because the internal coefficients need to settle.
 Resuming from a saved predictor state avoids these problems.
 Applications can save this state on every exit or run a training workload
 at install time.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
From metrics selection
\end_layout

\end_inset

 to inferring deadlines and modifying FFplay, I hope I conveyed an understanding
 of integrating 
\noun on
Atlas
\noun default
 into a complex real-time application.
 Unlike the classical periodic task model, deadlines can be placed arbitrarily.
 Unlike priority-based schedulers, no knowledge of surrounding applications
 and their priorities was needed.
 
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Full Width
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
Asynchronous lambdas are gaining traction because of their benefits for
 parallel programming.
 
\noun on
Atlas
\noun default
 builds on this trend by extending it: With asynchronous lambdas, the applicatio
n dispatches blocks, which the runtime later executes on an automatic background
 thread.
 By passing additional job information with blocks, the 
\noun on
Atlas
\noun default
 task model aims for a developer mindset of telling the runtime: “Do this
 work.
 Until then.
 Here’s what I know about it.” Deadlines specify the time constraint, workload
 metrics describe the resource requirements.
 Both are part of the application domain and can be obtained by developers
 with local reasoning.
 No global system knowledge is needed.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
The estimator uses the metrics to derive approximate execution times.
 But to be useful for look-ahead scheduling, we want the estimator to operate
 predictively.
 It needs to provide execution times of submitted, but not yet executed
 jobs before they run.
 The next section evaluates this ability.
\end_layout

\begin_layout Section
Look-Ahead Prediction
\end_layout

\begin_layout Standard
Thanks to queueing, FFplay exposes jobs to the 
\noun on
Atlas
\noun default
 interface ahead-of-time.
 For every such submitted job, a predicted execution time 
\begin_inset Formula $e$
\end_inset

 is calculated as the dot product of the job’s workload metrics vector 
\begin_inset Formula $\underline{m}$
\end_inset

 and the current coefficient vector 
\begin_inset Formula $\underline{x}$
\end_inset

 from the auto-regressive predictor:
\begin_inset Formula 
\[
e=\underline{m}\cdot\underline{x}
\]

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Queueing_Gap.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Queueing-Gap"

\end_inset

Queueing-Gap Between Prediction and Training
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
For every completed job, the actual execution time is measured and used
 to train the predictor, updating the coefficient vector 
\begin_inset Formula $\underline{x}$
\end_inset

.
 The queue therefore introduces a gap between prediction and training illustrate
d in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Queueing-Gap"

\end_inset

.
\end_layout

\begin_layout Standard
In this section, I evaluate the accuracy of the execution time prediction.
\begin_inset Foot
status open

\begin_layout Plain Layout
The test machine is the same as in preceding experiments: a 
\begin_inset Formula $2.4\,\mathrm{GHz}$
\end_inset

 Intel Core
\begin_inset space ~
\end_inset

i5-
\begin_inset Formula $520\mathrm{M}$
\end_inset

 Arrandale with 
\begin_inset Formula $4\,\mathrm{GiB}$
\end_inset

 of 
\begin_inset Formula $1066\,\mathrm{MHz}$
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\mathrm{DDR}3$
\end_inset


\begin_inset space ~
\end_inset

SDRAM.
 To ensure stable and reproducible results, CPU frequency scaling including
 Intel Turbo Boost (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Intel: Turbo Boost Technology"
target "http://www.intel.com/technology/turboboost/"

\end_inset


\end_layout

\end_inset

) was disabled.
\end_layout

\end_inset

 In addition to the test videos used so far,
\begin_inset Foot
status open

\begin_layout Plain Layout
see Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-tab:Test-Clips"

\end_inset


\end_layout

\end_inset

 I supplement select experiments with the short and full-length feature
 film listed in Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-tab:Film-Clips"

\end_inset

.
\end_layout

\begin_layout Standard
I discuss alternatives for the decoder metrics and also measure the overhead
 introduced by the predictor.
 To improve stability I introduced the aging factor and automatic metrics
 sub-setting based on the column contribution threshold.
 I substantiate the choice of values for these parameters and demonstrate
 that the stable subset settles.
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="7">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="2.5cm">
<column alignment="left" valignment="top" width="4cm">
<column alignment="right" valignment="top" width="0pt">
<column alignment="right" valignment="top" width="0">
<column alignment="right" valignment="top" width="0">
<column alignment="left" valignment="top" width="0">
<column alignment="left" valignment="top" width="2.2cm">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Video (Source)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Content
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Resolution
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FPS
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Length
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Profile
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Encoding
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sintel
\begin_inset Newline newline
\end_inset

(
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Xiph Archive"
target "http://media.xiph.org/sintel/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
short film “Sintel” (2010), computer animated
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $4096\!\!\times\!\!1744$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $24$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $15\,\mathrm{min}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
High
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x264, CRF, rate
\begin_inset space ~
\end_inset

factor
\begin_inset space ~
\end_inset

23
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dante’s Peak (DVB recording)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
feature film “Dante’s Peak” (1997), live-action movie
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1280\!\!\times\!\!544$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $24$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $101\,\mathrm{min}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Main
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x264, CRF, rate
\begin_inset space ~
\end_inset

factor
\begin_inset space ~
\end_inset

20
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace 15pt
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-tab:Film-Clips"

\end_inset

Properties of Movies for Experiments
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
No metrics were passed
\end_layout

\end_inset

 for the input and output stages of FFplay.
 For convenience, 
\noun on
Atlas
\noun default
 adds a one-metric to enable prediction based on the average of previous
 execution times.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Prediction-Accuracy-IO"

\end_inset

 shows the mean relative error and its lower and upper quartiles as error
 bars.
 Given the small overall execution times of these two stages,
\begin_inset Foot
status open

\begin_layout Plain Layout
recall Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-mar:Relative-Time-Steps"

\end_inset


\end_layout

\end_inset

 those errors can be tolerated.
 The overall evaluation of scheduling behavior will verify that additional
 effort to find suitable metrics is not warranted.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_IO.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Prediction-Accuracy-IO"

\end_inset

Prediction Accuracy for Input and Output Stages
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset VSpace -0.5cm
\end_inset


\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The decoding stage
\end_layout

\end_inset

 is the most time consuming part of FFplay and thus calls for a precise
 prediction of its execution time.
 To demonstrate the importance of workload knowledge, I compare three alternativ
es for the decoding time metrics.
\end_layout

\begin_layout Standard
The first version uses no metrics and consequently does not exploit workload
 insights.
 Thanks to the automatic one-metric, the prediction is based on previous
 execution times.
 I call this alternative 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
time only
\end_layout

\end_inset

 and it serves as a lower bound.
 No other prediction should be worse.
\end_layout

\begin_layout Standard
The option I call 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
full metrics
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
full metrics
\end_layout

\end_inset

 uses the complete set of metrics identified previously.
 We expect this version to provide the most accurate predictions, because
 it forwards the largest set of valuable workload information to the estimator.
 Unfortunately, the majority of the metrics hide in the video bitstream
 behind an outer layer of entropy coding, so extracting them requires performing
 part of the decoding work.
\end_layout

\begin_layout Standard
Two solutions can remedy this problem.
 A staged decoder
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
staged decoder
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Altenbernd:MPEG-WCET"

\end_inset

 first processes the entropy compression layer and then extracts the metrics
 for the second stage, which performs the remaining decoding steps.
 This design requires intricate changes to the video decoder, which I do
 not think developers are prepared to implement.
\end_layout

\begin_layout Standard
Instead, I chose an offline preprocessing step, which embeds the video metrics
 into the bitstream.
 The MPEG-
\begin_inset Formula $4$
\end_inset


\begin_inset space ~
\end_inset

Part
\begin_inset space ~
\end_inset

2 video standard
\begin_inset CommandInset citation
LatexCommand cite
key "MPEG4-2"

\end_inset

 describes a complexity estimation header
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
complexity estimation header
\end_layout

\end_inset

 which optionally contains video metadata similar to my metrics.
 Unfortunately, this header has not been carried over to the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 standard.
 My preprocessing recreates such metadata for 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 by adding user-defined datagrams.
 The resulting video is still a standards compliant stream that any unmodified
 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
H
\end_layout

\end_inset

.264 decoder can play.
 Preprocessing one video only requires decoding it once and thus is fast.
 To keep the extra data small, I apply exp-golomb coding,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
exp-golomb coding
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Golomb:RLE"

\end_inset

 an established compression technology for bitstream header elements.
 The size overhead from the embedded metrics amounts to a geometric mean
 of 
\begin_inset Formula $\PreprocessSizeOverhead$
\end_inset

 over all test clips.
\end_layout

\begin_layout Standard
The full metrics with stream preprocessing serve as an upper bound for implement
or effort and resulting prediction accuracy.
 This alternative demonstrates, how good predictions can get when designers
 are willing to apply an end-to-end approach and are able to engineer the
 data format of their application to support a desired non-functional property.
 But clearly, a middle ground between the full-metrics and time-only approaches
 is needed.
\end_layout

\begin_layout Standard
This intermediate option is limited to information that can be easily obtained
 from an unmodified bitstream:
\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset VSpace -8pt
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

the number of pixels per frame,
\end_layout

\begin_layout Itemize
the number of bits of the compressed frame, and
\end_layout

\begin_layout Itemize
the frame type (I, P, or B).
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
The first two values are used as metrics directly.
 The frame type is passed to the estimator as three separate binary metrics,
 each of which can only take the values 
\begin_inset Formula $0$
\end_inset

 or 
\begin_inset Formula $1$
\end_inset

.
 The combination 
\begin_inset Formula $(1,0,0)$
\end_inset

 signals an I-frame, 
\begin_inset Formula $(0,1,0)$
\end_inset

 a P- and 
\begin_inset Formula $(0,0,1)$
\end_inset

 a B-frame.
 I call this alternative 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
\noindent
reduced metrics.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Comparison.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Prediction-Accuracy-Decoder"

\end_inset

Prediction Accuracy for the Decoder Stage
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Prediction-Accuracy-Decoder"

\end_inset

 shows that workload awareness improves prediction accuracy over a purely
 time-based predictor.
 Again, the error bars represent the lower and upper quartile of the per-frame
 relative errors.
 The reduced metrics, which do not require preprocessing or a staged decoder
 provide a good middle ground, whereas the full set of metrics offers the
 highest precision, with typical relative errors of less than 
\begin_inset Formula $10\%$
\end_inset

.
 The convincing results indicate that the prediction provides accurate estimates
 for short clips and full-length features, regardless of the encoding profile
 and video resolution being used.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Timeline.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Prediction-Zoom"

\end_inset

Zoomed View of Prediction Alternatives
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Prediction-Zoom"

\end_inset

 zooms in on a section of the Hunger Games video to illustrate that the
 full-metrics prediction tightly follows the large variations of the decoding
 time, while time-only prediction yields a long-term moving average.
\end_layout

\begin_layout Standard
Across the test videos, the predictor introduces a runtime overhead of 
\begin_inset Formula $\PredictionOverhead$
\end_inset

, but with an interquartile range of 
\begin_inset Formula $\PredictionOverheadIQR$
\end_inset

, meaning that the overhead is smaller than the variability of FFplay’s
 execution time measurements.
\end_layout

\begin_layout Standard
To show the hardware independence of the resulting preprocessed videos,
 I reran the prediction experiment on an Intel Atom
\begin_inset space ~
\end_inset

D2550 with 
\begin_inset Formula $1.86\,\mathrm{GHz}$
\end_inset

.
 The results in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Prediction-Atom"

\end_inset

 are similar to those from the Core
\begin_inset space ~
\end_inset

i5, with full metrics leading to relative errors of less than 
\begin_inset Formula $10\%$
\end_inset

.
 We conclude that our choice of metrics allows a hardware-independent prediction
 of execution times.
 Directly storing decoding time traces in the video bitstream would undo
 this benefit.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Atom.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Prediction-Atom"

\end_inset

Prediction Accuracy on Intel
\begin_inset space ~
\end_inset

Atom Hardware
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Two tunable parameters
\end_layout

\end_inset

 are part of the predictor design: The aging factor
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
aging factor
\end_layout

\end_inset

 determines, how quickly historical job data should be discarded in favor
 of newly acquired knowledge.
 The column contribution threshold
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
column contribution threshold
\end_layout

\end_inset

 trades prediction accuracy against numerical stability.
 The following experiments analyze the effect of these parameters.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Age.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Prediction-Aging"

\end_inset

Prediction Accuracy Influenced by Different Aging Factors
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Prediction-Aging"

\end_inset

 demonstrates how the aging factor affects prediction accuracy for the Hunger
 Games video.
 The factor determines, how quickly the predictor discards old knowledge
 and adapts to new application behavior.
 A larger factor means quicker adaption, while a smaller factor preserves
 historic data longer.
\end_layout

\begin_layout Standard
With the less precise time-only and reduced-metrics options, faster aging
 improves the prediction.
 This result is expected, because these metrics rely on the moving average
 to capture application behavior.
 This moving average adapts quicker with faster aging.
 However, for the full-metrics option, quick aging diminishes prediction
 accuracy.
 These metrics already cover the complete application behavior and therefore
 benefit from more knowledge aggregating in the predictor.
 Because the benefit for the full-metrics prediction levels off at 
\begin_inset Formula $0.01$
\end_inset

, I chose this value as the default.
 It also constitutes an acceptable compromise for the reduced metrics, which
 are important if videos are not preprocessed.
 A 
\begin_inset Formula $0.01$
\end_inset

 aging factor reduces the weight of past knowledge to 
\begin_inset Formula $10\%$
\end_inset

 after about 230 jobs.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\nicefrac{\ln0.1}{\ln0.99}=229.105\text{…}$
\end_inset


\end_layout

\end_inset

 Should the need arise, applications are free to override the default.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The column contribution threshold
\end_layout

\end_inset

 trades numerical stability against accuracy.
 A small value uses more metrics, which should result in more accurate predictio
ns in the long term, but can lead to overshoots due to instability in the
 short term.
 A larger value ignores more metrics by dropping their corresponding column
 from the linear system.
 Dropping more metrics increases numerical robustness, but reduces long-term
 precision.
\end_layout

\begin_layout Standard
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Instability-Problem"

\end_inset

 illustrates an instability problem at the beginning of the Hunger Games
 video: Like every movie trailer, it starts with the typical green MPAA
 rating card.
 Without column dropping, the predictor overfits to those simple frames
 and produces intermittent spikes and a series of exaggerated prediction
 once the actual trailer begins.
 Note the logarithmic ordinate of the plot.
 These overshooting predictions are undesirable and the figure also shows,
 how a column contribution threshold of 
\begin_inset Formula $1.1$
\end_inset

 prevents them.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Stability.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
Instability Problem at the Start of the Hunger Games Trailer
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "3-fig:Instability-Problem"

\end_inset

Instability Problem at the Start of the Hunger Games Trailer
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Note the logarithmic ordinate.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
A threshold of 
\begin_inset Formula $1.1$
\end_inset

 drops a metric, if it contributes less than 
\begin_inset Formula $10\%$
\end_inset

 improvement to the residual error.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Prediction-Column"

\end_inset

 confirms that higher thresholds lead to less accurate predictions in the
 long run.
 The figure shows the median instead of the mean relative error, because
 the median is robust against the overshooting outlier predictions.
 Error bars again indicate the upper and lower quartile.
 We see that a threshold of 
\begin_inset Formula $1.2$
\end_inset

 would reduce long-term prediction accuracy, substantiating the choice of
 
\begin_inset Formula $1.1$
\end_inset

.
 Again, applications are free to override this default.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Column.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Prediction-Column"

\end_inset

Prediction Accuracy for Different Column Contribution Thresholds
\end_layout

\end_inset


\begin_inset VSpace 1cm
\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Prediction_Subsetting.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Column-Dropping"

\end_inset

Stability of Column Subset
\end_layout

\end_inset


\end_layout

\end_inset

The column dropping algorithm comes at the cost of a worst-case time complexity
 in 
\begin_inset Formula $\mathcal{O}\bigl(l^{3}\bigr)$
\end_inset

 for 
\begin_inset Formula $l$
\end_inset

 metrics.
 However, the predictor reorders columns so that a computational cost is
 only incurred when the state of a column changes from keep to drop or vice
 versa.
 If the column state does not wildly fluctuate, the average case runtime
 of the predictor improves.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Column-Dropping"

\end_inset

 demonstrates the stability of the subset of active columns.
 Shaded areas denote that the predictor uses the column corresponding to
 this metric, white areas signal dropped columns.
 We can see a band structure, where a column stays in use for multiple consecuti
ve invocations of the predictor.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The interface
\end_layout

\end_inset

 between the 
\noun on
Atlas
\noun default
-enhanced GCD runtime and the predictor is thin.
 Apart from housekeeping, it contains a function to train the predictor
 with a new metrics vector and the corresponding measured execution time.
 The second important function is to generate a prediction from a metrics
 vector alone.
 This modularity allows applications to use a custom predictor, but I think
 the one presented and evaluated here is a good starting point.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Full Width
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
The linear auto-regressive predictor
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
linear auto-regressive predictor
\end_layout

\end_inset

 offers applications a suitable default predictor.
 It is easy to use for application developers, because it derives execution
 time predictions from workload metrics
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

 that are part of the application domain.
 I demonstrated the accuracy of the resulting predictions: Typical relative
 errors of less than 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\backslash
addfontfeature{Numbers={Lining}}
\end_layout

\end_inset

10%
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 can be achieved if deep workload insight is available.
 Predictions with less workload knowledge are still competitive compared
 to purely time-based predictions.
 I have shown the hardware independence of the predictor and the sensitivity
 of its parameters.
 Metrics dropping improves prediction stability by automatically selecting
 relevant metrics, relieving the developer of manual pre-filtering.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 hands execution times from the predictor down to the scheduler.
 We have to keep in mind that over- and underestimation is possible, which
 the kernel scheduler must consider.
 I also ask the reader to remember the three evaluated prediction options:
 time only, reduced metrics and full metrics, because they will reappear
 when I evaluate the overall scheduling behavior.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Verical_Integration_Scheduler.svg

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
System Scheduler
\end_layout

\begin_layout Standard
Multiple applications may independently submit jobs,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
job
\end_layout

\end_inset

 which compete for execution time.
 Because we cannot assume applications to trust each other, a privileged
 management component needs to oversee and enforce the allocation of CPU
 time.
 Microkernel research experiments with user-level scheduling primitives
\begin_inset CommandInset citation
LatexCommand cite
after "-2\\baselineskip"
key "Lackorzynski:vCPUs"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 and hierarchical scheduling,
\begin_inset CommandInset citation
LatexCommand cite
key "Ford:Fluke"

\end_inset

 but on commodity operating systems, a single system-wide scheduler lives
 in the kernel.
\begin_inset Note Note
status open

\begin_layout Plain Layout
not enough room for 
\begin_inset CommandInset citation
LatexCommand cite
key "Bovet:LinuxKernel"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The 
\noun on
Atlas
\noun default
 scheduler comes as a kernel patch to Linux version
\begin_inset space ~
\end_inset


\begin_inset Formula $3.5.7$
\end_inset

.
 Stefan Wächtler implemented the scheduler during his master’s thesis work,
 which I supervised together with Björn Döbel.
\begin_inset CommandInset citation
LatexCommand cite
key "Waechtler:Look-Ahead"

\end_inset

 I explain the general design of the scheduler and its properties here.
 A thorough description, implementation details, and overhead analysis can
 be found in Stefan’s thesis.
\end_layout

\begin_layout Standard
The scheduler integrates in an otherwise unmodified Ubuntu Linux kernel.
 We could have used a scheduler testbed such as LITMUS
\begin_inset script superscript

\begin_layout Plain Layout
RT
\end_layout

\end_inset

,
\begin_inset CommandInset citation
LatexCommand cite
key "Calandrino:LITMUSRT"

\end_inset

 but 
\noun on
Atlas
\noun default
’ aperiodic task model, its custom system call interface and the tight integrati
on with the Linux default scheduler diminishes the potential simplifications,
 so we decided to go for vanilla Linux.
\end_layout

\begin_layout Standard
I describe the scheduler in three parts: I first provide context and present
 initial design constraints that derive from the task model.
 Next, I explain the scheduling algorithm assuming all reported execution
 times were precise.
 I later relax this assumption and show how the scheduler accounts for over-
 and underestimated execution time predictions.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The Atlas task model
\end_layout

\end_inset

 allows applications to submit arbitrary jobs 
\begin_inset Formula $J=(e,d)$
\end_inset

 to the scheduler.
 Each job 
\begin_inset Formula $J$
\end_inset

 consists of an absolute deadline 
\begin_inset Formula $d$
\end_inset

 and an execution time estimate 
\begin_inset Formula $e$
\end_inset

.
 For now, we assume precise execution times.
\begin_inset Foot
status open

\begin_layout Plain Layout
Revisit Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-mar:Architectural-Overview"

\end_inset

 for an overview of the 
\noun on
Atlas
\noun default
 architecture.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The order and parameters of jobs submitted to the scheduler depend on what
 work the applications dispatch when and to what queue.
 Therefore, deadlines generally do not follow any pattern such as periods
 and no minimum distance between two deadlines can be assumed.
 By calling 
\emph on
atlas_next,
\emph default
 a thread transitions execution from one job to the next and therefore from
 one deadline to the next.
 As a consequence, the urgency of the thread relative to other threads changes.
 Scheduling algorithms for fixed task priorities like Rate-Monotonic Scheduling
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
rate-monotonic scheduling
\end_layout

\end_inset

 are thus unfit for the given task model.
\end_layout

\begin_layout Standard
However, the deadline for a job does not change after submission, so the
 class of dynamic task and fixed job priority algorithms appears attractive.
 For the uniprocessor case considered here, this class contains algorithms
 such as Earliest Deadline First,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
earliest deadline first
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RMS"

\end_inset

 which is optimal with regard to schedulability.
 An optimal
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
optimal scheduler
\end_layout

\end_inset

 algorithm only fails to find a schedule that fulfills all timing constraints
 if there is no such schedule within the bounds of the class.
 However, this optimality only holds for independent, preemptible and non-blocki
ng tasks.
\end_layout

\begin_layout Standard
In real applications, jobs may arbitrarily block for different reasons.
 They may wait for peripherals or for computation results from other jobs,
 or they may self-suspend
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
self-suspension
\end_layout

\end_inset

 by just sleeping for a while.
 FFplay contains all these situations.
 The input stage waits for the video file to arrive from disk, the output
 stage sleeps until the next frame is due for display.
 The producer-consumer queues introduce dependencies: When the output stage
 wants to display a frame, the decoder stage must have finished preparing
 the frame, otherwise the output stage blocks on an empty picture queue.
 Unfortunately, such blocking conditions are only visible to the scheduler
 circumstantially and potentially too late.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
An example illustrates
\end_layout

\end_inset

 how the Earliest Deadline First (EDF) algorithm fails to find a feasible
 schedule when dependencies
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
dependency
\end_layout

\end_inset

 are involved.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:EDF-and-LDF"

\end_inset

 depicts a set of three jobs 
\begin_inset Formula $(e_{i},d_{i})$
\end_inset

, each with an execution time of 
\begin_inset Formula $e_{i}=1$
\end_inset

 and absolute deadlines 
\begin_inset Formula $d_{A}=4$
\end_inset

, 
\begin_inset Formula $d_{B}=2$
\end_inset

 and 
\begin_inset Formula $d_{C}=3$
\end_inset

.
 Job 
\begin_inset Formula $B$
\end_inset

 depends on job 
\begin_inset Formula $A$
\end_inset

, meaning 
\begin_inset Formula $B$
\end_inset

 can only execute after 
\begin_inset Formula $A$
\end_inset

 completes.
 Imagine 
\begin_inset Formula $B$
\end_inset

 calling the synchronization function 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
pthread_cond_wait()
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Unix:Pthread_Cond_Wait"

\end_inset

 on a condition variable that 
\begin_inset Formula $A$
\end_inset

 signals at the end of its execution.
 This dependency is spelled out in the jobs’ code, but is unknown to the
 EDF scheduler.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/3-Real-Time/EDF_vs_LDF.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:EDF-and-LDF"

\end_inset

EDF and LDF Scheduling with Dependent Jobs
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
According to the EDF algorithm, at time instant zero, job 
\begin_inset Formula $B$
\end_inset

 is selected to run, because its deadline is earliest among the present
 jobs.
 
\begin_inset Formula $B$
\end_inset

 however blocks immediately on the condition variable.
 The scheduler decides again and finds 
\begin_inset Formula $C$
\end_inset

 to have the earliest deadline among the remaining jobs.
 
\begin_inset Formula $C$
\end_inset

 runs to completion at which point job 
\begin_inset Formula $A$
\end_inset

 is scheduled.
 It also runs to completion and releases 
\begin_inset Formula $B$
\end_inset

, which can finally run, but completes at time instant three and therefore
 one time unit behind its deadline.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:EDF-and-LDF"

\end_inset

 shows the schedule graphically.
\end_layout

\begin_layout Standard
An optimal algorithm for scheduling jobs with dependencies is the Latest
 Deadline First
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
latest deadline first
\end_layout

\end_inset

 (LDF) algorithm.
\begin_inset CommandInset citation
LatexCommand cite
key "Lawler:LDF"

\end_inset

 It iteratively picks the job with the latest deadline among all leaf jobs
 in the dependency graph, remembers this job in a list and removes the correspon
ding node from the graph.
 It continues until the last job has been picked and then executes the list
 of remembered jobs in reverse order.
 The resulting schedule in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:EDF-and-LDF"

\end_inset

 completes all jobs before their deadline.
\end_layout

\begin_layout Standard
The LDF algorithm is optimal with dependent jobs, but requires a-priori
 knowledge of all dependencies.
\begin_inset Foot
status open

\begin_layout Plain Layout
EDF is also optimal with dependent jobs, if it operates on effective deadlines.
 Calculating effective deadlines equally requires prior knowledge of all
 dependencies.
\end_layout

\end_inset

 The 
\noun on
Atlas
\noun default
 scheduler does not have this knowledge and can only detect at runtime when
 a job blocks.
 Even worse, 
\noun on
Atlas
\noun default
 can only see that job 
\begin_inset Formula $B$
\end_inset

 blocks, but not that job 
\begin_inset Formula $A$
\end_inset

 is responsible for resolving the blocking condition.
 Therefore, achieving optimality under arbitrary job dependencies remains
 an open problem in the 
\noun on
Atlas
\noun default
 context.
 Our scheduler contract will have to settle for lesser guarantees.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The Atlas kernel scheduler
\end_layout

\end_inset

 combines design cues from three existing algorithms: EDF, LDF, and LRT
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

the Latest Release Time
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
latest release time
\end_layout

\end_inset

 scheduler,
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RealTimeSystems"

\end_inset

 often summarized as “EDF backwards.” I first explain what 
\noun on
Atlas
\noun default
 does and then analyze the guarantees the scheduler assures.
\end_layout

\begin_layout Standard
The kernel scheduler keeps a single global list of submitted jobs, which
 is ordered by deadline, similar to EDF.
 Every newly submitted job is inserted into this list, which I call the
 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
job list.
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
job list
\end_layout

\end_inset

 Every job is also associated with exactly one real-time task, which corresponds
 to one specific serial GCD queue in an application.
\begin_inset Foot
status open

\begin_layout Plain Layout
Recall that I do not consider parallel queues here.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A job in the list can be in one of four states: 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
running, blocked, ready,
\end_layout

\end_inset

 or 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
waiting.
\end_layout

\end_inset

 A job is running, when it currently executes on the CPU.
 Only a single job can be running.
 A job waiting for a resource other than the CPU is blocked.
 A job is ready if it is not running or blocked and is the frontmost job
 in its associated real-time task.
 In the originating GCD queue, blocks are also sorted by deadline, so the
 block corresponding to a ready job executes next in that queue.
 This way, the scheduler’s job list and the application’s queues stay in
 sync.
 Any job not running, ready, or blocked is waiting.
\begin_inset Note Note
status open

\begin_layout Plain Layout
figure?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
When asked to make a scheduling decision,
\end_layout

\end_inset

 the scheduler changes the state of the running job to ready and uses the
 job list to calculate the 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
available slack
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
available slack
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Literature sometimes uses the term static slack, but usually with schedules
 based on worst-case execution times.
 
\noun on
Atlas
\noun default
’ job execution times are based on runtime knowledge, so the word “static”
 is inappropriate.
\end_layout

\end_inset

 at the current time instant 
\begin_inset Formula $t_{now}$
\end_inset

: Every job 
\begin_inset Formula $J_{i}$
\end_inset

 comes with a current per-job slack 
\begin_inset Formula $s_{i}(t_{now})$
\end_inset

,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
slack time
\end_layout

\end_inset

 which is the difference between the time remaining until 
\begin_inset Formula $J_{i}$
\end_inset

's absolute deadline 
\begin_inset Formula $d_{i}$
\end_inset

 and the sum of all execution times of jobs scheduled to run between 
\begin_inset Formula $t_{now}$
\end_inset

 and 
\begin_inset Formula $d_{i}$
\end_inset

: 
\begin_inset Formula 
\[
s_{i}(t_{now})=\left(d_{i}-t_{now}\right)-\sum_{\left\{ J_{k}\mid\mathrm{job\: scheduled\: between}\: t_{now}\:\mathrm{and}\: d_{i}\right\} }e_{k}
\]

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Slack_Calculation.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Slack-Calculation"

\end_inset

Slack Calculation
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Slack-Calculation"

\end_inset

 visualizes this calculation.
 The available slack 
\begin_inset Formula $s(t_{now})$
\end_inset

 is the minimum of all 
\begin_inset Formula $s_{i}(t_{now})$
\end_inset

.
\begin_inset Foot
status open

\begin_layout Plain Layout
The actual implementation is optimized and does not continuously recalculate
 all per-job slacks to find the minimum.
\end_layout

\end_inset

 The intuition behind available slack is that we can safely delay execution
 of all pending jobs for another 
\begin_inset Formula $s(t_{now})$
\end_inset

 time units without violating any timing constraints.
\begin_inset CommandInset citation
LatexCommand cite
key "Tia:Slack"

\end_inset

 The calculation of available slack ensures, that there is still enough
 time to finish all jobs before their deadline.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $s(t_{now})$
\end_inset

 is zero, then some 
\begin_inset Formula $s_{i}(t_{now})$
\end_inset

 was zero, meaning we have a job in the system which misses its deadline
 if we do not choose to run a job now.
 According to EDF, we select the frontmost ready job from the job list,
 set its state to running and return it as the job to execute.
\begin_inset Foot
status open

\begin_layout Plain Layout
Due to latencies in the Linux kernel, 
\begin_inset Formula $s$
\end_inset

 may drop below zero, in which case we also run the frontmost ready job.
 To avoid these situations and reduce the number of context switches, values
 of 
\begin_inset Formula $s$
\end_inset

 below 
\begin_inset Formula $1\,\mathrm{ms}$
\end_inset

 are considered to be zero.
\end_layout

\end_inset

 As in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Slack-Calculation"

\end_inset

, this frontmost ready job is not necessarily the job with zero per-job
 slack.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $s(t_{now})$
\end_inset

 is greater than zero, there is no urgent need to run a job now.
 The scheduler selects no job to run, but programs a timer to decide again
 after 
\begin_inset Formula $s(t_{now})$
\end_inset

 time units, at which point the available slack will be zero.
 This scheduling strategy is similar to LRT, which also runs work only when
 the available slack is zero.
\end_layout

\begin_layout Standard
Apart from the principal scheduling decision, the other operations of the
 
\noun on
Atlas
\noun default
 scheduler are technical and I briefly list them here:
\end_layout

\begin_layout Itemize
Before every scheduling decision, the currently running job transitions
 to the ready state.
 At this point, the execution time it already consumed is subtracted from
 its job description to ensure correct slack time calculations.
\end_layout

\begin_layout Itemize
Calling 
\emph on
atlas_submit
\emph default
 to report a new job forces a scheduling decision.
\end_layout

\begin_layout Itemize
When the running job calls 
\emph on
atlas_next,
\emph default
 it is removed from the scheduler and a scheduling decision is made.
 Removing the job causes the next job in the corresponding real-time task
 to become ready.
\end_layout

\begin_layout Itemize
When the running job blocks, its state changes from running to blocked.
 Unblocking reverts the state to ready.
 Both events cause a scheduling decision.
\end_layout

\begin_layout Itemize
If the execution time of a job was underestimated, a timer fires once the
 reported time is depleted.
 A similar timer fires when a job has passed its deadline.
 In both cases, the job is removed from the job list, but remains registered
 with its real-time task.
 The job is no longer involved in scheduling decisions, but the next job
 in the real-time task does not become ready because its predecessor has
 not yet completed.
 I discuss this situation later.
\end_layout

\begin_layout Standard
From the description of the 
\noun on
Atlas
\noun default
 scheduling algorithm, we can observe that it is not work conserving:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
work-conserving scheduler
\end_layout

\end_inset

 It may not return a job to run although there are ready jobs.
 In fact, 
\noun on
Atlas
\noun default
 only runs jobs when the available slack is zero, at which point any further
 delay would lead to a certain deadline miss.
 The research community has explored non-work-conserving schedulers to improve
 CPU response times
\begin_inset CommandInset citation
LatexCommand cite
key "Rosti:NWC_Partitioning"

\end_inset

 or throughput.
\begin_inset CommandInset citation
LatexCommand cite
key "Fedorova:SMT_Scheduling"

\end_inset

 Here, the rationale behind this design is threefold:
\end_layout

\begin_layout Itemize
The 
\noun on
Atlas
\noun default
 task model does not express an arrival time
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
arrival time
\end_layout

\end_inset

 to the scheduler.
 Any job with a constraint of not running before a certain time must self-suspen
d.
 The FFplay output stage does so because video frames should be displayed
 neither too early nor too late.
 
\noun on
Atlas
\noun default
 runs jobs as late as possible which helps to minimize such self-suspensions.
 The hidden assumption is that most deadline-limited work has its execution
 sweet spot
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
execution sweet spot
\end_layout

\end_inset

 toward the end of its scheduling window.
 Other models like the gravitational task model
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
gravitational task model
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Guerra:Gravitational"

\end_inset

 can express execution sweet spots explicitly, 
\noun on
Atlas
\noun default
 treats it heuristically.
\end_layout

\begin_layout Itemize
When slack calculation reveals that no real-time job needs to run, we can
 use the CPU to improve response times for non-real-time work.
\begin_inset CommandInset citation
LatexCommand cite
key "Lehoczky:Slack"

\end_inset

 I want to run 
\noun on
Atlas
\noun default
-enabled applications next to unmodified Linux applications, so the scheduler
 has to expect significant non-real-time load.
 Part of it may be applications with user interfaces, which run as regular
 time-shared threads, but expect timely service.
 Even applications converted to 
\noun on
Atlas
\noun default
 like FFplay start with a main thread, which acts as the application backbone
 and orchestrates all real-time work, but is initially not real-time scheduled
 itself.
 To solve this chicken-and-egg problem, time not claimed by the 
\noun on
Atlas
\noun default
 scheduler is handed to Linux’ default CFS
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
completely fair scheduler
\end_layout

\end_inset

 scheduler.
 The LRT-like strategy guarantees that time is donated to CFS as early as
 possible, until an urgent real-time job must run.
 Within its time allocation, CFS can apply all its throughput and responsiveness
 optimizations to improve service to legacy applications.
 Reaping the benefits of existing non-real-time schedulers is a common idea
 in real-time research.
\begin_inset CommandInset citation
LatexCommand cite
key "Reuther:DAS"

\end_inset


\end_layout

\begin_layout Itemize
The non-work-conserving scheduling also benefits jobs, which have overrun
 their announced execution time.
 They can catch up quickly by using the available slack early.
 I come back to this point later.
\end_layout

\begin_layout Standard
In summary, the 
\noun on
Atlas
\noun default
 scheduler behaves like a hybrid between EDF and LRT: It executes jobs in
 deadline order, but delays execution until the available slack is zero.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
What guarantees
\end_layout

\end_inset

 can we expect from this scheduler? For independent, preemptible and not
 self-suspending jobs on a single processor, EDF is an optimal algorithm.
 I prove by contradiction that the 
\noun on
Atlas
\noun default
 scheduler retains this property:
\end_layout

\begin_layout Enumerate
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

Assume the 
\noun on
Atlas
\noun default
 scheduler was not optimal under the given restrictions.
 Then, a set of independent, preemptible and not self-suspending jobs exists,
 for which there is a feasible schedule, but 
\noun on
Atlas
\noun default
 fails to find one.
\end_layout

\begin_layout Enumerate
EDF can successfully schedule this job set, because the criteria for EDF
 optimality are met.
\end_layout

\begin_layout Enumerate
Iterate over all jobs in the EDF schedule in descending deadline order.
 Move each visited job maximally to the right, until it either hits its
 deadline or collides with the next job in ascending deadline order.
 Observe that each moved job still completes before its deadline and that
 jobs are not reordered, because no job moves beyond its successor.
\end_layout

\begin_layout Enumerate
In the thus constructed schedule, available slack is zero whenever a job
 is scheduled to begin execution, i.e., at its release time.
 We can prove this by induction over all jobs in descending deadline order:
 Per-job slack and thus available slack is trivially zero at the release
 of the last job 
\begin_inset Formula $J_{last}$
\end_inset

, because its execution starts at 
\begin_inset Formula $d_{last}-e_{last}$
\end_inset

.
 For any other job, the same argument applies if it ends at its deadline.
 For any job 
\begin_inset Formula $J_{i}$
\end_inset

 not ending at its deadline, we know by the induction premise that available
 slack is zero at the release of 
\begin_inset Formula $J_{i+1}$
\end_inset

.
 Thus, there is some job 
\begin_inset Formula $J_{\star}$
\end_inset

 whose per-job slack is zero at the release time 
\begin_inset Formula $t_{i+1}$
\end_inset

 of job 
\begin_inset Formula $J_{i+1}$
\end_inset


\emph on
:
\emph default
 
\begin_inset Formula $s_{\star}(t_{i+1})=0$
\end_inset

.
 Moving the release time from 
\begin_inset Formula $t_{i+1}$
\end_inset

 to 
\begin_inset Formula $t_{i}$
\end_inset

 adds 
\begin_inset Formula $t_{i+1}-t_{i}$
\end_inset

 time units to the slack of 
\begin_inset Formula $J_{\star}$
\end_inset

.
 But simultaneously, the execution of 
\begin_inset Formula $J_{i}$
\end_inset

 is now part of the interval 
\begin_inset Formula $\left[t_{i},d_{\star}\right]$
\end_inset

, so we subtract its execution time: 
\begin_inset Formula $s_{\star}(t_{i})=s_{\star}(t_{i+1})+\left(t_{i+1}-t_{i}\right)-e_{i}$
\end_inset

.
 By construction there is no gap between the execution of 
\begin_inset Formula $J_{i}$
\end_inset

 and its successor 
\begin_inset Formula $J_{i+1}$
\end_inset

.
 Thus, 
\begin_inset Formula $t_{i+1}-t_{i}=e_{i}$
\end_inset

, resulting in 
\begin_inset Formula $s_{\star}(t_{i})=s_{\star}(t_{i+1})=0$
\end_inset

.
 Therefore, at the release of job 
\begin_inset Formula $J_{i}$
\end_inset

, the per-job slack of 
\begin_inset Formula $J_{\star}$
\end_inset

 is still zero and thus the available slack is zero as well, which completes
 the induction.
\end_layout

\begin_layout Enumerate
The constructed schedule runs all jobs in deadline order and only when available
 slack is zero.
 The presented 
\noun on
Atlas
\noun default
 algorithm also runs all jobs in deadline order and only when available
 slack is zero.
 Without loss of generality we can assume the same tie-breaking rules in
 EDF and 
\noun on
Atlas
\noun default
.
 Therefore, deadline order is unambiguous and the constructed schedule and
 the one 
\noun on
Atlas
\noun default
 finds are identical.
\end_layout

\begin_layout Enumerate
The constructed schedule and thus the 
\noun on
Atlas
\noun default
 schedule are feasible, because no job completes after its deadline, contradicti
ng the initial assumption and completing the proof.
\end_layout

\begin_layout Standard
What remains for discussion are the requirements of EDF optimality: preemption,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
preemption
\end_layout

\end_inset

 no self-suspension and independence.
\end_layout

\begin_layout Description
Preemption is unproblematic, because all 
\noun on
Atlas
\noun default
 jobs are fully preemptible, a feature naturally provided by the Linux schedulin
g infrastructure.
\end_layout

\begin_layout Description
Self-Suspension is alleviated by the late execution of jobs as discussed
 previously.
 Jobs are still free to shoot themselves in the foot by sleeping past their
 deadline, but I consider this a programmer error.
 The guarantees 
\noun on
Atlas
\noun default
 aims to provide collapse in the presence of jobs self-suspending arbitrarily.
\end_layout

\begin_layout Description
Dependencies thwart the optimality of EDF, as we have seen by example.
 LDF however is optimal for dependent jobs.
 From the way LDF operates, it is easy to show that both algorithms find
 the same schedule, as long as deadlines never decrease along edges of the
 dependency graph:
\end_layout

\begin_deeper
\begin_layout Standard
LDF iteratively picks the latest-deadline job among the leaf jobs in the
 dependency graph.
 If deadlines do not decrease along graph edges, the job selected by LDF
 also has the latest deadline overall, disregarding dependencies, because
 all non-leaf jobs have earlier deadlines.
 With compatible tie-breaking to resolve ambiguities, LDF results in the
 same deadline-ordered task list as EDF.
\end_layout

\begin_layout Standard
Because LDF is optimal for all dependent job sets, it is also optimal for
 job sets with non-decreasing deadlines along dependency edges.
 EDF results in the same schedule for those job sets and therefore must
 be optimal as well.
 Applying the preceding proof shows that 
\noun on
Atlas
\noun default
 is also optimal for such job sets.
\end_layout

\end_deeper
\begin_layout Standard
\noindent
The limitation that dependent jobs must have a deadline not earlier than
 their prerequisite job is not difficult in practice.
 The deadline flow I devised for FFplay follows the flow of data through
 the player queues, so the output job for a given frame has a later deadline
 than the matching decode job.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Leaving the perfect world
\end_layout

\end_inset

 of nicely arranged deadlines and precise execution times, I now discuss
 what the scheduler can do for applications that do not behave perfectly.
 Care must be taken not to break the properties I have shown above.
 I first talk about over- and underestimated execution times, followed by
 blocking.
 
\noun on
Atlas
\noun default
 programs High Precision Event Timers
\begin_inset Foot
status open

\begin_layout Plain Layout
High Precision Event Timer: hardware timer used in personal computers (cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Wikipedia: High Precision Event Timer"
target "http://en.wikipedia.org/w/index.php?title=High_Precision_Event_Timer&oldid=556583213"

\end_inset


\end_layout

\end_inset

)
\end_layout

\end_inset

 to police deadline or reserved execution time overruns.
\begin_inset CommandInset citation
LatexCommand cite
key "Mercer:CapacityReserve"

\end_inset


\end_layout

\begin_layout Description
Overestimated
\begin_inset space \space{}
\end_inset

Execution
\begin_inset space \space{}
\end_inset

Times are the easiest to handle.
 Whenever a job calls 
\emph on
atlas_next
\emph default
 early, before the reserved execution time has been consumed, the remaining
 time becomes available as additional dynamic slack.
 
\noun on
Atlas
\noun default
 does not donate slack across real-time jobs,
\begin_inset CommandInset citation
LatexCommand cite
key "Lin:Backslash"

\end_inset

 all slack goes to CFS instead.
 Robustness against runaway jobs is one reason for this design decision,
 which will be further explained during the evaluation.
\end_layout

\begin_layout Description
Underestimation is by far the harder problem.
 Our LRT-inspired schedule comes with the downside that any reservation
 overrun leads to a certain deadline miss.
 
\noun on
Atlas
\noun default
 mitigates this problem by always making the frontmost ready job eligible
 for scheduling by the default CFS scheduler.
 Whenever slack time in 
\noun on
Atlas
\noun default
 causes CFS to run, it not only time-shares the CPU among all non-real-time
 threads, but also finds one extra thread from the 
\noun on
Atlas
\noun default
 world.
 The time a job receives in CFS is not accounted against the reported execution
 time estimate, thereby allowing for a free head start,
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
head start
\end_layout

\end_inset

 albeit with no progress guarantee.
 If the job even completes in CFS, the next job from 
\noun on
Atlas
\noun default
’ job list takes its place.
 If sufficient compute time is available in CFS, this head start mechanism
 thus transforms the non-work-conserving LRT-arrangement of 
\noun on
Atlas
\noun default
 jobs into a classical work-conserving EDF release.
\end_layout

\begin_deeper
\begin_layout Standard
A job may still overrun its reservation, even with the help of the head
 start.
 In this case, 
\noun on
Atlas
\noun default
 has to protect the remaining jobs to uphold the scheduler guarantees.
 The infringing job is marked as late and is removed from the 
\noun on
Atlas
\noun default
 job list.
 CFS exclusively schedules all late jobs in the slack left over by 
\noun on
Atlas.

\noun default
 Because slack is available early, late jobs get a chance to catch up quickly.
\end_layout

\end_deeper
\begin_layout Description
Blocking can push job completion behind the deadline, for example when a
 job experienced an unexpected delay while waiting for a peripheral device
 or a needed result from another job.
 In order to protect innocent jobs, 
\noun on
Atlas
\noun default
 has to stop considering the delayed job after its deadline has passed.
 However, as long as this job has not depleted its reserved execution time,
 we do not want to drop it to CFS.
 Instead, we allow jobs behind their deadline to consume their remaining
 reservation with a higher priority than all CFS threads.
 This policy does not diminish service to CFS, because the total CPU time
 claimed by 
\noun on
Atlas
\noun default
 does not change, blocking just distributes it differently.
 In fact, when a job has blocked, CFS already received extra time earlier.
\end_layout

\begin_deeper
\begin_layout Standard
The implementation uses a scheduling band between 
\noun on
Atlas
\noun default
 and CFS to catch such delayed jobs.
 All jobs within this band have deadlines lying in the past, but the band
 is still scheduled according to EDF to allow jobs with the highest tardiness
 to complete first.
\begin_inset CommandInset citation
LatexCommand cite
key "Stoyenko:Tardiness"

\end_inset

 Note that the 
\noun on
Atlas
\noun default
 guarantees are unaffected, because this band only runs when there is available
 slack.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/3-Real-Time/Scheduler_Layers.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Linux-Scheduler-Layers"

\end_inset

Linux Scheduler Layers
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The implementation of Atlas
\end_layout

\end_inset

 within the Linux scheduling infrastructure introduces two new layers between
 the existing CFS and POSIX real-time bands.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Linux-Scheduler-Layers"

\end_inset

 shows the resulting scheduler stack, including the two special layers stop
 and idle.
 Linux calls the schedulers in a strict hierarchy, with any lower layer
 only receiving time not claimed by the upper layers.
 Consequently, the stop and POSIX real-time layers could take time away
 from 
\noun on
Atlas.

\noun default
 However, the stop layer is only used by the Linux kernel internally for
 rare operations during CPU shutdown and access to the POSIX real-time layer
 can be controlled by way of the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
RLIMIT_RTPRIO
\end_layout

\end_inset


\end_layout

\end_inset

 resource limit.
\begin_inset CommandInset citation
LatexCommand cite
key "Linux:Sched_Setscheduler"

\end_inset

 The placement of the 
\noun on
Atlas
\noun default
 layer retains the semantics of the POSIX real-time layer.
 Simultaneous use of both layers would require more sophisticated analysis
 methods
\begin_inset CommandInset citation
LatexCommand cite
key "Shin:Compositional"

\end_inset

 to determine the guarantees provided by 
\noun on
Atlas
\noun default
.
\end_layout

\begin_layout Standard
Available slack in the 
\noun on
Atlas
\noun default
 layer automatically passes down to the EDF recovery layer, which catches
 jobs that overran their deadline due to blocking.
 When this layer has no jobs to run, the default CFS scheduler executes,
 but it cooperates with the 
\noun on
Atlas
\noun default
 layer to implement the head start mechanism.
\end_layout

\begin_layout Standard
Although the 
\noun on
Atlas
\noun default
 task model of aperiodic jobs described by execution time and deadline is
 simple, we have seen how contact with the real world turns scheduling into
 a complex topic.
\begin_inset CommandInset citation
LatexCommand cite
key "Corbet:CFS_Complexity"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The scheduler contract
\end_layout

\end_inset

 
\noun on
Atlas
\noun default
 provides is comprehensible and useful.
 To receive strong guarantees, submitted execution times must be precise,
 jobs must not self-suspend, and deadlines must never decrease along dependency
 edges.
 Developers can reason about these requirements by analyzing just their
 own application code, without making assumptions about system context or
 other applications.
 In return, 
\noun on
Atlas
\noun default
 guarantees optimal behavior regarding schedulability: When there is a feasible
 schedule, all jobs will meet their deadlines.
\end_layout

\begin_layout Standard
For imperfect real-time applications, where the developer did not spend
 the analysis effort or where technical reasons prevent satisfying all requireme
nts, 
\noun on
Atlas
\noun default
 employs band-aid mechanisms to uphold good service to that application:
 Jobs get a free head start in EDF order to remedy wrong execution times.
 Jobs delayed by blocking or self-suspension can consume their reservation
 with higher priority than any CFS job.
 Lastly, 
\noun on
Atlas
\noun default
 donates its slack time to CFS early, allowing late jobs to catch up quickly
 and legacy threads to make progress.
 In all these cases, 
\noun on
Atlas
\noun default
 ensures that misbehaving jobs never interfere with the timeliness of behaving
 jobs.
\end_layout

\begin_layout Full Width
\begin_inset VSpace defskip
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout

\noun on
Atlas
\noun default
 offers a vertically integrated solution, completely implemented from an
 asynchronous-lambda-based application runtime and a linear auto-regressive
 predictor down to the kernel scheduler.
 On all layers, developers need to reflect only on application-local behavior.
 Based on a clear contract, the scheduler provides useful timeliness guarantees.
 The custom GCD runtime mediates between application and scheduler, enabling
 developers to drive the entire machinery by way of a single function call:
 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
dispatch_async_atlas
\end_layout

\end_inset


\end_layout

\end_inset

.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
FFplay meets all conditions of the scheduler contract but one: We have seen
 that predictions are precise and I argued that the deadline placement intuitive
ly follows dependencies.
 However, the output stage may self-suspend.
 Frames should not be displayed too early, so this violation is due to technical
 requirements of the application.
\end_layout

\begin_layout Standard
Additionally, all 
\noun on
Atlas
\noun default
 guarantees collapse when the system is permanently or temporarily overloaded.
 The scheduler interface does not allow to reject jobs, because I think
 users and developers would be startled.
 But thanks to jobs being submitted ahead of time, 
\noun on
Atlas
\noun default
 should be able to detect overload and notify applications.
 In the next section, I evaluate this feature and the overall scheduling
 behavior.
\end_layout

\begin_layout Section
Timeliness Experiments
\end_layout

\begin_layout Standard
The 
\noun on
Atlas
\noun default
 interface is friendly to developers, but does it provide useful real-time
 behavior to applications? I answer this question with experiments
\begin_inset Foot
status open

\begin_layout Plain Layout
The test machine is the same as in preceding experiments: a 
\begin_inset Formula $2.4\,\mathrm{GHz}$
\end_inset

 Intel Core
\begin_inset space ~
\end_inset

i5-
\begin_inset Formula $520\mathrm{M}$
\end_inset

 Arrandale with 
\begin_inset Formula $4\,\mathrm{GiB}$
\end_inset

 of 
\begin_inset Formula $1066\,\mathrm{MHz}$
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\mathrm{DDR}3$
\end_inset


\begin_inset space ~
\end_inset

SDRAM and CPU frequency scaling disabled.
\end_layout

\end_inset

 using three different workloads: gesture tracking, user interface responsivenes
s, and the FFplay video player.
 I show how 
\noun on
Atlas
\noun default
 satisfies the timing constraints of these applications when the system
 is not overloaded.
 Finally, I validate my claim that for an overloaded system, 
\noun on
Atlas
\noun default
 can anticipate deadline misses before they occur.
\end_layout

\begin_layout Standard
In select experiments, I compare the scheduling behavior of 
\noun on
Atlas
\noun default
 with competing schedulers by running background load next to the real-time
 application under test.
 In the following, whenever the term background load is used without further
 explanation, it refers to ten concurrently running CPU-hogging processes
 that each execute a tight endless loop.
\begin_inset Foot
status open

\begin_layout Plain Layout
Their complete source code:
\end_layout

\begin_layout Plain Layout
\begin_inset listings
inline true
status open

\begin_layout Plain Layout

int main(void) 
\backslash
{ while (1); 
\backslash
}
\end_layout

\end_inset


\end_layout

\end_inset

 Background load is scheduled by the Linux default CFS scheduler.
\end_layout

\begin_layout Standard
In all experiments, the 
\noun on
Atlas
\noun default
 execution time predictor runs with the default aging factor of 
\begin_inset Formula $0.01$
\end_inset

 and column contribution threshold of 
\begin_inset Formula $1.1$
\end_inset

 as previously established.
 To account for scheduling overhead, time measurement jitter, and unexpected
 latencies in the runtime library or the Linux kernel, all job execution
 times are enlarged by 
\begin_inset Formula $1\%$
\end_inset

 before being submitted to the kernel.
 Otherwise, a job which precisely needs its specified execution time may
 overrun its deadline because of these overheads and inaccuracies.
 Oversubscribing all jobs by 
\begin_inset Formula $1\%$
\end_inset

 of course leads to an equivalent loss of 
\begin_inset Formula $1\%$
\end_inset

 schedulable utilization.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/Bodytrack.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Bodytrack-Result"

\end_inset

Result of the Bodytrack Benchmark
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Bodytrack
\end_layout

\end_inset

 is the first evaluation workload.
 It is part of the Parsec
\begin_inset space ~
\end_inset

3.0 benchmark suite
\begin_inset CommandInset citation
LatexCommand cite
key "Bienia:Parsec"

\end_inset

 and implements tracking of a human body’s 
\begin_inset Formula $\mathrm{3D}$
\end_inset

 pose from camera images.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Bodytrack-Result"

\end_inset

 visualizes the tracking result.
 Other than commercial systems such as Microsoft Kinect,
\begin_inset Foot
status open

\begin_layout Plain Layout
cf.
\begin_inset space ~
\end_inset


\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "Microsoft: Kinect for Windows"
target "http://www.microsoft.com/en-us/kinectforwindows/"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 Bodytrack performs unassisted tracking with no markers or depth images.
 I chose this benchmark because gesture tracking is part of an emerging
 field of user interface research.
\begin_inset CommandInset citation
LatexCommand cite
key "Jacob:RBI"

\end_inset


\end_layout

\begin_layout Standard
Bodytrack employs an annealed particle filter.
 With its default parameters of 4000 particles and five annealing layers,
 the workload is too CPU intensive for useful real-time operation on a single
 CPU.
 I therefore reduce the parameters to 750 particles and three annealing
 layers, resulting in an average execution time of 
\begin_inset Formula $\BodytrackExecutionTime$
\end_inset

 per camera image.
 This time does not fluctuate much across the test set of captured images,
 so a purely time-based prediction is sufficient.
 The error bars in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Bodytrack-Execution-Time"

\end_inset

 indicate the upper and lower quartile of measured execution time and prediction.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\begin_inset Graphics
	filename Data/3-Real-Time/Bodytrack_Alone.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Bodytrack-Execution-Time"

\end_inset

Bodytrack Execution Time
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The original Bodytrack benchmark was not meant to run as a real-time application
, but using gesture tracking as user input requires deadlines to ensure
 responsive behavior.
 I configured the processing of each camera image to finish within 
\begin_inset Formula $250\,\mathrm{ms}$
\end_inset

 and modified the Bodytrack code accordingly.
 No metrics are involved and the modifications touch just 16
\begin_inset space ~
\end_inset

lines of code.
\end_layout

\begin_layout Standard
Bodytrack now behaves like a classical periodic real-time task: Jobs exhibit
 constant execution time and one job instance is released at the beginning
 of a 
\begin_inset Formula $250\,\mathrm{ms}$
\end_inset

 period and must complete within that interval.
 I use this opportunity to compare 
\noun on
Atlas
\noun default
 against a fixed priority scheduler, which is often used to schedule periodic
 tasks.
 Because the application knows it will continuously process frames, it can
 submit jobs in advance.
 My modified Bodytrack submits eight jobs ahead of time, providing the scheduler
 with a two second look-ahead horizon.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Bodytrack_Schedule.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Bodytrack-Scheduling"

\end_inset

Bodytrack Scheduling Behavior
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Bodytrack-Scheduling"

\end_inset

 shows how 
\noun on
Atlas
\noun default
 protects the real-time work from competing background load.
 The first subfigure illustrates the behavior of a Bodytrack run with no
 concurrent load.
 The application progresses linearly through the captured image sequence.
 Every job meets its deadline.
 The second subfigure demonstrates scheduling behavior of the Linux default
 CFS scheduler, when Bodytrack competes with background load, which starts
 15
\begin_inset space ~
\end_inset

seconds into the experiment and stops at time instant 45.
 Bodytrack’s progress slows down because the background load receives too
 much CPU time.
 When the background load recedes, Bodytrack tries to catch up.
 Scheduling under 
\noun on
Atlas
\noun default
 avoids this problem.
 As the third subfigure confirms, 
\noun on
Atlas
\noun default
 successfully schedules Bodytrack according to its specified timing requirements.
 Background load throttles as needed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/Bodytrack_Fail.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Bodytrack-Failing"

\end_inset

Bodytrack Failing to an Endless Loop
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Periodic tasks can be scheduled with a traditional fixed priority scheduler
 such as the POSIX real-time scheduler in Linux.
 The left part of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Bodytrack-Failing"

\end_inset

 demonstrates that prioritizing Bodytrack indeed protects it from background
 load similarly to 
\noun on
Atlas
\noun default
.
 However, when average applications without special vetting or certification
 are allowed to use real-time scheduling, we have to expect programmer errors.
 Imagine a bug that causes Bodytrack to fail to an endless loop.
 With fixed priority scheduling, any runaway real-time application can lock
 up the entire system.
\begin_inset CommandInset citation
LatexCommand cite
after "-2\\baselineskip"
key "Nieh:SVR4UNIX_Unacceptable"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 The second subfigure of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Bodytrack-Failing"

\end_inset

 illustrates, how all background activity comes to a halt.
 The system becomes unusable at this point.
\end_layout

\begin_layout Standard
The third subfigure reveals how 
\noun on
Atlas
\noun default
 handles these situations gracefully: The real-time application still ceases
 to make progress, which is expected because 
\noun on
Atlas
\noun default
 cannot fix the application bug.
 But background load immediately receives its fair share of the CPU once
 Bodytrack overruns the time reserved for its job.
 The system is fully operable, allowing the user or a system service to
 kill the faulty application.
 This benefit confirms our design decision not to implement donation of
 dynamic slack across jobs, but to always pass all slack to CFS.
 Any failing job may otherwise receive more time by way of slack donation,
 prolonging the time it is able to prevent service to non-real-time applications.
 Instead, 
\noun on
Atlas
\noun default
 demotes jobs overrunning their reservation directly to CFS.
 Only when they catch up they are promoted to 
\noun on
Atlas
\noun default
 again.
\end_layout

\begin_layout Standard
This design is similar to the time-constrained threads facility
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:TimeConstrainedThread"

\end_inset

 in the Darwin kernel of Apple’s OS
\begin_inset space ~
\end_inset

X.
 It offers ordinary applications an interface to specify a period and an
 execution time requirement.
 The kernel however reserves the right to demote threads to best-effort
 scheduling to defend against denial of service.
\end_layout

\begin_layout Standard
In summary, 
\noun on
Atlas
\noun default
 provides the same scheduling behavior to periodic tasks as a fixed-priority
 scheduler, but without inheriting its vulnerability against failing jobs.
 
\noun on
Atlas
\noun default
 handles such jobs similarly to Darwin’s time-constrained threads, but without
 requiring developers to report execution times.
 Due to the constant execution time of Bodytrack’s jobs, enabling 
\noun on
Atlas
\noun default
 scheduling was only a matter of reporting the deadline, leaving execution
 time recognition to the runtime.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/3-Real-Time/UI_Worker.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:User-Interface-Test"

\end_inset

User Interface Test Application
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Graphical user interface code
\end_layout

\end_inset

 has timing requirements much different from a classical periodic task.
 Spontaneous user interaction releases jobs without prior warning and not
 bound to a period.
 With the next set of experiments, I evaluate how 
\noun on
Atlas
\noun default
 handles such jobs.
 I developed a test application based on GTK+,
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "GTK+"
target "http://www.gtk.org/"

\end_inset


\end_layout

\end_inset

 is a multi-platform toolkit for creating graphical user interfaces.
\end_layout

\end_inset

 the standard application framework for the GNOME
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "GNOME"
target "https://www.gnome.org/"

\end_inset


\end_layout

\end_inset

 is the standard desktop for the Ubuntu Linux distribution.
\end_layout

\end_inset

 desktop environment.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:User-Interface-Test"

\end_inset

 shows the minimal user interface.
 A click on the only button triggers work that uses the 
\begin_inset Flex NoWrap
status collapsed

\begin_layout Plain Layout
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
strcasestr()
\end_layout

\end_inset


\end_layout

\end_inset

 function to simulate searching a word in a document.
 For each click, the scanned memory is chosen randomly between 64 and 128
\begin_inset space \thinspace{}
\end_inset

MiB.
 The chosen size is passed as the only workload metric and the work is submitted
 to execute asynchronously with a deadline of 
\begin_inset Formula $100\,\mathrm{ms}$
\end_inset

, a typical time bound where users perceive a system response as immediate.
\begin_inset CommandInset citation
LatexCommand cite
after "-3\\baselineskip"
key "Card:RealTimeUI"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 
\noun on
Atlas
\noun default
 scheduling is integrated into the button click handler with just seven
 lines of code as shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Pseudocode-ATLAS"

\end_inset

:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
enlargethispage{1
\backslash
baselineskip}
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
page size extended
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

double metrics[] = { size };
\end_layout

\begin_layout Plain Layout

atlas_job_t job = {
\end_layout

\begin_layout Plain Layout

	.deadline = atlas_now() + 0.1,
\end_layout

\begin_layout Plain Layout

	.metrics_count = 1,
\end_layout

\begin_layout Plain Layout

	.metrics = metrics
\end_layout

\begin_layout Plain Layout

};
\end_layout

\begin_layout Plain Layout

dispatch_async_atlas(queue, job, ^{ scan_document(size); });
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Pseudocode-ATLAS"

\end_inset

Pseudocode for 
\noun on
Atlas
\noun default
 Scheduling in Worker
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-mar:Worker-Execution-Time"

\end_inset

 displays the accuracy of the predicted execution times.
 The test application can be used interactively, but for the experiments,
 the button is “clicked” programmatically.
 Two clicks are separated by a randomly chosen interval between 
\begin_inset Formula $0.5$
\end_inset

 and 
\begin_inset Formula $1.5$
\end_inset


\begin_inset space ~
\end_inset

seconds.
 The experiments run for five minutes.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/UI_Worker_Schedule.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-fig:Worker-Makespan"

\end_inset

Worker Makespan Histograms
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-fig:Worker-Makespan"

\end_inset

 demonstrates the benefit of using 
\noun on
Atlas
\noun default
 by visualizing the job makespan, i.e., the time between release and completion.
 Makespan lengths below 
\begin_inset Formula $100\,\mathrm{ms}$
\end_inset

 meet the specified deadline.
 The first subfigure shows the worker scheduled by CFS and executing with
 no concurrent load.
 All jobs finish before their deadline.
 We observe the same completion behavior in the second subfigure, where
 the application is scheduled by 
\noun on
Atlas.

\noun default
 Without background load, 
\noun on
Atlas
\noun default
-scheduled jobs finish as early as CFS-scheduled work.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Data/3-Real-Time/UI_Worker_Alone.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-mar:Worker-Execution-Time"

\end_inset

Worker Execution Time Prediction
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The third subfigure adds background load.
 When scheduled by CFS, the competing load causes excessive deadline misses,
 with jobs taking up to one second to complete.
 The last subfigure illustrates the 
\noun on
Atlas
\noun default
 behavior of scheduling real-time work as late as possible, but reliably
 completing all jobs before their deadline.
\end_layout

\begin_layout Standard
This noticeable advantage of 
\noun on
Atlas
\noun default
 over CFS for spontaneous jobs was not expected, because CFS employs a concept
 called sleeper fairness
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
sleeper fairness
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Molnar:SleeperFairness"

\end_inset

 to prioritize threads waking from sleep over continuously running background
 activity.
 The test application sleeps for long intervals in between its short bursts
 of activity, so it should receive preferential treatment by CFS.
 However, we have clearly seen that this heuristic is insufficient and that
 the 
\noun on
Atlas
\noun default
 scheduler is better suited to ensure application responsiveness.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I now turn to FFplay
\end_layout

\end_inset

 to evaluate the scheduling behavior of 
\noun on
Atlas
\noun default
 with a complex real-world application with highly dynamic resource requirements.
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
evaluation
\end_layout

\begin_deeper
\begin_layout Itemize
use complex video player to evaluate dynamic real application
\end_layout

\begin_deeper
\begin_layout Itemize
timeliness against a fair share scheduler
\end_layout

\begin_layout Itemize
timeliness against CBS-style reservation?
\end_layout

\begin_layout Itemize
no support for IO, only blocking for other CPU jobs works as intended
\end_layout

\begin_layout Itemize
compare keep-the-queue-filled deadlines with tight deadlines
\end_layout

\end_deeper
\begin_layout Itemize
more than one application concurrently scheduled by 
\noun on
Atlas
\end_layout

\begin_layout Itemize
system can predict deadline misses, even though it does not have implicit
 clairvoyance from periods
\end_layout

\end_deeper
\begin_layout Itemize
discuss related work in detail
\end_layout

\begin_deeper
\begin_layout Itemize
explore the spectrum introduced above, compare approaches to describe timing
 and resource requirements
\end_layout

\begin_deeper
\begin_layout Itemize
frame this in a two-dimensional map instead? flexible/weak – rigid/strong;
 fluid flow – individual jobs
\end_layout

\begin_layout Itemize
discuss clusters first and then provide details for each cluster
\end_layout

\end_deeper
\begin_layout Itemize
figure out where these fit in, maybe move to earlier discussions
\end_layout

\begin_deeper
\begin_layout Itemize
resource kernels
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

 separate concerns top-down: applications specify, scheduler manages time
\end_layout

\begin_deeper
\begin_layout Itemize
similar insight into task model: requirements state explicitly, execution
 time is not portable, calibrate automatically
\end_layout

\begin_layout Itemize
otherwise very close to periodic tasks
\end_layout

\begin_layout Itemize
decouple different resources with buffering
\end_layout

\end_deeper
\begin_layout Itemize
ARTIFACT
\begin_inset CommandInset citation
LatexCommand cite
key "Sasinowski:ARTIFACT"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
ubiquitous priorities, MPEG execution model hard, load-shedding (forward
 reference to adaptivity)
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
fixed-priority approaches: strongest guarantees possible, minimal implementation
\end_layout

\begin_deeper
\begin_layout Itemize
expose scheduler implementation to user-land, other task models would be
 implemented on top
\end_layout

\begin_deeper
\begin_layout Itemize
microkernel bottom-up paradigm
\end_layout

\begin_layout Itemize
used in practice: QNX in the BlackBerry PlayBook
\end_layout

\end_deeper
\begin_layout Itemize
view shared with Nemesis
\begin_inset CommandInset citation
LatexCommand cite
key "Leslie:Nemesis"

\end_inset

: fixed priorities require full analysis of the system to determine the
 priorities
\end_layout

\begin_layout Itemize
periodic tasks with probabilistic admission
\begin_inset CommandInset citation
LatexCommand cite
key "Hamann:QAS,Hamann:QRMS"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
more flexible resource requirements than strict periodic tasks, probabilistic
 admission
\end_layout

\begin_layout Itemize
higher utilization, but still using period for timing requirements
\end_layout

\begin_layout Itemize
QRMS runs on top of fixed priority scheduling
\end_layout

\end_deeper
\begin_layout Itemize
RT in Linux
\end_layout

\begin_deeper
\begin_layout Itemize
SCHED_RR, SCHED_FIFO
\end_layout

\begin_layout Itemize
RT-patch adds SCHED_DEADLINE, previously SCHED_EDF
\begin_inset CommandInset citation
LatexCommand cite
key "Faggioli:SCHED_EDF"

\end_inset


\end_layout

\begin_layout Itemize
only for root processes
\end_layout

\begin_layout Itemize
no look-ahead
\end_layout

\end_deeper
\begin_layout Itemize
event streams
\begin_inset CommandInset citation
LatexCommand cite
key "Albers:EventStreams"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
allow periodic jobs with jitter and sporadic jobs
\end_layout

\begin_layout Itemize
still targets strong analysis rather than easy programming
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
reservation approaches: focus on isolation
\end_layout

\begin_deeper
\begin_layout Itemize
integration of hard real-time, soft real-time and best effort: RBED
\begin_inset CommandInset citation
LatexCommand cite
key "Brandt:RBED"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
focus in integration while preserving strong guarantees
\end_layout

\begin_layout Itemize
underlying hard real-time EDF scheduler, resource allocator on top protects
 EDF scheduler from overload
\end_layout

\begin_layout Itemize
key insight: separate resource management from resource dispatching
\end_layout

\begin_layout Itemize
starts with periodic task model and calculates relaxation bounds for parameters
 that keep the schedule feasible
\end_layout

\begin_layout Itemize
applications can submit jobs with parameters within those bounds
\end_layout

\begin_layout Itemize
set_rbed_scheduler() and rbed_deadline_met() calls similar to submit/next
\end_layout

\end_deeper
\begin_layout Itemize
Constant Bandwidth Server
\begin_inset CommandInset citation
LatexCommand cite
key "Abeni:CBS"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
employs EDF as the fundamental scheduler
\end_layout

\begin_layout Itemize
provides temporal isolation: protect hard real-time tasks from the messy
 soft real-time tasks
\end_layout

\begin_layout Itemize
different world view: illusion of a dedicated slower processor
\end_layout

\begin_layout Itemize
fluid flow allocation contradicts the job style, more amenable to threads
\end_layout

\begin_layout Itemize
server manages the deadlines (assignment, postponing), not the application
\end_layout

\begin_layout Itemize
does not target improving the soft-real time workload, thus somewhat orthogonal
 to this work
\end_layout

\begin_layout Itemize
could be used to provide isolated hard real-time load in our system
\end_layout

\begin_layout Itemize
see also: Total Bandwidth Server (“Efficient Aperiodic Service under Earliest
 Deadline First”)
\end_layout

\end_deeper
\begin_layout Itemize
slack reclamation
\begin_inset CommandInset citation
LatexCommand cite
key "Caccamo:SlackReclaiming"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
similar to 
\noun on
Atlas
\noun default
 EDF-headstart
\end_layout

\begin_layout Itemize
they: server is EDF-scheduled, picks slack time; here: slack time handed
 to CFS, picks next EDF-job
\end_layout

\end_deeper
\begin_layout Itemize
adaptive reservations
\begin_inset CommandInset citation
LatexCommand cite
key "Abeni:AdaptiveReservations"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
similarities: no worst-case planning, because it is wasteful; no focus on
 preventing every single deadline violation
\end_layout

\begin_layout Itemize
overload handling instead of admission
\end_layout

\begin_layout Itemize
two layer approach: dedicated controller per task like estimator
\end_layout

\begin_layout Itemize
dynamic bandwidth adaptation to workload as an afterthought
\end_layout

\begin_layout Itemize
control remembers the past and predicts from there, chaotic jumps are eased
 after they occurred
\end_layout

\begin_layout Itemize

\noun on
Atlas
\noun default
 can preconceive jumps from metrics and predict much tighter
\end_layout

\begin_layout Itemize
both control and 
\noun on
Atlas
\noun default
 assume that extrapolation from past behavior works
\end_layout

\begin_layout Itemize
my predictor can be used in a reservation-based system
\end_layout

\begin_layout Itemize
finishing work until the deadline matters, abstracting from the application's
 work pattern using reservations makes this harder to accomplish and requires
 more complexity in control layer
\end_layout

\begin_layout Itemize
CBS covers the real temporal behavior of the application, now we try to
 recreate that in the control layer
\end_layout

\end_deeper
\begin_layout Itemize
slack reclaiming added to CBS
\begin_inset CommandInset citation
LatexCommand cite
key "Palopoli:FeedbackReclaiming"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
results in AQuoSA
\begin_inset CommandInset citation
LatexCommand cite
key "Palopoli:AQuoSA"

\end_inset

 system
\end_layout

\end_deeper
\begin_layout Itemize
workload insight for video
\begin_inset CommandInset citation
LatexCommand cite
key "Ditze:MPEG_Utilization"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
repeatedly run admission with some granularity like GOPs
\end_layout

\begin_layout Itemize
do not plan for global worst-case, but for the worst-case within the admission
 window
\end_layout

\begin_layout Itemize
peak notification embedded in user-data fields of video stream
\end_layout

\begin_layout Itemize

\noun on
Atlas
\noun default
 takes this idea to the max an predicts not just peaks but every job and
 reserves time not for a GOP-sized admission window, but for individual
 jobs
\end_layout

\end_deeper
\begin_layout Itemize
AIRS
\begin_inset CommandInset citation
LatexCommand cite
key "Kato:AIRS"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
CBS-based reservations combined with EDF-WM multicore scheduler
\end_layout

\begin_layout Itemize
reservation extends CBS to reclaim slack
\end_layout

\begin_layout Itemize
no evaluation against freely migrating schedulers such as CFS
\end_layout

\end_deeper
\begin_layout Itemize
Self-tuning scheduler
\begin_inset CommandInset citation
LatexCommand cite
key "Cucinotta:Self-Tuning"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
treat existing real-time application as black box: 
\begin_inset Quotes eld
\end_inset

applications that are characterized by some temporal constraints, but are
 not developed using a specific API
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
insight: applications have real-time behavior but do not expose it, I modify
 applications and allow them to expose this
\end_layout

\begin_layout Itemize
estimate period and execution time by looking at its outside behavior
\end_layout

\begin_layout Itemize
study in this paper: choosing the wrong scheduling period causes deadline
 misses or over-allocation, so schedulers that decouple scheduling period
 from application period can be inefficient
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
fair processor sharing: minimal interface
\end_layout

\begin_deeper
\begin_layout Itemize
historical context: fairness between users time-sharing system
\end_layout

\begin_layout Itemize
good average application behavior when developers do nothing
\end_layout

\begin_layout Itemize
starts with no interface to expose anything
\end_layout

\begin_layout Itemize
virtual time approaches, like CFS
\begin_inset CommandInset citation
LatexCommand cite
key "Molnar:CFS"

\end_inset

 in Linux
\end_layout

\begin_layout Itemize
research approaches start out as fair sharing and add twists
\begin_inset CommandInset citation
LatexCommand cite
key "Bavier:VirtualTime"

\end_inset


\end_layout

\begin_layout Itemize
while coming from the other end, it overlaps with reservation approaches
 in the spectrum:
\end_layout

\begin_deeper
\begin_layout Itemize
sharing based on cycle rates with slack reclaiming similar to CBS work
\end_layout

\begin_layout Itemize
timing guarantees for virtual-time based algorithms are possible by showing
 bounded deadline overrun
\begin_inset CommandInset citation
LatexCommand cite
key "Stoica:ProportionalShareRT"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
BVT
\begin_inset CommandInset citation
LatexCommand cite
key "Duda:BVT"

\end_inset

 adds a warp to express dispatch priority
\end_layout

\begin_deeper
\begin_layout Itemize
many task parameters (CPU share, warp time, warp time limit, warp time requireme
nt) require global knowledge, some dimensionless, not inherent to application
\end_layout

\begin_layout Itemize
warp time is a priority, admission control needed to control the assignment
 of warp parameters
\end_layout

\end_deeper
\begin_layout Itemize
BERT
\begin_inset CommandInset citation
LatexCommand cite
key "Bavier:BERT"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
virtual-clock-based scheduler combines of EDF and proportional share: tasks
 receive a share of cycles before a given deadline
\end_layout

\begin_layout Itemize
tasks reserve time according to a feedback estimator
\end_layout

\begin_layout Itemize
feedback is coarse grained (in the order of seconds) and only aligns allocation
 and actual use in the long term
\end_layout

\begin_layout Itemize

\noun on
Atlas
\noun default
 aims for precise allocation of every job
\end_layout

\begin_layout Itemize
on load spikes, cycles are stolen from lower priorities; similar to CBS
 with adaptive reservations
\end_layout

\begin_layout Itemize
strict priorities for stealing
\end_layout

\begin_layout Itemize
stealing in BERT in unbounded, no guarantees for the lower priority tasks
\end_layout

\begin_layout Itemize

\noun on
Atlas
\noun default
 uses CFS preroll to gain extra cycles without harming any guarantees
\end_layout

\end_deeper
\begin_layout Itemize
BEST
\begin_inset CommandInset citation
LatexCommand cite
key "Banachowski:BEST"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
auto-detection of periods by observing when process enters ready queue
\end_layout

\begin_layout Itemize
assign deadlines based on periods, schedule by EDF
\end_layout

\begin_layout Itemize
period detection should be problematic for multithreaded producer-consumer
 setups
\end_layout

\begin_layout Itemize
evaluation covers single-threaded applications only
\end_layout

\end_deeper
\begin_layout Itemize
Real-Rate Scheduling
\begin_inset CommandInset citation
LatexCommand cite
key "Steere:RealRate"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
task model based on period and proportion
\end_layout

\begin_layout Itemize
estimate both by a feedback loop at runtime
\end_layout

\begin_layout Itemize
adapt CPU-share according to application-exposed progress hints
\end_layout

\begin_layout Itemize
for example buffer fill level in producer-consumer-scenario
\end_layout

\end_deeper
\begin_layout Itemize
Nemesis
\begin_inset CommandInset citation
LatexCommand cite
key "Leslie:Nemesis"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
criticism of virtual processors (fair sharing): performance of each virtual
 processor depends on load on other virtual processors
\end_layout

\begin_layout Itemize
both fixed priorities and virtual processors require global knowledge to
 predict their behavior
\end_layout

\begin_layout Itemize
basic idea: free developer from determining resource requirements
\end_layout

\begin_layout Itemize
use feedback control
\end_layout

\end_deeper
\begin_layout Itemize
like reservations, virtual time put isolation first and application’s timing
 requirements second
\end_layout

\begin_deeper
\begin_layout Itemize
some of the above work tries to retrofit timing requirements into the fair
 sharing concept
\end_layout

\begin_layout Itemize
my approach: put applications first, consider fairness only on overload
\end_layout

\begin_layout Itemize
without global coordination, applications should specify timing requirements
 directly, not as relative importance using weights or shares
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
whole-system approaches: lightweight specification
\end_layout

\begin_deeper
\begin_layout Itemize
SMART
\begin_inset CommandInset citation
LatexCommand cite
key "Nieh:SMART"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
deadlines from application, priorities and relative shares configured by
 user
\end_layout

\begin_layout Itemize
respects timing until system is overloaded
\end_layout

\begin_layout Itemize
when overloaded, only shares are guaranteed, which are context-sensitive
\end_layout

\begin_layout Itemize
rationale for fairness: responsiveness under overload
\end_layout

\begin_layout Itemize
for 
\noun on
Atlas
\noun default
, the LRT-band always comes first; responsiveness is real-time and should
 be expressed by deadline
\end_layout

\begin_layout Itemize
in the presence of a compute-bound non-real-time application, the system
 is immediately overloaded
\end_layout

\begin_layout Itemize
a background calculation without time constraints can squeeze down real-time
 applications
\end_layout

\end_deeper
\begin_layout Itemize
Redline
\begin_inset CommandInset citation
LatexCommand cite
key "Yang:Redline"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "Redline Slides"
target "http://os.inf.tu-dresden.de/local/dropscon/archive/2008-12-03-Michael-Redline.pdf"

\end_inset


\end_layout

\begin_layout Itemize
also no modifications to applications
\end_layout

\begin_layout Itemize
manual annotation with period and fixed execution time
\end_layout

\begin_layout Itemize
will adapt parameters at runtime using feedback
\end_layout

\begin_layout Itemize
uses EDF scheduler
\end_layout

\end_deeper
\begin_layout Itemize
coop_poll
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:CoopPoll"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
uses application insight, no black-box approach, applications explicitly
 expose knowledge
\end_layout

\begin_layout Itemize
propagates application's task descriptions down to the kernel, but without
 look-ahead
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Itemize
future work: device IO
\end_layout

\begin_deeper
\begin_layout Itemize
propagate deadlines to device queues when jobs issue IO requests
\end_layout

\begin_layout Itemize
helps anticipatory schedulers
\begin_inset CommandInset citation
LatexCommand cite
key "Iyer:Anticipatory"

\end_inset


\end_layout

\begin_layout Itemize
propagate future jobs to devices for prefetching
\begin_inset CommandInset citation
LatexCommand cite
key "Patterson:InformedPrefetching"

\end_inset


\end_layout

\begin_layout Itemize
asynchronous device access and queue-ahead of upcoming jobs: provides the
 same look-ahead for device IO
\end_layout

\begin_deeper
\begin_layout Itemize
fostered by GCD dispatch sources and Boost.Asio
\end_layout

\end_deeper
\begin_layout Itemize
devices become smart and self-schedule: manage the queue themselves
\end_layout

\begin_deeper
\begin_layout Itemize
example: interrupt rate limiting, low-latency packet override and another
 rate limiting for the low-latency override in Intel 82576 network card
\begin_inset CommandInset citation
LatexCommand cite
key "Intel_NIC"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
submit code directly to such smart devices, run the scheduler on the device
\begin_inset CommandInset citation
LatexCommand cite
key "Nightingale:Helios"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Dynamic Active Subset helps
\begin_inset CommandInset citation
LatexCommand cite
key "Reuther:DAS"

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "4-chap:Adaptivity"

\end_inset

Adapt to Handle Overload
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
our 
\begin_inset Quotes eld
\end_inset

no admission
\begin_inset Quotes erd
\end_inset

 policy requires us to deal with overloads when the work does not fit within
 the deadlines
\end_layout

\begin_deeper
\begin_layout Itemize
but only when overloaded: timeliness first, fairness only when overloaded
\end_layout

\begin_layout Itemize
decouple urgency (timing requirements) and importance (utility)
\end_layout

\begin_layout Itemize

\noun on
Atlas
\noun default
 flexibility stems from admitting on job-level instead of task-level
\end_layout

\begin_layout Itemize
job admission does not reject, but inform
\end_layout

\begin_layout Itemize
applications decide how to react, because only they know how to adapt
\end_layout

\begin_layout Itemize
no central one-size-fits-all job dropping or deadline tardiness
\end_layout

\end_deeper
\begin_layout Itemize
load shedding is an old concept
\begin_inset CommandInset citation
LatexCommand cite
key "Lampson:HintsDesign"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

shed load to control demand, rather than allowing the system to become overloade
d.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
do not waste work by learning after the fact that you missed the deadline
\end_layout

\begin_layout Itemize
Robert Morris idea: red button next to terminal, push when dissatisfied,
 system must raise your QoS or throw you off
\end_layout

\begin_layout Itemize
this old idea already argued for quality-aware adaptation, not just load-aware
\end_layout

\begin_layout Itemize
when overloaded, real-time applications become brittle and show bi-modal
 fairness
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:PriorityProgress"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
quality-aware adaptation is application-specific
\end_layout

\begin_deeper
\begin_layout Itemize
some work just needs to be done, no discussion, no adaptation possible
\end_layout

\begin_deeper
\begin_layout Itemize
I would argue this is the common case
\end_layout

\begin_layout Itemize
we can only hope to compensate by using the most efficient compute resource
 and organize it the most efficient way
\end_layout

\end_deeper
\begin_layout Itemize
some applications can make quality/resource trade-offs according to application-
specific notion of quality
\end_layout

\begin_deeper
\begin_layout Itemize
video is one example
\end_layout

\begin_layout Itemize
however, quality per invested CPU time is varying: with resource-fairness,
 quality would be varying
\end_layout

\begin_layout Itemize
application knowledge needed, however applications can lie to unfairly degrade
 others
\end_layout

\begin_layout Itemize
combine resource-fairness and quality-fairness
\end_layout

\begin_layout Itemize
this also applies to resources other than CPU time, like network bandwidth
 for streaming
\end_layout

\end_deeper
\begin_layout Itemize
better behavior for more developer effort
\end_layout

\begin_layout Itemize
look-ahead enables choosing the part to degrade amongst many options, compared
 to forcibly degrade the job at hand
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end solution
\end_layout

\begin_deeper
\begin_layout Itemize
workload: offer different processing paths, trading resources and quality
\end_layout

\begin_layout Itemize
application: under given resource constraints, find a quality-optimal path
 through this lattice of options
\end_layout

\begin_layout Itemize
system: distribute computing resource cutbacks in a quality-fair fashion
\end_layout

\end_deeper
\begin_layout Itemize
backpressure needs to be quality-fair, not resource-fair, but the quality
 scale is application specific and does not compare
\end_layout

\begin_deeper
\begin_layout Itemize
global quality-scheduling too complex, resort to balanced backpressure and
 per-application adaptivity
\end_layout

\begin_layout Itemize
needs help from the applications: provide percentage of missed deadlines
 relative to the maximum quality case, that represents the bare minimum
 quality users will accept
\end_layout

\begin_layout Itemize
backpressure will be distributed amongst adaptive applications weighted
 by this minimum quality
\end_layout

\begin_layout Itemize
assumption: linear quality drop from meeting all deadlines down to that
 percentage
\end_layout

\begin_deeper
\begin_layout Itemize
could also use time-utility functions to optimize
\end_layout

\begin_layout Itemize
could also include heuristics like less degradation for the frontmost applicatio
n
\end_layout

\end_deeper
\begin_layout Itemize
use of percentage of missed deadlines as quality parameter inspired by QRMS
\begin_inset CommandInset citation
LatexCommand cite
key "Hamann:QRMS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
describe fallback decoding path for video
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:VideoQuality"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
decoding time estimate already given, quality estimate needed
\end_layout

\begin_layout Itemize
greedy solution for (constrained) bin-packing: order jobs by quality/resource
 ratio
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end evaluation
\end_layout

\begin_deeper
\begin_layout Itemize
compare reduction policy in scheduler: quality-based vs.
 fairness-based
\end_layout

\begin_layout Itemize
compare to ad-hoc adaptation using a low water-mark in the video player
 queue
\end_layout

\begin_layout Itemize
compare to fully clairvoyant oracle that calculates truly quality-optimal
 execution
\end_layout

\end_deeper
\begin_layout Itemize
discuss related work
\end_layout

\begin_deeper
\begin_layout Itemize
other fairness-policies can be integrated into my system as well
\end_layout

\begin_deeper
\begin_layout Itemize
relative or absolute shares for temporal isolation, like CBS
\end_layout

\end_deeper
\begin_layout Itemize
task models that allow for deadline misses
\end_layout

\begin_deeper
\begin_layout Itemize
(m,k)-firm tasks
\end_layout

\begin_layout Itemize
imprecise computation
\begin_inset CommandInset citation
LatexCommand cite
key "Lin:Imprecise"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
scheduling systems that control overload
\end_layout

\begin_deeper
\begin_layout Itemize
overload handling with adaptive reservations
\begin_inset CommandInset citation
LatexCommand cite
key "Abeni:AdaptiveReservations"

\end_inset


\end_layout

\begin_layout Itemize
real-rate scheduling reduces allocations weighted by an importance value
\begin_inset CommandInset citation
LatexCommand cite
key "Steere:RealRate"

\end_inset


\end_layout

\begin_layout Itemize
virtual time for progress fairness
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:CoopPoll"

\end_inset


\end_layout

\begin_layout Itemize
application notifications using execution time estimates
\begin_inset CommandInset citation
LatexCommand cite
key "Nieh:SMART"

\end_inset

, but no look-ahead
\end_layout

\begin_layout Itemize
BERT
\begin_inset CommandInset citation
LatexCommand cite
key "Bavier:BERT"

\end_inset

: no strict task admission, but overload mitigation; job-shedding, when
 latest release time is in the past
\end_layout

\begin_layout Itemize
resource kernels
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

: user-level QoS expected to be more useful than stacked schedulers
\end_layout

\begin_layout Itemize
expose application-internal settings and QoS expectations for global management
\begin_inset CommandInset citation
LatexCommand cite
key "Hoffmann:PowerDial"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
also based on training phase
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
overload notification
\end_layout

\begin_deeper
\begin_layout Itemize
inject language exceptions on deadline overruns: post-mortem, no look-ahead
\end_layout

\end_deeper
\begin_layout Itemize
application-specific adaptation
\end_layout

\begin_deeper
\begin_layout Itemize
load-shedding queues in network servers
\begin_inset CommandInset citation
LatexCommand cite
key "Welsh:SEDA"

\end_inset


\end_layout

\begin_layout Itemize
reducing video quality
\begin_inset CommandInset citation
LatexCommand cite
key "Isovic:QoS_Video,Wuest:QoS_Video"

\end_inset


\end_layout

\begin_layout Itemize
other sources for adaptive video
\end_layout

\begin_deeper
\begin_layout Itemize
SVC
\end_layout

\begin_layout Itemize
adaptive streaming protocols: application propagates back-pressure even
 to the server
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
prioritize work and skip the low priorities when congested
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:PriorityProgress"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
simple quality-aware scheme
\end_layout

\begin_layout Itemize
global priority-monotonic ordering of video frames
\end_layout

\begin_layout Itemize
unclear how much of the fairness benefits stem from the priority sorting
 or just from global queueing
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "5-chap:The-Road-Ahead"

\end_inset

The Road Ahead
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Chapter
Scheduling Meets Multicore
\end_layout

\begin_layout Itemize
For jobs with internal parallelism, 
\noun on
Atlas
\noun default
 can trade using more cores against using more time on fewer cores.
 In order to make those decisions, it needs information about the available
 parallelism and speedup.
 Placement of work on cores also influences execution times due to contention
 on shared caches and memory.
\begin_inset CommandInset citation
LatexCommand cite
key "Zhuravlev:DIO"

\end_inset


\end_layout

\begin_deeper
\begin_layout Plain Layout
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Data/5-Road-Ahead/Parallel_Execution_Alternatives.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Parallel-Execution-Alternatives"

\end_inset

Parallel Execution Alternatives
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I contribute a collaboration mechanism
\end_layout

\end_inset

 that allows applications to propagate the degree of parallelism to the
 scheduler.
 Integrating with the lambda programming-style, I tap into the application
 to automatically deduce available parallelism and to maintain a model of
 the parallel speedup:
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
parallel speedup
\end_layout

\end_inset

 For each number of cores a job can make use of, the scheduler receives
 an execution time estimate as illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Parallel-Execution-Alternatives"

\end_inset

.
 
\noun on
Atlas
\noun default
 predicts these alternative resource requirements ahead of time, allowing
 look-ahead scheduling.
\end_layout

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I claim that the rich information
\end_layout

\end_inset

 provided by applications allows non-work-conserving scheduling
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
non-work-conserving scheduling
\end_layout

\end_inset

 disciplines that reduce core allocation more aggressively than competing
 approaches.
 A non-work-conserving scheduler deliberately keeps cores idle even though
 runnable threads are available.
 
\noun on
Atlas
\noun default
 knows about the resource requirements of jobs, so it can select a core
 assignment that uses a minimum number of cores while still meeting all
 timing requirements.
 The schedulers in commodity operating systems are work-conserving.
 They lack this knowledge and therefore occupy cores eagerly.
\end_layout

\begin_layout Plain Layout
Because parallel speedup is typically sub-linear,
\begin_inset CommandInset citation
LatexCommand cite
key "Amdahl:AmdahlsLaw"

\end_inset

 reducing core allocation reduces the overhead that comes with parallel
 execution.
 Single-core execution would achieve the lowest overhead, but also yields
 the worst response time.
 Timing requirements constrain this optimization problem by imposing a limit
 on the tolerated response time.
 Existing real-time research relies on the implicit knowledge of future
 jobs provided by periodic task models.
\begin_inset CommandInset citation
LatexCommand cite
key "Collette:JobParallelism"

\end_inset

 I show how look-ahead scheduling reduces core allocation compared to the
 worst-case planning implied by periodic tasks.
\end_layout

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Non-work-conserving scheduling policies
\end_layout

\end_inset

 have been researched before to improve response times
\begin_inset CommandInset citation
LatexCommand cite
key "Rosti:NWC_Partitioning"

\end_inset

 or throughput.
\begin_inset CommandInset citation
LatexCommand cite
key "Fedorova:SMT_Scheduling"

\end_inset

 Keeping idle cores as spares to cater for future job arrivals reduces overall
 response times, however future arrivals are merely guessed from past observatio
ns.
 Throughput can suffer, when co-scheduled jobs causes thrashing on shared
 resources such as the last-level cache.
 In such cases, deliberately not using all the available parallelism increases
 instruction throughput.
 We can observe similar behavior with magnetic disks: Interleaving requests
 from two different applications can cause more disk-head movements and
 thus lower throughput compared to briefly idling the disk to allow for
 batching of consecutive requests from the same application.
\begin_inset CommandInset citation
LatexCommand cite
key "Iyer:Anticipatory"

\end_inset

 These solutions do not exploit knowledge of timing requirements, resource
 requirements or the benefit of look-ahead.
\end_layout

\begin_layout Plain Layout
I present and discuss parallel speedup estimation and the non-work-conserving
 scheduler in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Parallelism"

\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
multicores add another scheduling dimension: placement in space accompanies
 ordering in time
\end_layout

\begin_layout Itemize
scheduling in time is being deemphasized
\end_layout

\begin_deeper
\begin_layout Itemize
context switching used to be practical when many threads needed to be multiplexe
d in quasi-parallel fashion on one CPU
\end_layout

\begin_layout Itemize
with the number of cores approaching the number of ready threads, this approach
 gets impractical
\end_layout

\begin_layout Itemize
micro-benchmarks show cache-miss-related slowdown caused by only the timer
 tick
\begin_inset CommandInset citation
LatexCommand cite
key "Tsafrir:OSNoise"

\end_inset


\end_layout

\begin_layout Itemize
hardware transactional memory aborts on context switch
\begin_inset CommandInset citation
LatexCommand cite
key "AMD_ASF_Spec"

\end_inset


\end_layout

\begin_layout Itemize
many other resources cannot be preempted at all
\end_layout

\begin_deeper
\begin_layout Itemize
disk jobs
\end_layout

\begin_layout Itemize
GPUs get preemption functionality, but there is a lot of state to save and
 restore
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
systems increasingly schedule in space instead of time
\end_layout

\begin_deeper
\begin_layout Itemize
parallelism is replacing frequency scaling as the means to increase performance
\end_layout

\begin_layout Itemize
Lampson predicted this
\begin_inset CommandInset citation
LatexCommand cite
key "Lampson:HintsDesign"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

split resources in a fixed way if in doubt, rather than sharing them
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
multiplex as long as hardware is expensive, statically assign once hardware
 is cheap
\end_layout

\end_deeper
\begin_layout Itemize
specialize cores dynamically to execute kernel services
\end_layout

\begin_layout Itemize
placement becomes all the more relevant when cores differentiate: specialized
 instruction sets, distance/latency gaps
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:ParallelJungle"

\end_inset


\end_layout

\begin_layout Itemize
need to choreograph heterogeneous accelerators or dynamically fuse cores
 (Core Fusion)
\end_layout

\begin_layout Itemize
shutting down cores is also an important mechanism to save energy, because
 DVFS is losing effectiveness
\begin_inset CommandInset citation
LatexCommand cite
key "LeSueur:DVFS"

\end_inset


\end_layout

\begin_layout Itemize
with small core counts and high single thread performance, a fair sharing
 scheduler plus a 
\begin_inset Quotes eld
\end_inset

do things as fast as you can
\begin_inset Quotes erd
\end_inset

 was good for real-time
\end_layout

\begin_layout Itemize
now the gap between 
\begin_inset Quotes eld
\end_inset

as fast as you can
\begin_inset Quotes erd
\end_inset

 and reasonable execution widens
\end_layout

\end_deeper
\begin_layout Itemize
lambda-programming removes threads from application development, now remove/demo
te them in kernel interface
\end_layout

\begin_deeper
\begin_layout Plain Layout
An illustrative analogy to the use of asynchronous lambdas instead of threads
 is the shift from circuit-switched networks to packet routing.
\begin_inset CommandInset citation
LatexCommand cite
key "MacResearch:AboardGrandCentral"

\end_inset


\end_layout

\begin_layout Itemize
similar ideas explored earlier: scheduler activations
\begin_inset CommandInset citation
LatexCommand cite
key "Anderson:SchedulerActivations"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
threads can be co-scheduled on one core, they hide spatial properties from
 the application
\end_layout

\begin_layout Itemize
applications often work around this by creating more threads than there
 are processors to make sure all hardware parallelism is exploited
\end_layout

\begin_layout Itemize
idea: assign cores to applications, not virtual sections of a core's time
 (i.e.
 threads)
\end_layout

\begin_layout Itemize
still need kernel-level execution contexts, which you may still call threads
\end_layout

\begin_layout Itemize
work queues offer parallelism, dispatching is separate, system can decide
 placement; threads blend this in one concept
\end_layout

\begin_layout Itemize
parallelism becomes controllable instead of being fixed in the application
 code
\end_layout

\end_deeper
\begin_layout Itemize
work queues can also be used to manage placement for other interfaces, like
 the systemcall interface to the kernel
\begin_inset CommandInset citation
LatexCommand cite
key "Soares:FlexSC"

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Queues_Mode_Switches.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Work Queues Prevent Mode Switches
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
improves throughput and (surprisingly) also latency when loaded
\end_layout

\begin_layout Itemize
extends the spine+workers programming model to workloads where the kernel
 is the worker (i.e.
 Internet servers)
\end_layout

\begin_layout Itemize
notifications from kernel to user space could work asynchronously, but don't
 as far as I know, closest: kqueue
\begin_inset CommandInset citation
LatexCommand cite
key "Lemon:Kqueue"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
asynchronous network packet API for 10Gbit/s speed at userlevel
\begin_inset CommandInset citation
LatexCommand cite
key "Rizzo:Netmap"

\end_inset

, asynchronous pipes for efficient TCP
\begin_inset CommandInset citation
LatexCommand cite
key "Han:MegaPipe"

\end_inset


\end_layout

\begin_layout Itemize
DSI on L4 and Fbufs
\begin_inset CommandInset citation
LatexCommand cite
key "Druschel:Fbufs"

\end_inset

 provides asynchronous data movement between different address spaces
\end_layout

\begin_layout Itemize
many throughput-oriented drivers (network cards) work this way, too
\end_layout

\begin_layout Itemize
work queues also used to drive GPUs predictably
\begin_inset CommandInset citation
LatexCommand cite
key "Kato:Timegraph"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Tetris
\begin_inset Quotes erd
\end_inset

 style scheduling: we want to know the widths and heights of jobs to plan
 placement and order
\end_layout

\begin_deeper
\begin_layout Itemize
prerequisite to implementing placement policies is sufficient information
 on what you place
\end_layout

\begin_layout Itemize
using asynchronous blocks for parallelism and deadlines and metrics attached
 to block groups for real-time, both are decoupled
\end_layout

\begin_deeper
\begin_layout Itemize
decoupling makes sense if you consider the trend to massive parallelism
 (see GPUs)
\end_layout

\begin_layout Itemize
no interest in the finishing time for a particular lambda, but in the overall
 makespan (paper: 
\begin_inset Quotes eld
\end_inset

makespan computation for GPU threads
\begin_inset Quotes erd
\end_inset

 in submission to ECRTS)
\end_layout

\begin_layout Itemize
on GPUs, the individual lambdas may be dispatched by hardware
\begin_inset CommandInset citation
LatexCommand cite
key "NVIDIA_Fermi"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
execution time estimates give us the total execution time, but when spread
 across cores, it might take less wall-clock time to finish
\end_layout

\begin_layout Itemize
application must provide execution time estimate for any number of cores
 the job can use
\end_layout

\begin_layout Itemize
the actual placement onto cores is a policy and should be orthogonal to
 the placement mechanism described above
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end solution
\end_layout

\begin_deeper
\begin_layout Itemize
workload: make amenable for data-parallel processing like intrinsic load-balanci
ng
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Balancing"

\end_inset


\end_layout

\begin_layout Itemize
application: offer parallelism to the system, provide estimates on parallel
 scalability
\end_layout

\begin_layout Itemize
system: policy-based placement of jobs on cores and order in time based
 on deadlines, execution time estimates and parallelism
\end_layout

\end_deeper
\begin_layout Itemize
describe parallel workload and placement algorithm in detail
\end_layout

\begin_deeper
\begin_layout Itemize
video parallelization and balancing
\end_layout

\begin_layout Itemize
system communicates consequences of placement decision back to the application
\end_layout

\begin_deeper
\begin_layout Itemize
number of threads to be used by GCD runtime
\end_layout

\begin_layout Itemize
avoid context-switch, so no upcall interface, but info-page-style shared
 memory
\end_layout

\end_deeper
\begin_layout Itemize
limitation: dependency fan-in/out for jobs not implemented in scheduler,
 only serial dependencies
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end evaluation
\end_layout

\begin_deeper
\begin_layout Itemize
example policy: non-work-conserving placement of jobs on one core as long
 as it fits, fire up second core only when necessary
\end_layout

\begin_layout Itemize
core count reduced more aggressively compared to:
\end_layout

\begin_deeper
\begin_layout Itemize
greedy commodity schedulers
\end_layout

\begin_layout Itemize
heuristics based on the past
\end_layout

\begin_layout Itemize
planning based on worst-case execution time and period
\begin_inset CommandInset citation
LatexCommand cite
key "Collette:JobParallelism"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
the number of kernel traps and process migrations could be lower in my system,
 because I assign cores exclusively (i.e.
 no time-slicing) for a while
\end_layout

\begin_layout Itemize
discuss sustainability?
\begin_inset CommandInset citation
LatexCommand cite
key "Baker:MultiprocessorSustainability"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
discuss related work in detail
\end_layout

\begin_deeper
\begin_layout Itemize
schedule in space instead of in time, demote threads
\end_layout

\begin_deeper
\begin_layout Itemize
kernel threads are the wrong abstraction
\begin_inset CommandInset citation
LatexCommand cite
key "Anderson:SchedulerActivations"

\end_inset


\end_layout

\begin_layout Itemize
communication of available parallelism from application to scheduler allows
 global core arbitration
\end_layout

\begin_layout Itemize
OS design for systems with 1000+ cores focus on space sharing instead of
 time sharing
\begin_inset CommandInset citation
LatexCommand cite
key "Wentzlaff:fos"

\end_inset


\end_layout

\begin_layout Itemize
even stronger separation between cores: explicit communication instead of
 cache coherent shared memory
\begin_inset CommandInset citation
LatexCommand cite
key "Baumann:Barrelfish"

\end_inset


\end_layout

\begin_layout Itemize
run parts of the system close or on the device they target
\begin_inset CommandInset citation
LatexCommand cite
key "Nightingale:Helios"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
existing placement strategies can augment our placement algorithm
\end_layout

\begin_deeper
\begin_layout Itemize
fits well with our programming model of applications exposing metadata on
 parallel work
\end_layout

\begin_layout Itemize
performance counters often used for runtime monitoring, like online cache
 utility modeling
\begin_inset CommandInset citation
LatexCommand cite
key "West:CacheUtility"

\end_inset

 and detection of sharing patterns
\begin_inset CommandInset citation
LatexCommand cite
key "Tam:SharingAwareScheduling"

\end_inset


\end_layout

\begin_layout Itemize
L2 cache misses is the primary metric that expresses locality of a job,
 because it covers the two major harmful communication paths: memory accesses
 and coherency traffic
\end_layout

\begin_layout Itemize
placement of jobs on cores influences contention on caches, prefetcher and
 DRAM controller
\begin_inset CommandInset citation
LatexCommand cite
key "Zhuravlev:DIO"

\end_inset


\end_layout

\begin_layout Itemize
cache thrashing with hyperthreads
\begin_inset CommandInset citation
LatexCommand cite
key "Fedorova:SMT_Scheduling"

\end_inset


\end_layout

\begin_layout Itemize
on NUMA-systems, placement influences memory latency
\begin_inset CommandInset citation
LatexCommand cite
key "Blagodurov:DINO"

\end_inset


\end_layout

\begin_layout Itemize
warm up caches on a second core using an active prefetch thread
\begin_inset CommandInset citation
LatexCommand cite
key "Kamruzzaman:Prefetching"

\end_inset


\end_layout

\begin_layout Itemize
batch work by moving it around in the scheduling window to enable longer
 sleep times
\begin_inset CommandInset citation
LatexCommand cite
key "Awan:EnhancedRaceToHalt"

\end_inset


\end_layout

\begin_layout Itemize
migrate to prevent fan noise or throttling
\begin_inset CommandInset citation
LatexCommand cite
key "Merkel:EnergyModel"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
with NUMA or discontiguous memory, data needs to travel when making placement
 decisions for code to run
\end_layout

\begin_deeper
\begin_layout Itemize
schedule for placement of data regions in caches
\begin_inset CommandInset citation
LatexCommand cite
key "Lee:RegionScheduling"

\end_inset


\end_layout

\begin_layout Itemize
out of scope for me, but an important future problem
\begin_inset CommandInset citation
LatexCommand cite
key "Knauerhase:ExtremeParallelism,Rossbach:PTask"

\end_inset


\end_layout

\begin_layout Itemize
fledgling industry solutions: dispatch_data, C++AMP array_view
\end_layout

\end_deeper
\begin_layout Itemize
real-time analysis can yield placement strategies with guaranteed timing
 properties
\end_layout

\begin_deeper
\begin_layout Itemize
so far for more limited models of parallelism like fork-join
\begin_inset CommandInset citation
LatexCommand cite
key "Lakshmanan:ParallelRealTimeTasks"

\end_inset


\end_layout

\begin_layout Itemize
G-EDF is optimal for soft real-time
\begin_inset CommandInset citation
LatexCommand cite
key "Devi:GEDFTardiness"

\end_inset


\end_layout

\begin_layout Itemize
G-EDF not optimal with respect to feasibility, but optimal deadline-based
 algorithms are known
\begin_inset CommandInset citation
LatexCommand cite
key "Levin:DP-Fair"

\end_inset


\end_layout

\begin_layout Itemize
efficient EDF implementation strategies are known for single cores
\begin_inset CommandInset citation
LatexCommand cite
key "Short:EDFTaskManagement"

\end_inset

 and multicores
\begin_inset CommandInset citation
LatexCommand cite
key "Lelli:Scalable_EDF"

\end_inset


\end_layout

\begin_layout Itemize
extensive scalability studies for multicores
\begin_inset CommandInset citation
LatexCommand cite
key "Brandenburg:GlobalEDF"

\end_inset


\end_layout

\begin_layout Itemize
G-EDF scales for today's core counts, in the future we may want to consider
 clustered scheduling
\begin_inset CommandInset citation
LatexCommand cite
key "Calandrino:ClusteredEDF"

\end_inset


\end_layout

\begin_layout Itemize
ongoing discussion on trading schedulability and locality using partitioning,
 clustering
\begin_inset CommandInset citation
LatexCommand cite
key "Bastoni:EmpiricalComparison"

\end_inset

 and semi-partitioning
\begin_inset CommandInset citation
LatexCommand cite
key "Bastoni:SemiPartitioned"

\end_inset

 (some tasks allowed to migrate)
\end_layout

\end_deeper
\begin_layout Itemize
execution order of blocks within a job is relevant for speed and cache working
 set size
\begin_inset CommandInset citation
LatexCommand cite
key "Chen:ConstructiveCacheSharing"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
chunking, placement and ordering influence speedup for confluent algorithms
\begin_inset CommandInset citation
LatexCommand cite
key "Kulkarni:GaloisScheduling"

\end_inset


\end_layout

\begin_layout Itemize
use a lightweight specification language to describe beneficial scheduling
 policies
\begin_inset CommandInset citation
LatexCommand cite
key "Nguyen:ConcurrentSchedulers"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
knowledge about the job layout in both space and time allows disabling the
 periodic timer tick
\end_layout

\begin_deeper
\begin_layout Itemize
dynamically dedicate cores: place work somewhere, then let it run without
 interference
\end_layout

\begin_deeper
\begin_layout Itemize
the timer-tick is OS-level polling, hits all cores no matter what they run
\end_layout

\begin_layout Itemize
move to a tick-less kernels helps to reducing OS noise and energy consumption
\end_layout

\end_deeper
\begin_layout Itemize
good for barrier-sync-style HPC applications: even the timer interrupt hurts
 them badly
\begin_inset CommandInset citation
LatexCommand cite
key "Tsafrir:OSNoise"

\end_inset


\end_layout

\begin_layout Itemize
suggested solution: demand-driven 
\begin_inset Quotes eld
\end_inset

smart
\begin_inset Quotes erd
\end_inset

 timers which allow for batching instead of the slavish periodic tick
\end_layout

\begin_deeper
\begin_layout Itemize
idea is an extension to timers with precision
\begin_inset CommandInset citation
LatexCommand cite
key "Peter:30Seconds"

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
hardware extensions supporting work queues and reduced context switching
\end_layout

\begin_deeper
\begin_layout Itemize
NVIDIA Fermi uses GigaThread hardware to decide placement
\begin_inset CommandInset citation
LatexCommand cite
key "NVIDIA_Fermi"

\end_inset


\end_layout

\begin_layout Itemize
Core Manager distributes work and its data to processing elements
\begin_inset CommandInset citation
LatexCommand cite
key "Limberg:Tomahawk"

\end_inset


\end_layout

\begin_layout Itemize
Asynchronous Direct Messages
\begin_inset CommandInset citation
LatexCommand cite
key "Sanchez:ADM"

\end_inset

 allow very fine-grained lambdas
\end_layout

\begin_deeper
\begin_layout Itemize
more flexible: small hardware extension to be used by work queue implementation
\end_layout

\begin_layout Itemize
allows exposing more parallelism by splitting into smaller lambdas
\end_layout

\begin_layout Itemize
scalable because of local queues and work stealing that bypasses the memory
 hierarchy
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
holistic approach that extends placement problems beyond individual computers
 to distributed systems: MOSIX
\end_layout

\begin_deeper
\begin_layout Itemize
load balancing on networks of computers, predicts future problems within
 manycores
\end_layout

\begin_layout Itemize
increasing message latency between cores relative to compute speed: placement
 of work and communication patterns relevant
\end_layout

\begin_layout Itemize
employs gossiping to establish global system view without a central authority
\end_layout

\begin_layout Itemize
ad-hoc solution for my approach: assume that lambdas within the same job
 are more likely to talk to each other, place closer together
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
changing paradigm of computing, future: always on, always connected
\end_layout

\begin_deeper
\begin_layout Itemize
smartphones, tablets and the cloud usher in a new era
\end_layout

\begin_layout Itemize
mobile computing, but still with responsiveness and smooth video demanded
 by users
\end_layout

\begin_layout Itemize
battery and energy constraints added to the problem space
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

energy is the new speed
\begin_inset Quotes erd
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
the individual components have gotten new attention in the recent past
\end_layout

\begin_deeper
\begin_layout Itemize
timeliness: increased importance of responsiveness for touch UIs, tighter
 and stricter deadlines
\end_layout

\begin_layout Itemize
placement: heterogeneous manycores
\begin_inset CommandInset citation
LatexCommand cite
key "DeVuyst:HeterogeneousISA,Chen:SchedulingHeterogeneous"

\end_inset


\end_layout

\begin_layout Itemize
adaptivity: energy management
\end_layout

\end_deeper
\begin_layout Itemize
energy as the new major cross-cutting concern that works completely different
\end_layout

\begin_deeper
\begin_layout Itemize
deadlines are inherent to the application, energy limitations are driven
 by the long-term intent of the user
\end_layout

\begin_layout Itemize
many existing solutions throttle threads according to an energy budget
\begin_inset CommandInset citation
LatexCommand cite
key "Roy:Cinder"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
not graceful degradation, but just degradation
\end_layout

\end_deeper
\begin_layout Itemize
assuming software does only useful work against the user's stated intent,
 throttling makes no sense
\end_layout

\begin_layout Itemize
only energy efficiency (doing the same with less energy) and maybe adaptivity
 remains
\end_layout

\begin_deeper
\begin_layout Itemize
high impact of tail power: power state more important than utilization
\begin_inset CommandInset citation
LatexCommand cite
key "Pathak:PowerModeling"

\end_inset


\end_layout

\begin_layout Itemize
piggy-backing and bactching helps a lot, which needs knowledge about acceptable
 delays for requests
\end_layout

\begin_layout Itemize
directly enabled by look-ahead and deadline-knowledge
\end_layout

\begin_layout Itemize
batch disk IO with deferrable requests
\begin_inset CommandInset citation
LatexCommand cite
key "Weissel:Coop_IO"

\end_inset


\end_layout

\begin_layout Itemize
batch network requests to power up radio less often
\begin_inset CommandInset citation
LatexCommand cite
key "Roy:Cinder,Lagar-Cavilla:TrafficBackfilling"

\end_inset


\end_layout

\begin_layout Itemize
in the large: use predictions of renewable energy supply to schedule background
 jobs in datacenters
\begin_inset CommandInset citation
LatexCommand cite
key "Aksanli:EnergyPrediction"

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
we may have targeted hardware with reduced instruction sets available that
 is more energy-efficient
\end_layout

\begin_deeper
\begin_layout Itemize
pieces of GPU code (and other ISAs with tighter assumptions and less ability)
 interwoven with CPU code
\end_layout

\begin_layout Itemize
devices like GPU (and increasingly network cards
\begin_inset CommandInset citation
LatexCommand cite
key "Nightingale:Helios"

\end_inset

) treated as compute resources like CPU, not as a peripheral
\begin_inset CommandInset citation
LatexCommand cite
key "Kato:GPUManagement"

\end_inset


\end_layout

\begin_layout Itemize
hardware video decoders as an example of a special-purpose, limited-ISA
 co-processor
\end_layout

\begin_deeper
\begin_layout Itemize
saves some energy (up to 25%
\begin_inset CommandInset citation
LatexCommand cite
key "LeSueur:SlowDownSleep"

\end_inset

), but not game-changing savings
\end_layout

\begin_layout Itemize
treat as any coprocessor that work with tighter restrictions on the available
 instructions can be offloaded to (see 
\family typewriter
restrict
\family default
 keyword proposal
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:C++AMP_Keynote"

\end_inset

)
\end_layout

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
As a side note,
\end_layout

\end_inset

 even though this work does not deal with peripheral scheduling: What complicate
s the metadata-driven scheduling is the increasing complexity of devices
 themselves.
 The position of our disk write request is a logical block number, with
 only the drive knowing the physical position of the actual sector.
 Devices also increasingly develop internal self-scheduling capabilities:
 The software scheduler in the driver can send multiple outstanding requests
 to the device and a hardware scheduler in the device will use its more
 detailed knowledge on request execution properties to order the requests
 beneficially.
\end_layout

\begin_layout Plain Layout
Disks behave this way since the introduction of native command queueing
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
native command queueing
\end_layout

\end_inset

.
\begin_inset CommandInset citation
LatexCommand cite
key "Intel:NCQ"

\end_inset

 But because the device’s scheduling policy is fixed, it still makes sense
 for the software scheduler to pre-order the request according to its own
 policy, using job metadata derived with a simplified model of the device.
 A disk scheduler may have a notion of request urgency and inter-application
 fairness that the hardware scheduler would not know about.
\begin_inset CommandInset citation
LatexCommand cite
key "Reuther:DAS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
special-purpose devices offer more choice for job placement and change energy
 tradeoffs, but they do not eliminate the fundamental problem to get given
 work done (meeting given deadlines) with as little resources (energy, time)
 as possible
\end_layout

\begin_deeper
\begin_layout Itemize
from FPGAs over DSP/SoCs to GPGPU and GPCPU: design spectrum for compute
 ressources plus interconnects
\end_layout

\begin_layout Itemize
placement decisions in space and time still relevant
\end_layout

\begin_layout Itemize
use lambda-like programming model to expose knowledge to runtime
\begin_inset CommandInset citation
LatexCommand cite
key "Knauerhase:ExtremeParallelism"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
choosing between race-to-halt and slowdown depends on workload and platform
\begin_inset CommandInset citation
LatexCommand cite
key "LeSueur:SlowDownSleep"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
end-to-end solution: this is only a rough sketch
\end_layout

\begin_deeper
\begin_layout Itemize
workload: energy-aware encoding of video
\end_layout

\begin_layout Itemize
we get the three swim lanes again, but with a different metric and intention
\end_layout

\begin_layout Itemize
application: maintain energy model (enhances real-time), code for specialized
 hardware ISA (enables placement), adapt to save energy (enhances adaptivity)
\end_layout

\begin_layout Itemize
system: collect and act on energy metrics (enhances real-time), outsource
 to specialized hardware (enhances placement), backpressure based on energy
 intent (enhances adaptivity)
\end_layout

\end_deeper
\begin_layout Itemize
metadata to decide energy consequences can be collected per-job at runtime
\end_layout

\begin_deeper
\begin_layout Itemize
performance counter can help to tell memory- and CPU-bound jobs apart
\end_layout

\begin_deeper
\begin_layout Itemize
clocking down the CPU especially helpful for memory-bound jobs
\begin_inset CommandInset citation
LatexCommand cite
key "Snowdon:Koala"

\end_inset


\end_layout

\begin_layout Itemize
power behavior can be modeled with performance counters
\begin_inset CommandInset citation
LatexCommand cite
key "Isci:PowerPhases"

\end_inset


\end_layout

\begin_layout Itemize
exploit look-ahead for energy metadata: clock CPU down and then run all
 pending memory-bound jobs
\end_layout

\end_deeper
\begin_layout Itemize
linear combination of metrics to predict energy in a similar way to the
 execution time
\end_layout

\begin_deeper
\begin_layout Itemize
performance counters to train energy model
\begin_inset CommandInset citation
LatexCommand cite
key "Merkel:EnergyModel"

\end_inset


\end_layout

\begin_layout Itemize
energy counter in Intel Sandy Bridge CPUs
\end_layout

\begin_layout Itemize
more complex energy predictors available
\begin_inset CommandInset citation
LatexCommand cite
key "Lewis:CAP"

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
using backpressure also for energy-management
\end_layout

\begin_deeper
\begin_layout Itemize
some applications can adapt their energy or computation time needs
\begin_inset CommandInset citation
LatexCommand cite
key "Flinn:EnergyAdaptation"

\end_inset


\end_layout

\begin_layout Itemize
trivial examples (disable backup on low battery) are rather obvious and
 not interesting, more dynamic examples are rare
\end_layout

\begin_layout Itemize
use energy instead of CPU time as a cost metric in adaptation decisions
\end_layout

\begin_layout Itemize
nested control loops for trading application quality and energy use
\begin_inset CommandInset citation
LatexCommand cite
key "Cucinotta:ApplicationQoS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
other ends that were left open in this thesis
\end_layout

\begin_deeper
\begin_layout Itemize
a thread-less systems architecture (kernel interface), jobs as first class
 citizens in the system
\end_layout

\begin_layout Itemize
fault tolerance: recovery options may differ in required time and provided
 service quality, deadlines helpful
\end_layout

\begin_layout Itemize
unreliable computing:
\begin_inset CommandInset citation
LatexCommand cite
key "Chakrapani:ApproximateArithmetic"

\end_inset

 reliability requirements can be attached to lambdas, placement on reliable
 or unreliable core
\end_layout

\end_deeper
\begin_layout Itemize
future development can be researched within the presented design
\end_layout

\begin_layout Itemize
summarize the key contributions again
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
backmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "Bibliography/Thesis"
options "Bibliography/Thesis"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nochapteredge
\end_layout

\end_inset


\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList margintable

\end_inset


\begin_inset CommandInset index_print
LatexCommand printindex
type "idx"

\end_inset


\begin_inset Note Note
status open

\begin_layout Itemize
check the index terms and their referencing
\end_layout

\begin_layout Itemize
inner back cover: Creative Commons badge and URL 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://os.inf.tu-dresden.de/~mroi/git/thesis
\end_layout

\end_inset

 with QR-code
\end_layout

\begin_layout Itemize
last: commit a tarball with all raw log files to dissertation git
\end_layout

\end_inset


\end_layout

\end_body
\end_document
