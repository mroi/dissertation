#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass tufte-book
\begin_preamble
% simplified title and author for fancy headers, height-correct the dash
\renewcommand{\plaintitle}{Practical Real\raisebox{-0.45mm}{-}Time with Look\raisebox{-0.45mm}{-}Ahead Scheduling}
\renewcommand{\plainauthor}{Michael Roitzsch}

% typesetting tweaks
\clubpenalty=9999
\widowpenalty=9999
\relpenalty=9999
\binoppenalty=9999
\hyphenation{Atlas}

% font setup: disable Hoefler swashes, set math fonts
\usepackage{mathspec}
\setmainfont[ItalicFeatures={Contextuals={NoLineInitial,NoLineFinal}}]{Hoefler Text}
\setmathrm{Hoefler Text}
\setmathsfont(Digits,Latin)[ItalicFeatures={Contextuals={NoLineInitial,NoLineFinal}},Numbers={Lining,Proportional}]{Hoefler Text}
\setmathsfont(Greek){Georgia}
% restore mathspec's activation of " at document beginning, someone messes with it
\begingroup
\catcode`\"=\active
\AtBeginDocument{\let"=\eu@active@quote}
\endgroup

% letter spacing for capitalized text
\renewcommand{\allcapsspacing}[1]{{\addfontfeature{LetterSpace=6.5}#1}}
\renewcommand{\smallcapsspacing}[1]{{\addfontfeature{LetterSpace=5.0,Letters=SmallCaps}#1}}

% use all-bullets for itemize and give them the right size and height
\AtBeginDocument{
\def\labelitemi{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
\def\labelitemii{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
\def\labelitemiii{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
\def\labelitemiv{\raisebox{0.3mm}{\scriptsize\(\bullet\)}}
}

% do not indent the bibliography
\setlength{\bibhang}{0pt}

% repeat tufte caption definition because it gets garbled by hyperref
\long\def\@caption#1[#2]#3{\par%
\addcontentsline{\csname ext@#1\endcsname}{#1}%
{\protect\numberline{\csname the#1\endcsname}{\ignorespaces #2}}%
\begingroup%
\@parboxrestore%
\if@minipage\@setminipage\fi%
\@tufte@caption@font\@tufte@caption@justification%
\noindent\csname fnum@#1\endcsname: \ignorespaces#3\par%
\endgroup}

% colored page edge when a new chapter starts
\newcommand{\chapteredge}{
\fancypagestyle{plain}{
\fancyhf{}
\fancyfoot[LE,RO]{
\begin{picture}(0,0)
\color{gray}
\put(49,-60){\rule{10mm}{305mm}}
\end{picture}
}}}
\newcommand{\nochapteredge}{
\fancypagestyle{plain}{
\fancyhf{}
}}

% alternative chapter titling with big chapter number on the right
\titleformat{\chapter}[display]
{\relax\ifthenelse{\NOT\boolean{@tufte@symmetric}}{\begin{fullwidth}}{}}
{\hfill\sffamily\color{gray}\fontsize{42}{0}\selectfont\thechapter}
{0pt}
{\vskip -32pt\huge\rmfamily\itshape}
[\ifthenelse{\NOT\boolean{@tufte@symmetric}}{\end{fullwidth}}{}]

% epigraph command
\newcommand{\epigraph}[2]{
\begin{fullwidth}
\sffamily\Large
\begin{doublespace}
\noindent\allcaps{#1}\\% epigraph
\color{darkgray}\noindent\allcaps{#2}% author
\end{doublespace}
\end{fullwidth}
}

% use my own palette of gray tones
\definecolor{note_fontcolor}{HTML}{808785}
\definecolor{gray}{HTML}{808785}
\definecolor{darkgray}{HTML}{48494B}
\end_preamble
\options a4paper
\use_default_options true
\begin_modules
fixltx2e
enumitem
logicalmkup
\end_modules
\maintain_unincluded_children false
\begin_local_layout
Style Verleger
Margin	Static
LatexType	Command
Category	FrontMatter
LatexName	publisher
InTitle	1
InPreamble	1
Font
Size	Large
EndFont
End
\end_local_layout
\language english
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman Hoefler Text
\font_sans Gill Sans
\font_typewriter Menlo Regular
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 83

\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Practical Real-Time with Look-Ahead Scheduling"
\pdf_author "Michael Roitzsch"
\pdf_subject "Dissertation"
\pdf_keywords "Real-Time, Multicore, Work Queues, Look-Ahead, Clairvoyance"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 2
\pdf_breaklinks true
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\papersize default
\use_geometry true
\use_amsmath 0
\use_esint 0
\use_mhchem 0
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 0
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\listings_params "basicstyle={\ttfamily\small},language=C,numberstyle={\ttfamily\small\color{gray}},tabsize=2"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\begin_inset Flex AllCaps
status collapsed

\begin_layout Plain Layout
Outer Front Cover Placeholder
\end_layout

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
epigraph{I love deadlines.
\backslash
newline
\backslash
noindent I love the whooshing noise they make as they go by.}{Douglas Adams}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
epigraph{The art of prophecy is very difficult,
\backslash
newline
\backslash
noindent especially with respect to the future.}{Mark Twain}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
epigraph{Oh dear! Oh dear! I shall be too late!}{The White Rabbit}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage cleardoublepage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
frontmatter
\end_layout

\end_inset


\end_layout

\begin_layout Author
Michael Roitzsch – born August 15, 1980
\end_layout

\begin_layout Title
Practical Real
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.8mm}{-}
\end_layout

\end_inset

Time
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

with Look
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.8mm}{-}
\end_layout

\end_inset

Ahead
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Scheduling
\end_layout

\begin_layout Verleger
Dissertation
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Advisor: Prof.
\begin_inset space ~
\end_inset

Dr.
\begin_inset space ~
\end_inset

rer.
\begin_inset space ~
\end_inset

nat.
\begin_inset space ~
\end_inset

Hermann Härtig
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Technische Universität Dresden
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset


\begin_inset Graphics
	filename Figures/TU-Logo.pdf
	width 5cm

\end_inset


\end_layout

\begin_layout Full Width

\lang ngerman
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout

\lang ngerman
Dissertation
\end_layout

\end_inset

 zur Erlangung des akademischen Grades 
\begin_inset Flex AllCaps
status collapsed

\begin_layout Plain Layout

\lang ngerman
Doktoringenieur
\begin_inset space ~
\end_inset

(Dr.-Ing.)
\end_layout

\end_inset

, vorgelegt an der 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout

\lang ngerman
Technischen Universität Dresden, Fakultät Informatik
\end_layout

\end_inset

, eingereicht von
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset


\begin_inset Flex AllCaps
status collapsed

\begin_layout Plain Layout

\lang ngerman
Dipl.-Inf.
\begin_inset space ~
\end_inset

Michael
\begin_inset space ~
\end_inset

Roitzsch
\end_layout

\end_inset

, geboren am 15.
\begin_inset space ~
\end_inset

August 1980 in Dresden.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Full Width

\lang ngerman
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="0pt" special="@{}l">
<column alignment="left" valignment="top" width="0pt">
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Betreuender Hochschullehrer:
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Prof.
\begin_inset space ~
\end_inset

Dr.
\begin_inset space ~
\end_inset

rer.
\begin_inset space ~
\end_inset

nat.
\begin_inset space ~
\end_inset

Hermann Härtig,
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Technische Universität Dresden
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Fachreferent:
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Prof.
\begin_inset space ~
\end_inset

Dr.
\begin_inset space ~
\end_inset

Christof Fetzer,
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Technische Universität Dresden
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Gutachter:
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\lang ngerman
fehlt
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Statusvortrag:
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
12.
\begin_inset space ~
\end_inset

Dezember 2011
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
Verteidigung:
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang ngerman
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\lang ngerman
fehlt
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Full Width

\lang ngerman
\begin_inset VSpace bigskip
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent 
\end_layout

\end_inset

Dresden, 
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\lang ngerman
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
Acknowledgments
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
OS group, Prof.
\begin_inset space ~
\end_inset

Härtig, fellow researchers, friends, parents
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage cleardoublepage
\end_inset


\end_layout

\begin_layout Full Width
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\begin_inset VSpace vfill
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
noindent
\backslash
nohyphenation 
\end_layout

\end_inset


\shape italic
\size huge

\begin_inset Note Greyedout
status open

\begin_layout Plain Layout

\shape italic
\size huge
Dedication
\end_layout

\end_inset


\end_layout

\begin_layout Full Width
\begin_inset VSpace vfill
\end_inset


\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
mainmatter
\backslash
chapteredge
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The evolution of computing
\end_layout

\end_inset

 has treated users with an impressive stream of innovation: From the mainframe
 era through the age of productivity computing to today’s multimedia and
 mobile world, the capabilities of systems and thus the possibilities for
 users increased steadily.
 This sea change thrives on the exponential improvement of the underlying
 transistor technology as predicted by Moore’s Law
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Moore’s Law
\end_layout

\end_inset

: The number of transistors that can be integrated cost efficiently doubles
 approximately every two years.
\begin_inset Foot
status open

\begin_layout Plain Layout
This period is often misquoted as 18 months, which is a follow-up prediction
 of the increase in single chip performance.
 (cf.
\begin_inset space ~
\end_inset


\emph on

\begin_inset CommandInset href
LatexCommand href
name "CNET News: Moore’s Law to roll on for another decade"
target "http://news.cnet.com/2100-1001-984051.html"

\end_inset


\emph default
)
\end_layout

\end_inset

 Software matches this exponential growth: The total body of open source
 software in the world doubles about every 14 months.
\begin_inset CommandInset citation
LatexCommand cite
key "Deshpande:GrowthSoftware"

\end_inset


\end_layout

\begin_layout Section
Application Necessities
\end_layout

\begin_layout Standard
Users have grown accustomed to the constant improvement of technology.
 What started as high-end and expert use cases will become a commodity just
 a few years later and will be expected to work predictably and efficiently.
 The previous generation iPad
\begin_inset space ~
\end_inset

2 would have been in 1994’s Top
\begin_inset space ~
\end_inset

500 list of the fastest computers in the world
\begin_inset CommandInset citation
LatexCommand cite
key "Markoff:DongarraIPad"

\end_inset

 and it is arguably more intelligible today than those supercomputers were
 back then.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Satisfying these user expectations
\end_layout

\end_inset

 is a demanding job for developers.
 Users are no longer satisfied with functionality alone.
 Increasingly, 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
non-functional properties
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
non-functional properties
\end_layout

\end_inset

 separate good from great applications.
 Next to user interface design and visual appearance such properties include
 responsive and stutter-free operation,
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:FastFluid"

\end_inset

 perceived performance, and the useful and efficient employment of the invested
 resources,
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:PowerEfficiency"

\end_inset

 also driven by the resource and energy constraints of today’s battery-powered
 devices.
\end_layout

\begin_layout Standard
My dissertation is motivated by a need to integrate the non-functional requireme
nts within applications with system-wide decision-making.
 The following three properties exemplify such cooperation opportunities:
\end_layout

\begin_layout Description
Timeliness
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timeliness
\end_layout

\end_inset

: User interface responsiveness and the smoothness of multimedia operations
 require that applications’ 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset

 are met.
\begin_inset CommandInset citation
LatexCommand cite
key "Sasinowski:ARTIFACT"

\end_inset

 Such requirements arise when computers interface with the real world.
 Subsumed under the term real-time
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
real-time
\end_layout

\end_inset

, they tie the completion of software results to wall-clock time.
 Time being a global resource, a system-wide solution is needed.
 However, the majority of commodity systems today offer only weak temporal
 guarantees and predictability to applications, so developers have to work
 around those limitations.
 While real-time operating systems are available, they are typically applied
 only in special-purpose scenarios.
\begin_inset Foot
status open

\begin_layout Plain Layout
A notable exception is the BlackBerry PlayBook
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
BlackBerry PlayBook
\end_layout

\end_inset

, a general-purpose tablet computer which runs the real-time capable QNX
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
QNX
\end_layout

\end_inset

 kernel.
 (cf.
\begin_inset space ~
\end_inset


\emph on

\begin_inset CommandInset href
LatexCommand href
name "QNX: Meet the Power Behind the BackBerry Tablet OS"
target "http://www.qnx.com/company/announcements/power_behind_playbook.html"

\end_inset


\emph default
)
\end_layout

\end_inset


\end_layout

\begin_layout Description
Informed
\begin_inset space \space{}
\end_inset

Core
\begin_inset space \space{}
\end_inset

Placement: Single-core performance is leveling off, so processor manufacturers
 rely on increasing core counts to offer higher performance.
 Applications thus have to employ parallel programming to benefit from multiple
 cores.
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:FreeLunch"

\end_inset

 The amount of concurrency exposed by applications limits the number of
 cores occupied.
 However, the assignment of work to cores also influences cache contention
\begin_inset CommandInset citation
LatexCommand cite
key "Zhuravlev:DIO"

\end_inset

 and energy efficiency.
\begin_inset CommandInset citation
LatexCommand cite
key "Rangan:ThreadMotion"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
paper on energy-impact of core consolidation would be better
\end_layout

\end_inset

 Both processors and energy are global resources, so they require system-wide
 management.
 Instead of using local information for limited management within the applicatio
n I propose to contribute knowledge of 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset


\emph on
 
\emph default
to improve the system's global decisions.
\end_layout

\begin_layout Description
Quality-aware
\begin_inset space \space{}
\end_inset

Overload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
overload
\end_layout

\end_inset


\begin_inset space \space{}
\end_inset

Handling: Overload situations occur when all ready applications collectively
 ask for more computation time than the machine can offer without violating
 any timing requirements.
 Real-time systems avoid such situations statically with an admission
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
admission
\end_layout

\end_inset

 process: The system will not allow new tasks unless it can establish a
 formal guarantee that the total resource demand will never outgrow the
 available resources.
 On interactive systems, users will not accept rejected application launches.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:UserControl"

\end_inset

 These systems have to handle overload situations dynamically at runtime
 by reducing the resource allotment of a subset of applications.
 This reduction needs global management to maintain the system’s fairness
 policy, but applications may want to adapt their service according to a
 local notion of quality.
 The system should predict the overload and communicate it 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
ahead of time
\end_layout

\end_inset

,
\emph on
 
\emph default
so those applications can prepare before the resource shortage arrives.
\end_layout

\begin_layout Full Width
\begin_inset Flex Emph
status collapsed

\begin_layout Plain Layout
These three non-functional aspects all benefit from the aggregation of local
 application knowledge to implement a global system-wide policy.
 My mission is to show that a little added developer effort can be augmented
 by a newly designed runtime and lead to closer cooperation with the scheduler,
 enhancing application behavior with respect to non-functional properties.
 In this thesis, I will prove how communicating application’s timing requirement
s helps overall timeliness, how knowledge on resource requirements improves
 core placement and how ahead-of-time overload notification improves quality
 when adapting.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Developing a modern application
\end_layout

\end_inset

 alread is a complex undertaking, because users expect intricate features
 and applications have to handle new failure cases by connecting with the
 cloud.
 To face non-functional properties on top of that, developers need to rely
 on a foundation that helps them deliver without much development overhead.
 Systems research can and should help here.
 Libraries can mediate between the application’s view and the system interface.
 I will now motivate my work from the system’s perspective and show that
 the cross-cutting nature of non-functional properties actually requires
 the participation of the lower system levels.
\end_layout

\begin_layout Section
Scheduler Knowledge
\end_layout

\begin_layout Standard
As illustrated by Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Interaction"

\end_inset

, the scheduler
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
scheduler
\end_layout

\end_inset

 is a system component responsible for accumulating information about the
 work applications want to perform and determine an order and core placement
 to execute that work.
 The ordering policy should serve the non-functional properties applications
 expect: It should fulfill timing requirements, use cores effectively and
 handle overload early and fairly.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Interaction_Application_Scheduler.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Interaction"

\end_inset

Interaction between Application and Scheduler
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
every device in a computer system
\end_layout

\end_inset

 has a different notion of work: sending and receiving network packets,
 reading and writing storage requests or the execution of OpenGL shader
 code.
 Consequently, every devices follows a different policy for ordering its
 work and thus needs its own dedicated scheduler.
 However, this thesis focuses exclusively on scheduling the CPU cores of
 a computer system.
 The CPU plays a central role in the system as it is the gateway for the
 scheduling of all other devices.
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

 To submit work to a peripheral device, applications need to execute code
 on the CPU.
\end_layout

\begin_layout Standard
Nevertheless, taking a closer look at peripheral schedulers does help to
 reveal an important disadvantage of CPU scheduling: Schedulers for peripheral
 devices have a deeper insight into the jobs they are supposed to order.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
So how does a peripheral scheduler operate?
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
peripheral device scheduling
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Love:IO_Schedulers"

\end_inset

 We start with an application asking for the service of a device.
 A write request to persistent storage shall serve as an example.
 The application collects the data it wants to make durable and submits
 a job toward the device using an API or system call.
 A write request to a file would now traverse various layers of file system
 and buffer caching code in the operating system, but would finally arrive
 at the device driver as a write request to the magnetic disk.
 As part of the driver, the scheduler maintains a work queue of jobs waiting
 for execution.
 Our write request is added to that queue together with concurrent requests
 arriving from other applications, from other threads of the same application,
 or even from the same thread of the same application, if the initial write
 executes asynchronously.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Device-Scheduling"

\end_inset

 depicts this situation.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Peripheral_Scheduling.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Device-Scheduling"

\end_inset

Peripheral Device Scheduling
\end_layout

\end_inset


\end_layout

\end_inset

The scheduler now orders the jobs and sends them off to the device for execution.
 The scheduling algorithm performs that ordering with a service goal in
 mind, for example to maximize device throughput.
 Every job carries metadata for the request.
 In the case of our disk write request, that metadata contains the size
 of the request and its location on disk.
\end_layout

\begin_layout Standard
When ordering jobs, the scheduler can inspect the metadata to decide which
 order best supports its service goal.
 The disk scheduler in the example can use the on-disk location to execute
 a shortest access time first
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
shortest access time first
\end_layout

\end_inset

 policy
\begin_inset CommandInset citation
LatexCommand cite
key "Jacobson:SATF"

\end_inset

 to improve drive throughput.
 Peripheral device schedulers enjoy the advantage that the outstanding requests
 are self-describing jobs
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
self-describing job
\end_layout

\end_inset

.
 Inspecting them reveals all information the peripheral will use to execute
 them.
 This is natural, because to program the device, the driver must have all
 that information available anyway.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/1-Introduction/CPU_Scheduling.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:CPU-Scheduling"

\end_inset

CPU Scheduling
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The CPU scheduler
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
CPU scheduling
\end_layout

\end_inset

 does not share this benefit: It does not deal with self-describing jobs
 in a queue of outstanding work.
 Instead, it maintains a ready queue of runnable threads
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
thread
\end_layout

\end_inset

.
 Other than a job, a thread is not consumed after it executed, but is automatica
lly inserted into the ready queue again until terminated by the application.
 Other than a job, a thread is not a self-describing aggregate of payload
 and metadata, but rather an opaque handle to an execution context within
 the application’s address space.
 The actual behavior that unfolds if the thread is executed
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

whether it blocks after a short burst of code, or runs a long computation,
 or a periodic task
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

is hidden within the application’s code and memory state as illustrated
 by Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:CPU-Scheduling"

\end_inset

.
\end_layout

\begin_layout Standard
CPU schedulers in commodity operating systems support a notion of precedence,
 expressed with priorities
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
priority
\end_layout

\end_inset

 or the Unix nice levels
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
nice level
\end_layout

\end_inset

.
 This single numeric value
\begin_inset CommandInset citation
LatexCommand cite
key "Unix:nice"

\end_inset

 is a coarse abstraction of a thread’s behavior, because it only indicates
 the importance of a thread relative to other threads.
 The application developer has to supply the priority without knowledge
 of concurrent load, which gives rise to other problems I discuss in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

.
\end_layout

\begin_layout Standard
Real-time schedulers supporting a periodic task model
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
periodic task model
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RMS"

\end_inset

 have the benefit of implicit knowledge about a thread’s upcoming behavior,
 but only for applications fitting into that rigid model.
 More details again follow in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
In this thesis
\end_layout

\end_inset

, I want to argue that it is beneficial to organize CPU scheduling using
 self-describing jobs similar to peripheral schedulers.
 Those CPU jobs represent a specific piece of code execution and are consumed
 once the CPU executed them.
 They carry metadata describing the jobs’ urgency and required execution
 time.
 If the CPU scheduler receives jobs ahead-of-time, before they execute,
 it can build up a limited look into the applications’ future and detect
 overload situations early.
 In contrast to periodic task models, this knowledge is not available implicitly
, but applications share information with the scheduler by submitting jobs
 explicitly.
 I show how such a scheduling regime improves the non-functional application
 properties portrayed above.
\end_layout

\begin_layout Section
Driving Insights
\end_layout

\begin_layout Standard
The walk-through of the problem area shows that the considered non-functional
 properties timeliness, informed core placement, and quality-aware overload
 handling are cross-cutting concerns.
 They involve local knowledge from the applications and global policy executed
 by the scheduler.
 Furthermore, many applications act as an execution environment tailored
 to a specific workload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload
\end_layout

\end_inset

: a text editor manipulates documents, a photo album manages photos, a video
 player renders continuous media.
 Those applications’ behavior dynamically depends on the workload they handle.
 This workload is what users care about after all.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
A vertically integrated solution
\end_layout

\end_inset

 spanning from the workload through the application down to the scheduler
 is called for.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Verically_Integrated_Solution.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Vertically-Integrated-Solution"

\end_inset

Vertically Integrated Solution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

Refining the previous concept sketch from Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Interaction"

\end_inset

, Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Vertically-Integrated-Solution"

\end_inset

 shows how I imagine this integration to operate.
 Applications should be aware of their workload and extract information
 to model it.
 They communicate a useful representation of their local knowledge down
 to the scheduler.
 The scheduler collects this knowledge from all applications and executes
 its global policy, consequences of this policy take effect either implicitly
 by executing the scheduling decisions, or explicitly by the scheduler reporting
 back to an application.
 Overload situations propagate this way, because they require an application-spe
cific notion of quality to resolve them.
 The application in turn uses its model of the workload to decide on a quality-a
ware reaction.
\end_layout

\begin_layout Standard
What information is relayed along those paths and what the interfaces look
 like remains to be discussed.
 But as motivated in the section on scheduler knowledge above, the scheduler
 should operate on self-contained jobs instead of threads which hide their
 execution behavior deep in the application state.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Applications should expose local knowledge
\end_layout

\end_inset

 to the scheduler by explicitly submitting self-describing jobs that encapsulate
 timing and resource requirements depending on the current workload.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

To provide knowledge explicitly, applications likely have to be modified.
 We may get away with adapting key libraries to change the behavior of many
 applications at once, but in the context of this dissertation, modifying
 a library counts as modifying the application.
 How to reduce programming effort by architecting software so it hides this
 problem in library layers is outside the scope of this thesis.
 In scope however is to design the interfaces for ease of use:
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
The programming model should be approachable
\end_layout

\end_inset

 by matching current application development methods and by never asking
 the developer for parameters outside the application domain.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

I hope developers can provide parameters from within the application domain
 with reasonable effort.
 An example are deadlines
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deadline
\end_layout

\end_inset

 to describe the timing requirements of a job.
 Parameters requiring knowledge outside the application scope should be
 avoided.
 Developers should not need to provide estimated execution times of jobs,
 because these are specific to the underlying hardware platform.
\end_layout

\begin_layout Standard
An emerging trend in the development of parallel software is the use of
 lambdas
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
lambda
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:LambdasEverywhere"

\end_inset

, depending on the programming language also called closures
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
closure
\end_layout

\end_inset

 or blocks
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
block
\end_layout

\end_inset

.
 They are used to structure code into pieces that can be executed asynchronously
, which keeps applications responsive in the presence of long-running background
 computation or IO
\begin_inset space ~
\end_inset

operations.
 Because asynchronously executed code runs concurrently with other code,
 lambdas are also a tool to express parallelism.
 A more in-depth discussion of this programming style follows in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-chap:Anatomy"

\end_inset

.
 I will illustrate how lambdas and jobs can cooperate
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

both describe a bounded, self-contained piece of code execution
\begin_inset space \thinspace{}
\end_inset

—
\begin_inset space \thinspace{}
\end_inset

and how the communication of jobs to the scheduler integrates with the use
 of lambdas.
 Big platform vendors such as Apple
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatch"

\end_inset

 and Microsoft
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:C++PPL"

\end_inset

 adopted lambda programming, so by drafting a scheduler interface that leans
 toward it, I hope to create a pragmatic solution that developers can adopt
 as part of their programming toolbox.
\end_layout

\begin_layout Standard
The asynchronous execution of lambdas gives rise to another interesting
 benefit: announcing future code execution ahead-of-time.
 Application code can specify multiple pieces of work and dispatch them
 for later asynchronous and potentially parallel execution.
 The queues in the lambda runtime therefore contain knowledge about what
 pieces of code will execute in the future.
 Again, more details on how these runtimes operate follow in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-chap:Anatomy"

\end_inset

.
 Here we conclude:
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Knowledge of future execution
\end_layout

\end_inset

 should be propagated to the scheduler.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
null
\end_layout

\end_inset


\end_layout

\end_inset

I claim that many applications have knowledge on their future execution
 available, but currently lack a way to expose this information.
 Any operation that runs autonomously after being triggered by a system
 event or user interaction is fully determined at the moment it is triggered.
 If a user clicks 
\begin_inset Quotes eld
\end_inset

play
\begin_inset Quotes erd
\end_inset

 to watch a video, the application knows that it will now be fetching, decoding
 and displaying video frames.
\end_layout

\begin_layout Standard
Like video, some of these chains of actions may be long-running, others
 may be short, like the reaction to a user’s mouse click in a graphical
 interface.
 Highly interactive applications like games may have almost no knowledge
 of what will happen next, because the user can change the course of action
 at any moment.
 However, applications that do have knowledge of their future should be
 able to tell the scheduler about it early.
 Such insights enable the system to perform 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
look-ahead
\emph on
 
\emph default
scheduling
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
look-ahead scheduling
\end_layout

\end_inset

: It can make ahead-of-time, anticipating decisions rather than exercising
 post-mortem, reactive control.
\end_layout

\begin_layout Section
Thesis Goals
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
In this dissertation, I target three scheduling-related problems:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

timeliness,
\end_layout

\begin_layout Itemize
informed core placement, and
\end_layout

\begin_layout Itemize
quality-aware overload handling.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
I chose these problems because I believe they constitute important non-functiona
l properties
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
non-functional properties
\end_layout

\end_inset

, which applications should offer to their users.
 Therefore, I investigate these problems in the context of interactive end-user
 systems
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
interactive systems
\end_layout

\end_inset

, running a commodity operating system
\begin_inset CommandInset citation
LatexCommand cite
key "StatCounter:OSMarketShare"

\end_inset

 as an application platform.
 This category of systems includes classical desktop computers, notebooks
 and the ballooning family of smartphones and tablets.
 It does not include servers, although I am confident that my ideas generalize
 to this class of systems due to the large amount of shared technology.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I do not consider reactive systems
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
reactive systems
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Harel:ReactiveSystems"

\end_inset

 that continuously supervise sensors and actuators, for example in an industrial
 control environment or within other deeply embedded systems.
 Graphical and touch user interfaces however are subject to timing constraints
 dictated by the physical reality.
 Here, human-machine-interfaces and reactive systems overlap.
\begin_inset CommandInset citation
LatexCommand cite
key "Halbwachs:LUSTRE"

\end_inset

 Beyond these common timeliness demands, I ignore reactive systems in this
 work.
\end_layout

\begin_layout Standard
Similarly, I do not consider offline scheduling, where a precomputed schedule
 is reenacted at runtime.
 In a dynamic, interactive system, advance knowledge on the executed task
 set is generally not available.
 Therefore, I exclusively research online scheduling, where scheduling decisions
 happen while the system runs.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Figures/1-Introduction/Deadline_Types.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Deadline-Types"

\end_inset

Types of Real-Time Deadlines
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset

Real-time literature
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RealTimeSystems"

\end_inset

 distinguishes between systems with hard
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
hard deadline
\end_layout

\end_inset

, firm
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
firm deadline
\end_layout

\end_inset

 and soft deadlines
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
soft deadline
\end_layout

\end_inset

.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Deadline-Types"

\end_inset

 shows the delineating characteristics.
 Hard deadlines must never be missed and the system has to guarantee this
 invariant with a formal analysis.
 For firm and soft deadlines, weaker guarantees apply.
 Deadlines may be missed, but with predictable consequences.
 Jobs missing a firm deadline are aborted, whereas results arriving after
 a soft deadline are still useful.
\end_layout

\begin_layout Standard
I think an interactive system should not reject the user’s instruction to
 start an application.
 Therefore, a task admission
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
admission
\end_layout

\end_inset

 is not appropriate and consequently, the system cannot handle hard deadlines.
 Overload situations may occur and my solution provides methods to handle
 them.
 It is up to the application to decide on aborting the job or continuing.
\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Three layers have to be bridged
\end_layout

\end_inset

 for a comprehensive solution:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

workload,
\end_layout

\begin_layout Itemize
application, and
\end_layout

\begin_layout Itemize
CPU scheduler.
\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
I presume that combining application-specific knowledge on workload and
 execution behavior with system-wide knowledge on urgency and overall load
 is beneficial.
 Any solution that handles any of these aspects in isolation will be incomplete.
 Instead, applications and the scheduler have to collaborate
\begin_inset CommandInset citation
LatexCommand cite
key "Peter:EndToEndScheduler"

\end_inset

 to integrate application-local and global scheduling mechanisms.
\end_layout

\begin_layout Standard
Furthermore, the three non-functional properties in the focus of this thesis
 interrelate: Core placement influences execution speed
\begin_inset CommandInset citation
LatexCommand cite
key "Blagodurov:DINO"

\end_inset

 and therefore application progress, which affects timeliness.
 When too tight timing requirements are requested for a single core to fulfill,
 parallel execution on multiple cores can help to meet demand, otherwise
 the system runs into overload.
 Unless mitigated, overload disturbs timeliness.
 The scheduling layer thus needs one mechanism covering all three of the
 non-functional properties.
 I propose self-describing jobs as this integrative device.
 Equally, application developers should not face three different programming
 paradigms, but one wholesale solution.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Integration
\end_layout

\end_inset

 along the properties dimension and the layers dimension is crucial.
 The following Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-tab:Overview-Thesis"

\end_inset

 summarizes the thesis goals:
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="16text%">
<column alignment="left" valignment="top" width="23text%">
<column alignment="left" valignment="top" width="23text%">
<column alignment="left" valignment="top" width="23text%">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timeliness
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timeliness
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Core Placement
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Overload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
overload
\end_layout

\end_inset

 Handling
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Workload
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
derive workload metrics to predict execution times
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
balanced partitioning to enable parallel execution
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
offer degraded processing options
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Application
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
expose deadlines and execution time estimates ahead of time
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
deduce parallel speedup and workload metadata
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
balance resource and quality impact of load shedding
\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CPU Scheduler
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
scheduler
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
globally order jobs to meet deadlines, detect misses ahead of time
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
non-work-conserving assignment of jobs to cores
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
exert back-pressure when anticipating deadline misses
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Enabling Feature
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timing Requirements
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
timing requirements
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Resource Requirements
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
resource requirements
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scheduler Look-Ahead
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
look-ahead scheduling
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row bottomspace="default">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thesis Chapter
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset ref
LatexCommand nameref
reference "3-chap:Real-Time"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Parallelism"

\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset ref
LatexCommand nameref
reference "4-chap:Parallelism"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "5-chap:Adaptivity"

\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset ref
LatexCommand nameref
reference "5-chap:Adaptivity"

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-tab:Overview-Thesis"

\end_inset

Overview of the Solution Developed in this Thesis
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Vertical integration across the three layers is necessary, because no layer
 alone has enough knowledge to provide the desired non-functional properties.
 Horizontal integration across the properties is necessary to curb complexity
 for the developer and because of the cross-talk between the properties.
\end_layout

\begin_layout Standard
A large body of individual research results is available covering the nine
 intersections of my three by three goals matrix.
 However, in this dissertation I provide a comprehensive, end-to-end solution
 and I demonstrate improvements over the state of the art in each of the
 three property lanes.
 The scheduling system I present is dubbed 
\noun on
Atlas
\noun default
, the Auto-Training Look-Ahead Scheduler.
\begin_inset Foot
status open

\begin_layout Plain Layout
Like its namesake, the greek titan who supports the celestial globe (cf.
\begin_inset space ~
\end_inset


\emph on

\begin_inset CommandInset href
LatexCommand href
name "Wikipedia: Atlas"
target "http://en.wikipedia.org/wiki/Atlas_(mythology)"

\end_inset


\emph default
), we hope the 
\noun on
Atlas
\noun default
 system can support many applications.
\end_layout

\end_inset

 I will now give an overview of the work within each property lane and summarize
 the key contributions.
 Each lane is discussed in detail in its own chapter.
\end_layout

\begin_layout Section
Timeliness
\end_layout

\begin_layout Standard
Timeliness is the primary property of real-time scheduling.
 The scheduling policy considers secondary service goals only when timeliness
 is not jeopardized.
 Time is a global resource and is therefore managed by a system-wide scheduler.
 Imposing a separation of concerns as in the resource kernels concept,
\begin_inset CommandInset citation
LatexCommand cite
after "-1\\baselineskip"
key "Rajkumar:ResourceKernels"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 applications specify their timing requirements to the scheduler, which
 then exercises global management.
 This functional separation must be accompanied by an integration of knowledge:
 Only the application knows its workload and should expose this knowledge
 to the scheduler using appropriate interfaces.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I contribute a scheduler interface
\end_layout

\end_inset

 and an accompanying task model that allow applications to express timing
 and resource requirements.
 Other than the majority of related work, I do not employ a periodic task
 model
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
periodic task model
\end_layout

\end_inset

.
\begin_inset CommandInset citation
LatexCommand cite
key "Liu:RMS"

\end_inset

 Explicit submission of future jobs substitutes the implicit knowledge on
 future execution that periods provide.
\end_layout

\begin_layout Standard
The 
\noun on
Atlas
\noun default
 scheduler interface as seen by the application developer only asks for
 parameters from the application domain.
 Deadlines specify timing requirements.
 Resource requirements are specified using 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout

\emph off
workload metrics
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
workload metrics
\end_layout

\end_inset

: parameters from the workload that describe its computational weight.
 
\noun on
Atlas
\noun default
 uses machine-learning to automatically derive execution time estimates
 from the metrics before the actual execution.
 The estimated execution time of each job is therefore known ahead of time.
 I presented the prediction method employed by 
\noun on
Atlas
\noun default
 on the 27th IEEE Real-Time Systems Symposium.
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Predict"

\end_inset


\end_layout

\begin_layout Standard
I demonstrate with code examples that this task model is easy to program
 against.
 I believe it is easier than reservation-based interfaces for which the
 developer needs to specify a desired CPU allocation.
 However, a formal usability analysis of the programming interface is not
 part of this thesis.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I claim that the flexibility of this task model
\end_layout

\end_inset

 allows to inform the scheduler more accurately of application behavior
 than alternative approaches.
 I validate this claim by demonstrating that 
\noun on
Atlas
\noun default
 can predict the future execution of applications precise enough to anticipate
 deadline misses before they occur.
 Outside the implicit clairvoyance of periodic task systems, no other scheduling
 system I am aware of features a comparable look-ahead capability.
\end_layout

\begin_layout Standard
Literature mentions look-ahead together with scheduling in the areas of
 constraint satisfaction problems
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
constraint satisfaction problem
\end_layout

\end_inset

,
\begin_inset CommandInset citation
LatexCommand cite
key "Schaerf:CSP"

\end_inset

 factory scheduling,
\begin_inset CommandInset citation
LatexCommand cite
key "Itoh:ProductionScheduling"

\end_inset

 and server management for on-demand video.
\begin_inset CommandInset citation
LatexCommand cite
key "Yu:VOD_LookAhead"

\end_inset

 For constraint satisfaction problems and factory scheduling, look-ahead
 improves the traversal of the solution search space.
 Thus, the scheduling does not look ahead along the time axis into the future,
 but along the search tree into the solution space.
 In the on-demand video context, the server tries to batch multiple viewers
 of the same video to save disk requests.
 Look-ahead and buffering help the server to satisfy multiple users from
 the same disk stream, even if they independently pause and resume playback.
 Patterson
\begin_inset space ~
\end_inset

et
\begin_inset space ~
\end_inset

al.
\begin_inset space ~
\end_inset

investigated the submission of future jobs to a peripheral scheduler to
 improve prefetching for IO
\begin_inset space ~
\end_inset

devices.
\begin_inset CommandInset citation
LatexCommand cite
key "Patterson:InformedPrefetching"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I also evaluate the timeliness
\end_layout

\end_inset

 delivered by 
\noun on
Atlas
\noun default
 due to its compliance with the requested timing requirements.
 I compare with the behavior under conventional fair share scheduling without
 timing constraints.
 This evaluation serves to convince the reader of the scheduler’s basic
 functionality with respect to the timeliness property.
 I do not claim to improve the state of the art in this aspect.
\end_layout

\begin_layout Standard
I describe and evaluate the real-time task model and scheduler in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "3-chap:Real-Time"

\end_inset

.
\end_layout

\begin_layout Section
Core Placement
\end_layout

\begin_layout Standard
Managing multiple cores adds another dimension to the scheduling problem:
 Not only does the scheduler order jobs along the time axis, but it also
 has to decide on a placement of the work onto cores.
\end_layout

\begin_layout Standard
Serving the timeliness goal, applications structure their execution into
 jobs that bear a timing requirement.
 To enable parallel execution, applications must also structure their execution
 into independent pieces that can execute simultaneously.
 To simplify development, I decouple these two structures by allowing for
 parallelism within an individual job.
 Such task models have been presented before.
\begin_inset CommandInset citation
LatexCommand cite
key "Collette:JobParallelism"

\end_inset


\end_layout

\begin_layout Standard
For jobs with internal parallelism, 
\noun on
Atlas
\noun default
 can trade using more cores against using more time on fewer cores.
 In order to make those decisions, it needs information about the available
 parallelism and speedup.
 Placement of work on cores also influences execution times due to contention
 on shared caches and memory.
\begin_inset CommandInset citation
LatexCommand cite
key "Zhuravlev:DIO"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\begin_inset Graphics
	filename Plots/1-Introduction/Parallel_Execution_Alternatives.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Parallel-Execution-Alternatives"

\end_inset

Parallel Execution Alternatives
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I contribute a collaboration mechanism
\end_layout

\end_inset

 that allows applications to propagate the degree of parallelism to the
 scheduler.
 Integrating with the lambda programming-style, I tap into the application
 to automatically deduce available parallelism and to maintain a model of
 the parallel speedup
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
parallel speedup
\end_layout

\end_inset

: For each number of cores a job can make use of, the scheduler receives
 an execution time estimate as illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Parallel-Execution-Alternatives"

\end_inset

.
 These alternative resource requirements are predicted by 
\noun on
Atlas
\noun default
 ahead of time, allowing look-ahead scheduling.
\end_layout

\begin_layout Standard
Parallel speedup can be limited by serial sections in the applied algorithm
 or by imbalance in the workload partitioning.
 To demonstrate a typical optimization workflow, I show an example of improving
 the speedup by balancing the workload.
 I presented this work on the 7th International Conference on Embedded Software.
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Balancing"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I claim that the rich information
\end_layout

\end_inset

 provided by applications allows non-work-conserving scheduling
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
non-work-conserving scheduling
\end_layout

\end_inset

 disciplines that reduce core allocation more aggressively than competing
 approaches.
 A non-work-conserving scheduler deliberately keeps cores idle even though
 runnable threads are available.
 
\noun on
Atlas
\noun default
 knows about the resource requirements of jobs, so it can select a core
 assignment that uses a minimum number of cores while still meeting all
 timing requirements.
 The schedulers in commodity operating systems are work-conserving.
 They lack this knowledge and therefore occupy cores eagerly.
\end_layout

\begin_layout Standard
Because parallel speedup is typically sub-linear,
\begin_inset CommandInset citation
LatexCommand citet
key "Amdahl:AmdahlsLaw"

\end_inset

 reducing core allocation reduces the overhead that comes with parallel
 execution.
 The lowest overhead would be achieved with single-core execution, which
 however also yields the worst response time.
 Timing requirements constrain this optimization problem with a limit on
 the tolerated response time.
 Existing real-time research relies on the implicit knowledge of future
 jobs provided by periodic task models.
\begin_inset CommandInset citation
LatexCommand cite
key "Collette:JobParallelism"

\end_inset

 I show how look-ahead scheduling reduces core allocation compared to the
 worst-case planning implied by periodic tasks.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Non-work-conserving scheduling policies
\end_layout

\end_inset

 have been researched before to improve response times
\begin_inset CommandInset citation
LatexCommand cite
key "Rosti:NWC_Partitioning"

\end_inset

 or throughput.
\begin_inset CommandInset citation
LatexCommand cite
key "Fedorova:SMT_Scheduling"

\end_inset

 Keeping idle cores as spares to cater for future job arrivals reduces overall
 response times, however future arrivals are merely guessed from past observatio
ns.
 Throughput can suffer, when co-scheduled jobs causes thrashing on shared
 resources such as the last level cache.
 In such cases, deliberately not using all the available parallelism increases
 instruction throughput.
 We can observe similar behavior with magnetic disks: Interleaving requests
 from two different applications can cause more disk-head movements and
 thus lower throughput compared to briefly idling the disk to allow for
 batching of consecutive requests from the same application.
\begin_inset CommandInset citation
LatexCommand cite
key "Iyer:Anticipatory"

\end_inset

 These solutions do not exploit knowledge of timing requirements, resource
 requirements or the benefit of look-ahead.
\end_layout

\begin_layout Standard
I present and discuss parallel speedup estimation and the non-work-conserving
 scheduler in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Parallelism"

\end_inset

.
\end_layout

\begin_layout Section
Overload Handling
\end_layout

\begin_layout Standard

\noun on
Atlas
\noun default
 does not enforce an admission process.
 I think rejecting application launches or new subtasks within an application
 would be too surprising for the user and the developer.
 Consequently, the system can experience overload situations.
 Lacking an admission that can analytically prevent overloads, 
\noun on
Atlas
\noun default
 instead needs to offer mechanisms that handle overload gracefully.
\end_layout

\begin_layout Standard
Overload can occur for two reasons: First, an application can lie about
 its CPU demand.
 It announces timing and resource requirements that the scheduler can meet
 with idle computing capacity.
 However, at runtime, the application’s jobs run longer than reported.
 The scheduler handles such situations by ensuring that lying applications
 never degrade the service of honest applications.
\end_layout

\begin_layout Standard
The second overload condition is more interesting: Applications specify
 their demands correctly, but collectively ask for more CPU resources than
 available.
 In such a situation, service degradation is unavoidable.
 The best the system can do is control the overload to maximize the quality
 delivered to the user.
 Quality is a workload-specific measure and applications may apply custom
 strategies to adapt to overload.
\begin_inset CommandInset citation
LatexCommand cite
key "Isovic:QoS_Video"

\end_inset

 Interaction between scheduler and applications is therefore needed.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I contribute quality-weighted back-pressure
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
back-pressure
\end_layout

\end_inset

 as a mechanism to communicate overload mitigation from the scheduler to
 applications.
 When the scheduler detects an overload situation, it forcibly reduces the
 CPU time allocated to each application so that the overload is resolved.
 These cutbacks are apportioned according to a quality-weighted policy
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
quality-weighted policy
\end_layout

\end_inset

: Applications tell the scheduler how much reduction they can tolerate to
 maintain a minimal acceptable quality.
 This quality threshold is resembles probabilistic real-time task models
 such as QRMS.
\begin_inset CommandInset citation
LatexCommand cite
key "Hamann:QRMS"

\end_inset

 The scheduler combines this elasticity with the CPU load caused by the
 application to distribute the cutbacks.
 I will evaluate how a fully quality-fair policy compares to a fully resource-fa
ir policy.
\end_layout

\begin_layout Standard
The remaining CPU time assigned to each application is reported back to
 encourage adaptation
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
adaptation
\end_layout

\end_inset

.
 Developers can implement custom degradation strategies like load-shedding
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
load-shedding
\end_layout

\end_inset

 or imprecise computation
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
imprecise computation
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Lin:Imprecise"

\end_inset

 that take an application-specific notion of quality into account.
 I published a quality-aware adaptation technique for video playback in
 the Journal of Visual Communication and Image Representation.
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:VideoQuality"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Global management and local adaptation
\end_layout

\end_inset

 to react to overload have been researched independently.
 Scheduler systems such as AQuoSA
\begin_inset CommandInset citation
LatexCommand cite
key "Palopoli:AQuoSA"

\end_inset

 or Cooperative Polling
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:CoopPoll"

\end_inset

 manage overload situations by distributing CPU capacity according to an
 inter-application fairness policy.
 AQuoSA applies resource fairness, while Cooperative Polling uses application
 knowledge to establish quality fairness.
 Intra-application adaptation has been investigated for tasks like video
 playback
\begin_inset CommandInset citation
LatexCommand cite
key "Wuest:QoS_Video"

\end_inset

 or network servers.
\begin_inset CommandInset citation
LatexCommand cite
key "Welsh:SEDA"

\end_inset


\end_layout

\begin_layout Standard
Priority-Progress Adaptation
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:PriorityProgress"

\end_inset

 by Krasic
\begin_inset space ~
\end_inset

et
\begin_inset space ~
\end_inset

al.
\begin_inset space \space{}
\end_inset

is the only work I am aware of that combines global overload management
 with per-application adaptation.
 It does so by exposing a quality measure for each individual job, allowing
 the scheduler to globally order jobs by quality.
 The adaptation strategy to shed low-priority jobs on overload is therefore
 dictated by the scheduling method.
\end_layout

\begin_layout Standard
None of the presented research results exploit look-ahead to steer adaptation
 decisions.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
I claim that look-ahead improves quality
\end_layout

\end_inset

 when mitigating overload.
 Because of its look-ahead characteristic, 
\noun on
Atlas
\noun default
 can detect overload before it occurs.
 Applications receive announcements of resource cutbacks ahead of time,
 including the time when the future deadline miss is anticipated and how
 much CPU capacity remains.
 The applications can then degrade any pending job before the critical deadline
 to satisfy the reduction in CPU time.
 The resulting choice allows trimming jobs with a favorable ratio between
 resource savings and quality impact.
 Additionally, each application can choose the most suitable adaptation
 technique independently.
\end_layout

\begin_layout Standard
I validate the claim by comparing overload management with and without look-ahea
d.
 The flexibility of quality-weighted back-pressure is evaluated with implementat
ions of different degradation strategies.
 I explain and analyze these overload management and adaptation techniques
 in Chapter
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "5-chap:Adaptivity"

\end_inset

.
\end_layout

\begin_layout Section
Demo Application
\end_layout

\begin_layout Standard
The primary example workload in this thesis is video playback
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
video playback
\end_layout

\end_inset

.
 I chose video because I think it is representative for a number of real-time
 and throughput applications, because it combines interesting properties:
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Plots/1-Introduction/Decoding_Times_Histogram.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Decoding-Time-Histogram"

\end_inset

Histogram of Sintel-
\begin_inset Formula $4\mathrm{k}$
\end_inset

 Decoding Times
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Video playback is subject to deadlines that derive naturally from the frame
 rate specification or the presentation timestamps in the video stream.
 Timing requirements are tight, because even small delays
\begin_inset Foot
status open

\begin_layout Plain Layout
The telecine conversion of 24
\begin_inset space \thinspace{}
\end_inset

frames/s cinematic content to 30
\begin_inset space \thinspace{}
\end_inset

frames/s for NTSC television causes timing errors smaller than 20
\begin_inset space \thinspace{}
\end_inset

ms, which are visible to some viewers as jerky motion, especially in scenes
 with slow and steady camera movement.
 This error is called telecine judder (cf.
\begin_inset space ~
\end_inset


\emph on

\begin_inset CommandInset href
LatexCommand href
name "Wikipedia: Telecine"
target "http://en.wikipedia.org/w/index.php?title=Telecine&oldid=475341309#Telecine_judder"

\end_inset


\emph default
).
\end_layout

\end_inset

 in the frame display will be visible to the user.
\end_layout

\begin_layout Itemize
Although decoding and displaying video frames are repetitive tasks, they
 do not adhere to the classical periodic task model where the deadline of
 one job coincides with the release of the next job.
 Due to buffering in the video player, the jobs’ scheduling windows between
 release and deadline can overlap.
\end_layout

\begin_layout Itemize
Video playback can be CPU intensive, especially with high resolutions and
 modern coding schemes.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Decoding-Time-Histogram"

\end_inset

 visualizes the single-thread decoding times of the 
\begin_inset Formula $4096\!\!\times\!\!1744\,\mathrm{pixel}$
\end_inset

 Sintel-
\begin_inset Formula $4\mathrm{k}$
\end_inset

 video
\begin_inset Foot
status open

\begin_layout Plain Layout
Such video dimensions may not be common today, but they are already used
 in cinematic applications.
 With high resolution displays coming to market, such videos may appear
 on desktops soon.
 The properties of all videos used in this thesis are summarized in Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "3-tab:Videos"

\end_inset

.
\end_layout

\end_inset

 on a 
\begin_inset Formula $2.4\,\mathrm{GHz}$
\end_inset

 Intel Core
\begin_inset space ~
\end_inset

i5.
 The high utilization is challenging for schedulers because it increases
 the likelihood that misdirection of CPU time leads to deadline misses.
 In the figure, the marked decoding time equivalent to 24
\begin_inset space ~
\end_inset

frames per second shows that a significant portion of the frames need more
 time for decoding than available between the display instants of two consecutiv
e frames.
\end_layout

\begin_layout Itemize
To cope with the high load, video decoding can be parallelized to make use
 of multiple CPU cores.
 This allows me to evaluate 
\noun on
Atlas’
\noun default
 benefits for core placement.
\end_layout

\begin_layout Itemize
The CPU load is also highly dynamic.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand vref
reference "1-fig:Total-and-Zoomed"

\end_inset

 illustrates the short-term and long-term variations.
 The execution times of jobs are therefore difficult to predict and worst-case
 estimates would prohibitively over-allocate resources.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Plots/1-Introduction/Decoding_Times_Timeline.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-fig:Total-and-Zoomed"

\end_inset

Total and Zoomed Views of Sintel-
\begin_inset Formula $4\mathrm{k}$
\end_inset

 Decoding Times
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
When overloaded, a video player conventionally adapts by dropping frames.
 However, more sophisticated degradation options like low-quality decoding
 fallbacks are also available and can improve quality per invested CPU cycles.
\end_layout

\begin_layout Standard
By showing that 
\noun on
Atlas
\noun default
 can support video playback in all these aspects I hope to convince the
 reader that it also handles other applications with a subset of the stated
 properties.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "1-mar:Typical-Properties"

\end_inset

 condenses typical behavior of selected desktop real-time tasks.
 Although video is used as the running example throughout this thesis, I
 complement it with other experiments to substantiate the evaluation.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/1-Introduction/Real-Time_Applications.svg

\end_inset


\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "1-mar:Typical-Properties"

\end_inset

Typical Properties of Selected Real-Time Applications
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Before we dive into the details
\end_layout

\end_inset

 of the timeliness, core placement and overload handling aspects of 
\noun on
Atlas, 
\noun default
the next chapter gives an overview of the emerging use of lambdas as the
 programming model for parallel desktop applications.
 The intimate vertical integration proposed by 
\noun on
Atlas
\noun default
 requires developer endorsement, so taking a closer look at programming
 innovation is valuable.
 Aligning my task model with a future-proof paradigm helps simplifying the
 use of 
\noun on
Atlas
\noun default
 for developers.
\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "2-chap:Anatomy"

\end_inset

Anatomy of a Modern Desktop Application
\end_layout

\begin_layout Standard
For 
\begin_inset Flex Noun
status collapsed

\begin_layout Plain Layout
Atlas
\end_layout

\end_inset

, I envision a tight integration of application, runtime libraries and the
 CPU scheduler.
 The following pages explain the programming style of modern desktop application
s and motivate, how 
\begin_inset Flex Noun
status collapsed

\begin_layout Plain Layout
Atlas
\end_layout

\end_inset

 can be fitted for this style and what benefits the combination affords.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Three major paradigm shifts
\end_layout

\end_inset

 changed the way desktop software is written, with the latest of these transitio
ns still in progress.
 Historically, all applications started out single-threaded
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
single-threaded
\end_layout

\end_inset

.
 The traditional Unix design only knows about processes that implicitly
 host only a single activity.
\begin_inset CommandInset citation
LatexCommand cite
key "OpenGroup:SingleThread"

\end_inset

 There was no notion of multiple threads per address space.
 The resulting applications had no internal parallelism, which simplified
 programming and freed libraries from the worries of reentrant calls.
\end_layout

\begin_layout Standard
However, this model made the developers’ lives easier at the price of user
 irritation: When an application synchronously performs an IO-operation,
 for example reading a large file from disk or waiting for data from the
 network, its only thread is stuck in a blocking system call.
 Consequently, that thread is now unavailable for user interactions.
 The application appears dead for a while.
 The visual cue for such a mishap are redraw artifacts that tail other windows
 as they are dragged over the blocked application.
 They appear like in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-mar:Blocked-Window-Redraws"

\end_inset

 because the blocked application no longer performs updates of its window
 content.
\end_layout

\begin_layout Standard
\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/2-Anatomy/Blocked_Redraw.svg
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-mar:Blocked-Window-Redraws"

\end_inset

Blocked Window Redraws
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Recognizing the importance of responsiveness,
\end_layout

\end_inset

 developers started to migrate long-running or blocking work off the main
 user interface thread.
 Two mechanisms to support this change were asynchronous interfaces
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
asynchronous interface
\end_layout

\end_inset

 and the use of multiple threads.
 Both have their share of problems.
 Asynchronous interfaces split the logical code flow into two parts: The
 setup of context and arguments precedes the asynchronous invocation.
 Results are interpreted once the asynchronous operation finishes.
 Often, a callback by the underlying framework executes this second part,
 which riddles the code with additional functions just for callback purposes.
 This callback-soup
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
callback-soup
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "SantAnna:ProblemEvents"

\end_inset

 complicates code understanding.
 Furthermore, because the callback executes in a separate function, the
 context of local variables is different from when the asynchronous processing
 started, a problem known as stack ripping
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
stack ripping
\end_layout

\end_inset

.
\begin_inset CommandInset citation
LatexCommand cite
key "Adya:StackRipping"

\end_inset


\end_layout

\begin_layout Standard
On the other hand, it is also difficult for programmers to orchestrate multiple
 threads correctly.
 Threads do not suffer from stack ripping, because they individually follow
 a single control flow with a dedicated stack.
 However, as the number of concurrent threads increases, their interleaving
 becomes increasingly complex to manage.
 Programmers unknowingly make wrong assumptions on the execution order of
 code on different threads.
\begin_inset CommandInset citation
LatexCommand cite
key "Lu:ConcurrencyBugs"

\end_inset

 As mainstream computers featured only a single CPU core, those assumptions
 used to hold.
 But when Intel’s Hyper-Threading marked the first exposure of commodity
 machines to hardware concurrency, many multithreaded programs suddenly
 broke.
\end_layout

\begin_layout Standard
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
A new approach to concurrency is needed.
\end_layout

\end_inset

 The current shift in parallel programming
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:LambdasEverywhere"

\end_inset

 leads us away from threads and closer to the ideas behind asynchronous
 invocation, but without inheriting their historical callback-soup and stack
 ripping downsides.
 Today’s developers are discouraged from using threads directly, but should
 instead use new programming language constructs that allow them to envelop
 a piece of code and dispatch it for asynchronous invocation.
\end_layout

\begin_layout Standard
The name for this paradigm changes with the chosen programming language
 and runtime environment.
 The term task-based programming
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
task-based programming
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:TaskBasedProgramming"

\end_inset

 has been coined, but also covers traditional callback-style models.
 Given that the term “task” is hopelessly overloaded already, I will avoid
 it and call the programming style 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
asynchronous lambdas
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
asynchronous lambda
\end_layout

\end_inset

 instead.
\end_layout

\begin_layout Standard
The following Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-fig:Mouse-Processing-Styles"

\end_inset

 shows four pseudocode verions of a long-running computation triggered by
 user interaction, from the historical serial version to the modern lambda-style
:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="22text%" special="@{}>{\centering}p{101pt}">
<column alignment="center" valignment="top" width="110pt">
<column alignment="center" valignment="top" width="102pt">
<column alignment="center" valignment="top" width="107pt">
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	result = longWork();
\end_layout

\begin_layout Plain Layout

	view.update(result);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	context = { view };
\end_layout

\begin_layout Plain Layout

	async(longWork,
\end_layout

\begin_layout Plain Layout

		cb, context);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

/* callback */
\end_layout

\begin_layout Plain Layout

void cb(result, context)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = context[0];
\end_layout

\begin_layout Plain Layout

	view.update(result);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	context = { view };
\end_layout

\begin_layout Plain Layout

	thread_start(work,
\end_layout

\begin_layout Plain Layout

		context);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

/* worker thread */
\end_layout

\begin_layout Plain Layout

void work(context)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = context[0];
\end_layout

\begin_layout Plain Layout

	result = longWork();
\end_layout

\begin_layout Plain Layout

	view.update(result);
\end_layout

\begin_layout Plain Layout

	thread_exit();
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

void mouseClick(event)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	view = event.target;
\end_layout

\begin_layout Plain Layout

	async(^{
\end_layout

\begin_layout Plain Layout

		result = longWork();
\end_layout

\begin_layout Plain Layout

		view.update(result);
\end_layout

\begin_layout Plain Layout

	});
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Serial Version
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Asynchronous with Callback
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Multiple Threads
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Asynchronous Lambda
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace 20pt
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-fig:Mouse-Processing-Styles"

\end_inset

Pseudocode Examples for Long-Running Mouse Click Processing
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

Serial
\begin_inset space \space{}
\end_inset

Version is the shortest of the four and the easiest to read, because it
 describes the logical order of processing steps without much distraction
 by language clutter: First, the user interface element 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
view
\end_layout

\end_inset

 is fetched by evaluating where the user clicked.
 The long computation follows and its result updates the representation
 on screen.
\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

Callback
\begin_inset space \space{}
\end_inset

Version illustrates the stack ripping problem: What used to be a continuous
 control flow representing a single conceptual job is now broken across
 two functions.
 The programmer must explicitly deliver local state from the first function,
 if the second function needs access to it.
 After registering 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
longWork
\end_layout

\end_inset

 for execution, control returns to the runtime, which invokes the callback
 as the result is available.
 The callback function and the context act as a continuation to complete
 the job.
\end_layout

\begin_layout Description
Multiple
\begin_inset space \space{}
\end_inset

Threads similarly require manual passing of contextual state between the
 invoker and the worker thread.
 Processing is again split across two functions.
 A new problem introduced in this version is the updating of the view from
 a background thread.
 Many user interface frameworks limit updates to the main thread to avoid
 dealing with concurrent invocation.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:ThreadSafety,Qt:ThreadingBasics"

\end_inset

 Such a limitation further complicates the use of multiple threads.
\end_layout

\begin_layout Description
The
\begin_inset space \space{}
\end_inset

Lambda
\begin_inset space \space{}
\end_inset

Version on the very right invokes a block of code asynchronously, but without
 using a callback or manually managing separate threads.
 In fact, using lambdas, the code regains a lot of the simplicity of the
 serial version, which is the main reason why this programming style is
 so attractive.
 The pseudo-code lambda in the figure uses the block syntax from Apple’s
 Grand
\begin_inset space ~
\end_inset

Central
\begin_inset space ~
\end_inset

Dispatch (GCD) system
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatch"

\end_inset

, where a caret
\begin_inset space ~
\end_inset


\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
^
\end_layout

\end_inset

 marks the lambda code.
 The notation is not simplified, the example shows all typing the programmer
 has to do.
 The 
\begin_inset Flex Code
status collapsed

\begin_layout Plain Layout
view
\end_layout

\end_inset

 variable, which was assigned outside the lambda, is transparently available
 inside the lambda without any manual state transfer.
 If libraries impose concurrency limitations, GCD allows for seamless dispatchin
g of work back to the main thread.
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:MainThread"

\end_inset


\end_layout

\begin_layout Standard
Threads are still used behind the scenes to implement the asynchronous execution
 of lambdas, but the programmer does not need to bother.
 This avoids explicit thread management which often leads to an inflexible
 hard-coded assignment of work to threads that may not be optimal on the
 end-user’s machine.
 Instead, the runtime environment can manage the number of active threads,
 taking into account the number of cores and the current load on the machine.
 I will explore this control potential when I discuss core placement in
 Section
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "4-chap:Parallelism"

\end_inset

.
\end_layout

\begin_layout Section
Lambdas Far and Wide
\end_layout

\begin_layout Standard
Asynchronous lambdas combine a programming pattern based on asynchronous
 invocation and a lambda language feature to deliver a unique combination
 of properties.
\end_layout

\begin_layout Description
Asynchronous
\begin_inset space \space{}
\end_inset

invocation originates from event-based programming
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
event-based programming
\end_layout

\end_inset

.
\begin_inset CommandInset citation
LatexCommand cite
after "-2\\baselineskip"
key "Krohn:Events"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
manual offset
\end_layout

\end_inset

 High-thoughput network servers experience scalability bottlenecks when
 assigning each incoming request to a dedicated thread.
 Performance improves when organizing the server such that queues collect
 pieces of work and execute them asynchronously.
\begin_inset CommandInset citation
LatexCommand cite
after "-2\\baselineskip"
key "Welsh:SEDA"

\end_inset

 Queuing work instead of explicitly spawning a thread allows the runtime
 layer to control the number of threads, employing strategies like thread
 pooling or system-wide load balancing.
\end_layout

\begin_layout Description
Lambdas automatically transfer state by capturing variables from the enclosing
 scope.
 This relieves the programmer from manually collecting contextual data.
 Lambdas also preserve the logical locality of the code, because they appear
 inline and not as separate functions.
 The code looks like a serial flow of instructions and is easier to read
 than code written for threaded or callback parallelism.
\end_layout

\begin_layout Standard
The compiler and runtime combine the lambda’s code block and the necessary
 state to an object that can be passed as an argument to functions, making
 this language feature a natural fit for the pattern of asynchronous invocation.
 Herb Sutter believes lambdas are “the
\begin_inset space ~
\end_inset

holy
\begin_inset space ~
\end_inset

grail” for developing a library of parallel programming patterns.
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:C++AMP_Keynote"

\end_inset

 An illustrative analogy to the use of asynchronous lambdas instead of threads
 is the shift from circuit-switched networks to packet routing.
\begin_inset CommandInset citation
LatexCommand cite
key "MacResearch:AboardGrandCentral"

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
Existing implementations
\end_layout

\end_inset

 of asynchronous lambdas cover all or a significant subset of the four aspects
 of the programming paradigm:
\end_layout

\begin_layout Itemize
\begin_inset Argument
status collapsed

\begin_layout Plain Layout
noitemsep
\end_layout

\end_inset

logical coherence of the code,
\end_layout

\begin_layout Itemize
automatic state capturing,
\end_layout

\begin_layout Itemize
asynchronous execution, and
\end_layout

\begin_layout Itemize
automatic thread management.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
To show that this concept is now gaining traction, the following Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "2-tab:Asynchronous-Lambdas"

\end_inset

 presents a selection of popular complete and partial implementations, including
 their name for the unit of code execution, for which the different solutions
 are unfortunately not in agreement:
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\begin_inset Tabular
<lyxtabular version="3" rows="11" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="0pt">
<column alignment="left" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Implementation
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Term
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Logical Coherence
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
State Capture
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Asynch.
 Execution
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" rotate="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thread Management
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Apple Grand Central Dispatch
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Grand Central Dispatch
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Block
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Microsoft Parallel Patterns Library
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Parallel Patterns Library
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Lambda
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathrm{X10}$
\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $\mathrm{X10}$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activity
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google Go
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Goroutine
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel Threading Building Blocks
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Threading Building Blocks
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Task
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{++}
\end_layout

\end_inset


\begin_inset Formula $11$
\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{++}
\end_layout

\end_inset


\begin_inset Formula $11$
\end_inset


\end_layout

\end_inset

 (no additional libraries)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Lambda
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OpenMP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iteration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Galois
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iteration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TaskC
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Task
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Qt Signals and Slots
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Event
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "2-tab:Asynchronous-Lambdas"

\end_inset

Complete or Partial Implementations of Asynchronous Lambdas
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
Two complete solutions are available from commercial operating system vendors:
 Microsoft offers the Parallel Patterns Library,
\begin_inset CommandInset citation
LatexCommand cite
key "MSDN:C++PPL"

\end_inset

 a library on top of standard C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{++}
\end_layout

\end_inset


\begin_inset space ~
\end_inset

lambdas, and Apple is pushing for Grand Central Dispatch,
\begin_inset CommandInset citation
LatexCommand cite
key "Apple:GrandCentralDispatch"

\end_inset

 a combined C
\begin_inset space ~
\end_inset

language extension and work queue library.
 IBM developed 
\begin_inset Formula $\mathrm{X10}$
\end_inset

, a new language for parallel programming,
\begin_inset CommandInset citation
LatexCommand cite
key "Charles:X10"

\end_inset

 which also offers a full implementation of asynchronous lambdas.
 In addition, 
\begin_inset Formula $\mathrm{X10}$
\end_inset

 also introduces a 
\begin_inset Flex SmallCaps
status collapsed

\begin_layout Plain Layout
\noindent
places
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
places
\end_layout

\end_inset

 concept to represent locality in a partitioned address space.
\end_layout

\begin_layout Standard
Goroutines in Google’s Go language
\begin_inset CommandInset citation
LatexCommand cite
key "Google_Go"

\end_inset

 are functions that are executed asynchronously, with the Go runtime managing
 threads automatically.
 Go’s asynchronous lambda scorecard remains incomplete because its closures
 are anonymous inline functions that do not capture state.
\end_layout

\begin_layout Standard
C
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{0.3mm}{++}
\end_layout

\end_inset


\begin_inset Formula $11$
\end_inset

 offers lambdas as part of the language,
\begin_inset CommandInset citation
LatexCommand cite
key "C++11"

\end_inset

 but thread management for parallel execution needs to be added by an additional
 library like Intel’s Threading Building Blocks.
\begin_inset CommandInset citation
LatexCommand cite
key "Intel_TBB"

\end_inset

 Its primitives are tailored for parallelizing iterative and pipelined work,
 not for general asynchronous execution.
\end_layout

\begin_layout Standard
OpenMP employs an even more restrictive model of concurrency.
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
implementations of lambda programming
\end_layout

\begin_deeper
\begin_layout Itemize
do a table with checkmarks comparing different implementations of the paradigm
\end_layout

\begin_deeper
\begin_layout Itemize
cross-thread signal-slot-connections in Qt
\begin_inset CommandInset citation
LatexCommand cite
key "Qt:SignalsSlotsThreads"

\end_inset

: asynchronous method calls, no automatic thread management, no automatic
 state-capturing
\end_layout

\begin_layout Itemize
TaskC model for Core Manager
\begin_inset CommandInset citation
LatexCommand cite
key "Arnold:TaskC"

\end_inset

: asynchronous task spawning but not nested, automatic placement decision,
 manual statue capture because its not shared memory
\end_layout

\begin_layout Itemize
OpenMP for regular algorithms like iterating over dense arrays, mostly paralleli
zing loops: automatic thread assignment, guided self-scheduling to reduce
 dispatching overhead, synchronous
\end_layout

\begin_layout Itemize
Galois
\begin_inset CommandInset citation
LatexCommand cite
key "Kulkarni:Galois"

\end_inset

: optimistic set iterator
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
how it feels
\end_layout

\begin_deeper
\begin_layout Itemize
focus on GCD, explain primitives, illustrate with little sequence diagrams
\end_layout

\begin_deeper
\begin_layout Itemize
railway trains on a track network
\begin_inset CommandInset citation
LatexCommand cite
key "MacResearch:AboardGrandCentral"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
work queues
\end_layout

\begin_deeper
\begin_layout Itemize
necessary for data-dependent parallelism: build-up parallelism at runtime,
 because it is unknown statically
\end_layout

\begin_layout Itemize
executing some job can add new jobs to the set
\end_layout

\begin_layout Itemize
useful to implement irregular algorithms (processing on graph-like data
 structures with pointers, opposite: arrays, dense matrices)
\end_layout

\begin_layout Itemize
SPMD-to-MPMD-generalization of Galois optimistic set iterators
\end_layout

\begin_layout Itemize
principles for constructing runtimes have been explored a while back
\begin_inset CommandInset citation
LatexCommand cite
key "Blumofe:Cilk"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
express all latent parallelism
\end_layout

\begin_deeper
\begin_layout Itemize
developer expresses what can run in parallel
\end_layout

\begin_layout Itemize
runtime decides whether to translate it to actual parallelism
\end_layout

\end_deeper
\begin_layout Itemize
the UI thread (main thread) does no real work (see microkernel paradigm),
 it merely dispatches (spine-analogy) to keep background workers busy
\end_layout

\begin_deeper
\begin_layout Itemize
similar to immediate/system reservations in resource kernels
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset


\end_layout

\begin_layout Itemize
master and worker threads in OpenMP or Galois
\end_layout

\end_deeper
\begin_layout Itemize
synchronization is orthogonal to parallelism
\end_layout

\begin_deeper
\begin_layout Itemize
can be provided by mutual exclusion (pessimistic, see GCD) or transactional
 memory (optimistic, see Galois, rollback)
\end_layout

\begin_layout Itemize
interface to synchronisation is part of the same concept: serial queues
 allow explicit task ordering and allow the developer to reason about it
\end_layout

\begin_layout Itemize
odered iterators in Galois
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
result of this architecture: most work is done asynchronously and is announced
 by the before execution
\end_layout

\begin_deeper
\begin_layout Itemize
for autonomous computing tasks, applications already know what lies ahead
\end_layout

\begin_deeper
\begin_layout Itemize
only code and data determine the upcoming computation, both are known ahead-of-t
ime
\end_layout

\begin_layout Itemize
counterexample: direct, low-latency reaction to user input
\end_layout

\end_deeper
\begin_layout Itemize
limited view into the future as a common trait for modern applications (this
 is a key point here)
\end_layout

\begin_layout Itemize
lambdas (or groups of them) are natural receivers for metadata by the developer
 (deadlines) or automatically by the system (training)
\end_layout

\begin_deeper
\begin_layout Itemize
individual lambdas may be too fine-grained
\end_layout

\begin_layout Itemize
model jobs as lambdas or groups thereof
\end_layout

\begin_layout Itemize
attach deadlines there
\end_layout

\begin_layout Itemize
GCD supports groups
\end_layout

\end_deeper
\begin_layout Itemize
set down the terminology here:
\end_layout

\begin_deeper
\begin_layout Description
job: work item of code+metadata, unit of scheduling
\end_layout

\begin_layout Description
lambda: independently executable piece of code, unit of parallelism
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
describe fundamental video player architecture
\end_layout

\begin_deeper
\begin_layout Itemize
FFplay sets up a pipeline of three threads with very different characteristics
\end_layout

\begin_layout Itemize
input thread: blocks in IO, little CPU work
\end_layout

\begin_layout Itemize
decoder thread: high CPU throughput, highly dynamic
\end_layout

\begin_layout Itemize
output thread: very short, like a control task
\end_layout

\begin_layout Itemize
implementation is event-driven with thread-interdependencies
\end_layout

\begin_layout Itemize
spine: main thread runs event dispatch loop as is common in all GUI toolkits
\end_layout

\end_deeper
\begin_layout Itemize
describe adaptation to GCD
\end_layout

\begin_deeper
\begin_layout Itemize
tell about experimentation environment (Ubuntu 12.04 LTS, ffmpeg version)
 here?
\end_layout

\begin_layout Itemize
minimal GCD-runtime implemented, because I want to control threading
\end_layout

\begin_layout Itemize
this manifests the integration between application and scheduler I envision
\end_layout

\begin_layout Itemize
changes to FFplay are small
\end_layout

\begin_layout Itemize
applications change anyway (mobile software, parallel architectures, heterogenei
ty, scale-out)
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:ParallelJungle"

\end_inset


\end_layout

\begin_layout Itemize
leaning my paradigm toward those changes reduces developer effort
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "3-chap:Real-Time"

\end_inset

Real Simple Real
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
raisebox{-0.45mm}{-}
\end_layout

\end_inset

Time
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
many applications have intrinsic real-time characteristics
\end_layout

\begin_deeper
\begin_layout Itemize
real-time naturally surfaces when computers interact with the real world,
 in both input and output
\end_layout

\begin_layout Itemize
all desktops do that, yet almost no desktop software uses real-time programming
\end_layout

\begin_layout Itemize
deadlines for UI code driven by usability requirements: 10/100/1000
\begin_inset space \thinspace{}
\end_inset

ms
\end_layout

\begin_layout Itemize
obvious for animations, which become increasingly ubiquitous and which should
 not stutter if they are supposed to help usability by supporting mental
 transitions
\end_layout

\begin_layout Itemize
even harder for touch-based interaction, where lag of UI breaks the user's
 mental link of interacting with on-screen items directly
\end_layout

\begin_layout Itemize
often buried within the application and not expressed
\end_layout

\begin_layout Itemize
real-time used to be a rare special case, but it should become default;
 this work tries to pave the way
\end_layout

\end_deeper
\begin_layout Itemize
real-time scheduling is about ordering work so that it meets timing requirements
\end_layout

\begin_deeper
\begin_layout Itemize
order matters with time
\end_layout

\begin_layout Itemize
how to communicate timing and resource requirements between application
 and scheduler?
\end_layout

\begin_layout Itemize
existing solutions: spectrum between strong guarantees + complex programming
 and weak guarantees + simple programming
\end_layout

\begin_deeper
\begin_layout Itemize
points in this design space discussed in related work, here: only the ends
\end_layout

\end_deeper
\begin_layout Itemize
one end: classical periodic task model
\end_layout

\begin_deeper
\begin_layout Itemize
inflexible way to express timing requirements, pessimistic resource requirements
\end_layout

\begin_layout Itemize
fixed share of the CPU set aside
\end_layout

\begin_layout Itemize
for video: worst-case planning leads to infeasible reservation way off the
 actual demand
\end_layout

\begin_layout Itemize
however, the advantage: infinite clairvoyance allows an admission test
\end_layout

\begin_layout Itemize
strict admission not useful on desktops: yet another error condition for
 the developer, how to communicate refusal to the user?
\end_layout

\end_deeper
\begin_layout Itemize
other end: fair CPU sharing
\end_layout

\begin_deeper
\begin_layout Itemize
nothing to be done for developers, but also: nothing can be done
\end_layout

\begin_layout Itemize
scheduler distributes CPU evenly across applications according to a fairness
 measure
\end_layout

\begin_layout Itemize
users and applications do not want a fair share, so it's the wrong abstraction
\end_layout

\begin_layout Itemize
but it's the right abstraction for performance isolation
\end_layout

\begin_layout Itemize
pervasive: on Android all Dalvik threads use SCHED_OTHER
\begin_inset CommandInset citation
LatexCommand cite
key "Maia:AndroidRT"

\end_inset


\end_layout

\begin_layout Itemize
applications treated equally, disregarding their timing requirements because
 they are not expressed
\end_layout

\begin_layout Itemize
for video: concurrent heavy calculation may squeeze out video
\end_layout

\begin_layout Itemize
priorities would fix this, but they are an implementation detail of the
 scheduler that is hard to determine for developers in open systems
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
find a good middle ground between both approaches
\end_layout

\begin_deeper
\begin_layout Itemize
express timing requirements, but more flexible than periodic task: deadlines
\end_layout

\begin_layout Itemize
this is an attribute within the application's problem domain
\end_layout

\begin_deeper
\begin_layout Itemize
system cannot guess it
\end_layout

\begin_layout Itemize
developers should be able to provide it
\end_layout

\end_deeper
\begin_layout Itemize
express resource requirements, but without asking for execution times, which
 are hardware-dependent
\end_layout

\begin_layout Itemize
replace full clairvoyance with limited look-ahead
\end_layout

\begin_layout Itemize
instead of fairness and isolation first, put timeliness first and deal with
 fairness only when overloaded
\end_layout

\end_deeper
\begin_layout Itemize
deriving architecture from requirements
\end_layout

\begin_deeper
\begin_layout Itemize
execution time is workload-dependent, deadlines are application-specific:
 application-view needed
\end_layout

\begin_layout Itemize
scheduling must distribute loads so it meets all timing requirements: global
 view needed
\end_layout

\begin_layout Itemize
application-level component and global scheduler must work together
\end_layout

\end_deeper
\begin_layout Itemize
look-ahead
\end_layout

\begin_deeper
\begin_layout Itemize
future execution can be exposed as real-time jobs early
\end_layout

\begin_deeper
\begin_layout Itemize
must stay within application domain
\end_layout

\begin_layout Itemize
metrics are needed to predict execution times
\end_layout

\end_deeper
\begin_layout Itemize
use this knowledge to provide insightful look-ahead
\end_layout

\begin_layout Itemize
previous work usually depends on black-box guessing and post-mortem control
\end_layout

\begin_deeper
\begin_layout Itemize
state the key advancement here and forward-reference to the full related
 work discussion
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
end-to-end solution
\end_layout

\begin_deeper
\begin_layout Itemize
workload: analyze dependency between data and execution time – execution
 time metrics for video
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Predict"

\end_inset


\end_layout

\begin_layout Itemize
application: offer look into the future, derive execution time prediction
 from metrics, attach deadlines to jobs, propagate knowledge down to system
 level
\end_layout

\begin_layout Itemize
system: insert all jobs in an EDF run queue
\end_layout

\end_deeper
\begin_layout Itemize
explain online execution time training in detail
\end_layout

\begin_deeper
\begin_layout Itemize
linear auto-regressive predictor
\end_layout

\begin_layout Itemize
evaluate accuracy of execution time prediction against worst-case allocation
 of a periodic task
\end_layout

\begin_layout Itemize
sensitivity analysis for all the 
\begin_inset Quotes eld
\end_inset

magic
\begin_inset Quotes erd
\end_inset

 parameters of the estimator
\end_layout

\begin_layout Plain Layout
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "3-tab:Videos"

\end_inset

Videos Used in Experiments
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
system scheduler
\end_layout

\begin_deeper
\begin_layout Itemize
job programming model not compatible with fixed task priorities
\end_layout

\begin_deeper
\begin_layout Itemize
the same thread might execute work of different urgency
\end_layout

\begin_layout Itemize
depends on what work the application dispatches when to what queue
\end_layout

\begin_layout Itemize
we could restrict the programmer to allow for more implicit scheduler knowledge
 (like minimum inter-arrival distance), but this work opts not to
\end_layout

\begin_layout Itemize
the urgency of one job remains the same over its lifetime
\end_layout

\begin_layout Itemize
we need dynamic task priorities, but have fixed job priorities, so EDF is
 a good start
\end_layout

\end_deeper
\begin_layout Itemize
our execution times are only estimates
\end_layout

\begin_deeper
\begin_layout Itemize
design for underestimation and late jobs
\end_layout

\begin_layout Itemize
late jobs should not interfere with honest jobs
\end_layout

\begin_layout Itemize
without overload, we want EDF-behavior even when all execution times are
 wrong (for example all 0)
\end_layout

\end_deeper
\begin_layout Itemize
in real applications, jobs may block
\end_layout

\begin_deeper
\begin_layout Itemize
blocking occurs when waiting for another resource
\end_layout

\begin_layout Itemize
we do not consider IO here, but only dependencies among different parts
 of the application
\end_layout

\begin_layout Itemize
video: producer-consumer scenario
\end_layout

\end_deeper
\begin_layout Itemize
scheduler design
\end_layout

\begin_deeper
\begin_layout Itemize
dispatch according to EDF among the not-late jobs
\end_layout

\begin_deeper
\begin_layout Itemize
without overload, there will be no late jobs
\end_layout

\begin_layout Itemize
gives us EDF-behavior when everyone behaves
\end_layout

\begin_layout Itemize
execution times not needed, so they can be arbitrarily wrong
\end_layout

\end_deeper
\begin_layout Itemize
round-robin all late jobs and the next job in EDF order when there is slack
\end_layout

\begin_deeper
\begin_layout Itemize
jobs that need more time can continue, but the next job in EDF order can
 also start work
\end_layout

\end_deeper
\begin_layout Itemize
run next job in EDF order exclusively when deadlines would otherwise be
 missed down the road
\end_layout

\begin_deeper
\begin_layout Itemize
uses estimated execution times to calculate deadline misses
\end_layout

\begin_layout Itemize
makes sure that late jobs do not interfere with the timeliness of honest
 jobs
\end_layout

\end_deeper
\begin_layout Itemize
create a virtual LRT schedule using the estimated execution times
\end_layout

\begin_deeper
\begin_layout Itemize
solves the blocking problem: when starting job at latest possible instant
 and it still blocks, there's nothing else we can do
\end_layout

\begin_layout Itemize
LRT is optimal
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
this scheduling behavior can be simulated in userland by setting thread
 priorities
\end_layout

\begin_deeper
\begin_layout Itemize
experimenting with close interaction of application and scheduler is easier
 in userland
\end_layout

\begin_layout Itemize
separating schedule look-ahead and actual dispatching would be a good implementa
tion strategy anyway
\end_layout

\begin_layout Itemize
only downside: overhead is an upper bound, might be smaller with an in-kernel
 implementation
\end_layout

\end_deeper
\begin_layout Itemize
background jobs can use infinite deadline, no extra best-effort scheduling-band
 needed
\end_layout

\begin_layout Itemize
deadline inheritance on blocking is left for others to analyze
\end_layout

\begin_layout Itemize
evaluate scheduler overhead
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end evaluation
\end_layout

\begin_deeper
\begin_layout Itemize
illustrate that the scheduler works as intended
\end_layout

\begin_layout Itemize
timeliness against a fair share scheduler
\end_layout

\begin_layout Itemize
timeliness against CBS-style reservation
\end_layout

\begin_layout Itemize
system can predict deadline misses, even though it does not have implicit
 clairvoyance from periods
\end_layout

\end_deeper
\begin_layout Itemize
discuss related work in detail
\end_layout

\begin_deeper
\begin_layout Itemize
explore the spectrum introduced above, compare approaches to describe timing
 and resource requirements
\end_layout

\begin_layout Itemize
fixed-priority approaches: strongest guarantees possible, minimal implementation
\end_layout

\begin_deeper
\begin_layout Itemize
expose scheduler implementation to userland, other task models would be
 implemented on top
\end_layout

\begin_deeper
\begin_layout Itemize
microkernel bottom-up paradigm
\end_layout

\begin_layout Itemize
used in practice: QNX in the BlackBerry PlayBook
\end_layout

\end_deeper
\begin_layout Itemize
view shared with Nemesis
\begin_inset CommandInset citation
LatexCommand cite
key "Leslie:Nemesis"

\end_inset

: fixed priorities require full analysis of the system to determine the
 priorities
\end_layout

\begin_layout Itemize
periodic tasks with probabilistic admission
\begin_inset CommandInset citation
LatexCommand cite
key "Hamann:QAS,Hamann:QRMS"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
more flexible resource requirements than strict periodic tasks, probabilistic
 admission
\end_layout

\begin_layout Itemize
higher utilization, but still using period for timing requirements
\end_layout

\begin_layout Itemize
QRMS runs on top of fixed priority scheduling
\end_layout

\end_deeper
\begin_layout Itemize
RT in Linux
\end_layout

\begin_deeper
\begin_layout Itemize
SCHED_RR, SCHED_FIFO
\end_layout

\begin_layout Itemize
RT-patch adds SCHED_DEADLINE, previously SCHED_EDF
\begin_inset CommandInset citation
LatexCommand cite
key "Faggioli:SCHED_EDF"

\end_inset


\end_layout

\begin_layout Itemize
only for root processes
\end_layout

\begin_layout Itemize
no look-ahead
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
resource kernels
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

 separate concerns top-down: applications specify, scheduler manages time
\end_layout

\begin_deeper
\begin_layout Itemize
similar insight into task model: requirements state explicitly, execution
 time is not portable, calibrate automatically
\end_layout

\begin_layout Itemize
otherwise very close to periodic tasks
\end_layout

\begin_layout Itemize
decouple different resources with buffering
\end_layout

\end_deeper
\begin_layout Itemize
reservation approaches: focus on isolation
\end_layout

\begin_deeper
\begin_layout Itemize
integration of hard real-time, soft real-time and best effort: RBED
\begin_inset CommandInset citation
LatexCommand cite
key "Brandt:RBED"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
focus in integration while preserving strong guarantees
\end_layout

\begin_layout Itemize
underlying hard real-time EDF scheduler, resource allocator on top protects
 EDF scheduler from overload
\end_layout

\begin_layout Itemize
key insight: separate resource management from resource dispatching
\end_layout

\begin_layout Itemize
starts with periodic task model and calculates relaxation bounds for parameters
 that keep the schedule feasible
\end_layout

\begin_layout Itemize
applications can submit jobs with parameters within those bounds
\end_layout

\begin_layout Itemize
set_rbed_scheduler() and rbed_deadline_met() calls similar to submit/next
\end_layout

\end_deeper
\begin_layout Itemize
Constant Bandwidth Server
\begin_inset CommandInset citation
LatexCommand cite
key "Abeni:CBS"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
based on the concept of processor reservations
\begin_inset CommandInset citation
LatexCommand cite
key "Mercer:CapacityReserve"

\end_inset


\end_layout

\begin_layout Itemize
employs EDF as the fundamental scheduler
\end_layout

\begin_layout Itemize
provides temporal isolation: protect hard real-time tasks from the messy
 soft real-time tasks
\end_layout

\begin_layout Itemize
different world view: illusion of a dedicated slower processor
\end_layout

\begin_layout Itemize
fluid flow allocation contradicts the job style, more amenable to threads
\end_layout

\begin_layout Itemize
server manages the deadlines (assignment, postponing), not the application
\end_layout

\begin_layout Itemize
does not target improving the soft-real time workload, thus somewhat orthogonal
 to this work
\end_layout

\begin_layout Itemize
could be used to provide isolated hard real-time load in our system
\end_layout

\end_deeper
\begin_layout Itemize
adaptive reservations
\begin_inset CommandInset citation
LatexCommand cite
key "Abeni:AdaptiveReservations"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
similarities: no worst-case planning, because it is wasteful; no focus on
 preventing every single deadline violation
\end_layout

\begin_layout Itemize
overload handling instead of admission
\end_layout

\begin_layout Itemize
two layer approach: dedicated controller per task like HDE
\end_layout

\begin_layout Itemize
dynamic bandwidth adaptation to workload as an afterthought
\end_layout

\begin_layout Itemize
both control and Atlas assume that extrapolation from past behavior works
\end_layout

\begin_layout Itemize
my predictor can be used in a reservation-based system
\end_layout

\begin_layout Itemize
finishing work until the deadline matters, abstracting from the application's
 work pattern using reservations makes this harder to accomplish and requires
 more complexity in control layer
\end_layout

\begin_layout Itemize
CBS covers the real temporal behavior of the application, now we try to
 recreate that in the control layer
\end_layout

\end_deeper
\begin_layout Itemize
slack reclaiming added to CBS
\begin_inset CommandInset citation
LatexCommand cite
key "Palopoli:FeedbackReclaiming"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
results in AQuoSA
\begin_inset CommandInset citation
LatexCommand cite
key "Palopoli:AQuoSA"

\end_inset

 system
\end_layout

\end_deeper
\begin_layout Itemize
AIRS
\begin_inset CommandInset citation
LatexCommand cite
key "Kato:AIRS"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
CBS-based reservations combined with EDF-WM multicore scheduler
\end_layout

\begin_layout Itemize
reservation extends CBS to reclaim slack
\end_layout

\begin_layout Itemize
no evaluation against freely migrating schedulers such as CFS
\end_layout

\end_deeper
\begin_layout Itemize
Darwin time-constrained threads
\end_layout

\begin_deeper
\begin_layout Itemize
periodic thread with an average and maximum execution time
\end_layout

\begin_layout Itemize
accessible for non-root processes
\end_layout

\begin_layout Itemize
vague demotion policy to prevent denial of service
\end_layout

\begin_layout Itemize
execution time provided directly
\end_layout

\end_deeper
\begin_layout Itemize
Self-tuning scheduler
\begin_inset CommandInset citation
LatexCommand cite
key "Cucinotta:Self-Tuning"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
treat existing real-time application as black box: 
\begin_inset Quotes eld
\end_inset

applications that are characterized by some temporal constraints, but are
 not developed using a specific API
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
insight: applications have real-time behavior but do not expose it, I modify
 applications and allow them to expose this
\end_layout

\begin_layout Itemize
estimate period and execution time by looking at its outside behavior
\end_layout

\begin_layout Itemize
study in this paper: choosing the wrong scheduling period causes deadline
 misses or over-allocation, so schedulers that decouple scheduling period
 from application period can be inefficient
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
whole-system approaches: lightweight specification
\end_layout

\begin_deeper
\begin_layout Itemize
Redline
\begin_inset CommandInset citation
LatexCommand cite
key "Yang:Redline"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "Redline Slides"
target "http://os.inf.tu-dresden.de/local/dropscon/archive/2008-12-03-Michael-Redline.pdf"

\end_inset


\end_layout

\begin_layout Itemize
also no modifications to applications
\end_layout

\begin_layout Itemize
manual annotation with period and fixed execution time
\end_layout

\begin_layout Itemize
will adapt parameters at runtime using feedback
\end_layout

\begin_layout Itemize
uses EDF scheduler
\end_layout

\end_deeper
\begin_layout Itemize
coop_poll
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:CoopPoll"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
uses application insight, no black-box approach, applications explicitly
 expose knowledge
\end_layout

\begin_layout Itemize
propagates application's task descriptions down to the kernel, but without
 look-ahead
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
fair processor sharing: minimal interface
\end_layout

\begin_deeper
\begin_layout Itemize
historical context: fairness between users time-sharing system
\end_layout

\begin_layout Itemize
good average application behavior when developers do nothing
\end_layout

\begin_layout Itemize
starts with no interface to expose anything
\end_layout

\begin_layout Itemize
virtual time approaches, like CFS
\begin_inset CommandInset citation
LatexCommand cite
key "Molnar:CFS"

\end_inset

 in Linux
\end_layout

\begin_layout Itemize
research approaches start out as fair sharing and add twists
\begin_inset CommandInset citation
LatexCommand cite
key "Bavier:VirtualTime"

\end_inset


\end_layout

\begin_layout Itemize
while coming from the other end, it overlaps with reservation approaches
 in the spectrum:
\end_layout

\begin_deeper
\begin_layout Itemize
sharing based on cycle rates with slack reclaiming similar to CBS work
\end_layout

\begin_layout Itemize
timing guarantees for virtual-time based algorithms are possible by showing
 equivalence to EDF scheduling
\end_layout

\end_deeper
\begin_layout Itemize
BVT
\begin_inset CommandInset citation
LatexCommand cite
key "Duda:BVT"

\end_inset

 adds a warp to express dispatch priority
\end_layout

\begin_deeper
\begin_layout Itemize
many task parameters (CPU share, warp time, warp time limit, warp time requireme
nt) require global knowledge, some dimensionless, not inherent to application
\end_layout

\begin_layout Itemize
warp time is a priority, admission control needed to control the assignment
 of warp parameters
\end_layout

\end_deeper
\begin_layout Itemize
BERT
\end_layout

\begin_deeper
\begin_layout Itemize
binary overload mitigation: important tasks unboundedly steal from unimportant
 tasks
\end_layout

\end_deeper
\begin_layout Itemize
Nemesis
\begin_inset CommandInset citation
LatexCommand cite
key "Leslie:Nemesis"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
criticism of virtual processors (fair sharing): performance of each virtual
 processor depends on load on other virtual processors
\end_layout

\begin_layout Itemize
both fixed priorities and virtual processors require global knowledge to
 predict their behavior
\end_layout

\begin_layout Itemize
basic idea: free developer from determining resource requirements
\end_layout

\begin_layout Itemize
use feedback control
\end_layout

\end_deeper
\begin_layout Itemize
like reservations, virtual time put isolation first and application’s timing
 requirements second
\end_layout

\begin_deeper
\begin_layout Itemize
my approach: put applications first, consider fairness only on overload
\end_layout

\begin_layout Itemize
without global coordination, applications should specify timing requirements
 directly, not as relative importance using weights or shares
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
task models that express other properties: gravitational task model
\end_layout

\begin_layout Itemize
two-level scheduling
\begin_inset CommandInset citation
LatexCommand cite
key "Shin:Compositional"

\end_inset


\end_layout

\begin_layout Itemize
application-specific predictors can be used instead of the default auto-regressi
ve predictor
\end_layout

\begin_layout Itemize
device IO
\end_layout

\begin_deeper
\begin_layout Itemize
propagate deadlines to device queues when jobs issue IO requests
\end_layout

\begin_deeper
\begin_layout Itemize
helps anticipatory schedulers
\begin_inset CommandInset citation
LatexCommand cite
key "Iyer:Anticipatory"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
propagate future jobs to devices for prefetching
\begin_inset CommandInset citation
LatexCommand cite
key "Patterson:InformedPrefetching"

\end_inset


\end_layout

\begin_layout Itemize
asynchronous device access and queue-ahead of upcoming jobs: provides the
 same look-ahead for device IO
\end_layout

\begin_deeper
\begin_layout Itemize
fostered by GCD dispatch sources and Boost.Asio
\end_layout

\end_deeper
\begin_layout Itemize
devices become smart and self-schedule: manage the queue themselves
\end_layout

\begin_deeper
\begin_layout Itemize
example: interrupt rate limiting, low-latency packet override and another
 rate limiting for the low-latency override in Intel 82576 network card
\begin_inset CommandInset citation
LatexCommand cite
key "Intel_NIC"

\end_inset


\end_layout

\begin_layout Itemize
submit code directly to such smart devices, run the scheduler on the device
\begin_inset CommandInset citation
LatexCommand cite
key "Nightingale:Helios"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Dynamic Active Subset helps
\begin_inset CommandInset citation
LatexCommand cite
key "Reuther:DAS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
ARTIFACT
\begin_inset CommandInset citation
LatexCommand cite
key "Sasinowski:ARTIFACT"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
ubiquitous priorities, MPEG execution model hard, load-shedding (forward
 reference to adaptivity)
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "4-chap:Parallelism"

\end_inset

Scheduling meets Multicore
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
multicores add another scheduling dimension: placement in space accompanies
 ordering in time
\end_layout

\begin_layout Itemize
scheduling in time is being deemphasized
\end_layout

\begin_deeper
\begin_layout Itemize
context switching used to be practical when many threads needed to be multiplexe
d in quasi-parallel fashion on one CPU
\end_layout

\begin_layout Itemize
with the number of cores approaching the number of ready threads, this approach
 gets impractical
\end_layout

\begin_layout Itemize
micro-benchmarks show cache-miss-related slowdown caused by only the timer
 tick
\begin_inset CommandInset citation
LatexCommand cite
key "Tsafrir:OSNoise"

\end_inset


\end_layout

\begin_layout Itemize
hardware transactional memory aborts on context switch
\begin_inset CommandInset citation
LatexCommand cite
key "AMD_ASF_Spec"

\end_inset


\end_layout

\begin_layout Itemize
many other resources cannot be preempted at all
\end_layout

\begin_deeper
\begin_layout Itemize
disk jobs
\end_layout

\begin_layout Itemize
GPUs get preemption functionality, but there is a lot of state to save and
 restore
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
systems increasingly schedule in space instead of time
\end_layout

\begin_deeper
\begin_layout Itemize
parallelism is replacing frequency scaling as the means to increase performance
\end_layout

\begin_layout Itemize
Lampson predicted this
\begin_inset CommandInset citation
LatexCommand cite
key "Lampson:HintsDesign"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

split resources in a fixed way if in doubt, rather than sharing them
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
multiplex as long as hardware is expensive, statically assign once hardware
 is cheap
\end_layout

\end_deeper
\begin_layout Itemize
specialize cores dynamically to execute kernel services
\end_layout

\begin_layout Itemize
placement becomes all the more relevant when cores differentiate: specialized
 instruction sets, distance/latency gaps
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:ParallelJungle"

\end_inset


\end_layout

\begin_layout Itemize
need to choreograph heterogeneous accelerators
\end_layout

\begin_layout Itemize
shutting down cores is also an important mechanism to save energy, because
 DVFS is losing effectiveness
\begin_inset CommandInset citation
LatexCommand cite
key "LeSueur:DVFS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
lambda-programming removes threads from application development, now remove/demo
te them in kernel interface
\end_layout

\begin_deeper
\begin_layout Itemize
similar ideas explored earlier: scheduler activations
\begin_inset CommandInset citation
LatexCommand cite
key "Anderson:SchedulerActivations"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
threads can be co-scheduled on one core, they hide spatial properties from
 the application
\end_layout

\begin_layout Itemize
applications often work around this by creating more threads than there
 are processors to make sure all hardware parallelism is exploited
\end_layout

\begin_layout Itemize
idea: assign cores to applications, not virtual sections of a core's time
 (i.e.
 threads)
\end_layout

\begin_layout Itemize
still need kernel-level execution contexts, which you may still call threads
\end_layout

\begin_layout Itemize
work queues offer parallelism, dispatching is separate, system can decide
 placement; threads blend this in one concept
\end_layout

\begin_layout Itemize
parallelism becomes controllable instead of being fixed in the application
 code
\end_layout

\end_deeper
\begin_layout Itemize
work queues can also be used to manage placement for other interfaces, like
 the systemcall interface to the kernel
\begin_inset CommandInset citation
LatexCommand cite
key "Soares:FlexSC"

\end_inset


\begin_inset Float marginfigure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Queues_Mode_Switches.svg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Work Queues Prevent Mode Switches
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
improves throughput and (surprisingly) also latency when loaded
\end_layout

\begin_layout Itemize
extends the spine+workers programming model to workloads where the kernel
 is the worker (i.e.
 Internet servers)
\end_layout

\begin_layout Itemize
notifications from kernel to user space could work asynchronously, but don't
 as far as I know, closest: kqueue
\begin_inset CommandInset citation
LatexCommand cite
key "Lemon:Kqueue"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
DSI on L4 provides asynchronous data movement between different address
 spaces
\end_layout

\begin_layout Itemize
many throughput-oriented drivers (network cards) work this way, too
\end_layout

\begin_layout Itemize
work queues also used to drive GPUs predictably
\begin_inset CommandInset citation
LatexCommand cite
key "Kato:Timegraph"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Tetris
\begin_inset Quotes erd
\end_inset

 style scheduling: we want to know the widths and heights of jobs to plan
 placement and order
\end_layout

\begin_deeper
\begin_layout Itemize
prerequisite to implementing placement policies is sufficient information
 on what you place
\end_layout

\begin_layout Itemize
using asynchronous blocks for parallelism and deadlines and metrics attached
 to block groups for real-time, both are decoupled
\end_layout

\begin_deeper
\begin_layout Itemize
decoupling makes sense if you consider the trend to massive parallelism
 (see GPUs)
\end_layout

\begin_layout Itemize
no interest in the finishing time for a particular lambda, but in the overall
 makespan (paper: 
\begin_inset Quotes eld
\end_inset

makespan computation for GPU threads
\begin_inset Quotes erd
\end_inset

 in submission to ECRTS)
\end_layout

\begin_layout Itemize
on GPUs, the individual lambdas may be dispatched by hardware
\begin_inset CommandInset citation
LatexCommand cite
key "NVIDIA_Fermi"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
execution time estimates give us the total execution time, but when spread
 across cores, it might take less wall-clock time to finish
\end_layout

\begin_layout Itemize
application must provide execution time estimate for any number of cores
 the job can use
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end solution
\end_layout

\begin_deeper
\begin_layout Itemize
workload: make amenable for data-parallel processing like intrinsic load-balanci
ng
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:Balancing"

\end_inset


\end_layout

\begin_layout Itemize
application: offer parallelism to the system, provide estimates on parallel
 scalability
\end_layout

\begin_layout Itemize
system: non-work-conserving placement of jobs on cores and order in time
 based on deadlines, execution time estimates and parallelism
\end_layout

\end_deeper
\begin_layout Itemize
describe parallel workload and placement algorithm in detail
\end_layout

\begin_deeper
\begin_layout Itemize
video parallelization and balancing
\end_layout

\begin_layout Itemize
system communicates consequences of placement decision back to the application
\end_layout

\begin_deeper
\begin_layout Itemize
number of threads to be used by GCD runtime
\end_layout

\begin_layout Itemize
avoid context-switch, so no upcall interface, but info-page-style shared
 memory
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
system scheduler
\end_layout

\begin_deeper
\begin_layout Itemize
G-EDF is optimal for soft real-time
\begin_inset CommandInset citation
LatexCommand cite
key "Devi:GEDFTardiness"

\end_inset


\end_layout

\begin_layout Itemize
G-EDF not optimal with respect to feasibility, but optimal deadline-based
 algorithms are known
\begin_inset CommandInset citation
LatexCommand cite
key "Levin:DP-Fair"

\end_inset


\end_layout

\begin_layout Itemize
efficient EDF implementation strategies are known for single cores
\begin_inset CommandInset citation
LatexCommand cite
key "Short:EDFTaskManagement"

\end_inset

 and multicores
\begin_inset CommandInset citation
LatexCommand cite
key "Lelli:Scalable_EDF"

\end_inset


\end_layout

\begin_layout Itemize
extensive scalability studies for multicores
\begin_inset CommandInset citation
LatexCommand cite
key "Brandenburg:GlobalEDF"

\end_inset


\end_layout

\begin_layout Itemize
G-EDF scales for today's core counts, in the future we may want to consider
 clustered scheduling
\begin_inset CommandInset citation
LatexCommand cite
key "Calandrino:ClusteredEDF"

\end_inset


\end_layout

\begin_layout Itemize
ongoing discussion on trading schedulability and locality using partitioning,
 clustering
\begin_inset CommandInset citation
LatexCommand cite
key "Bastoni:EmpiricalComparison"

\end_inset

 and semi-partitioning
\begin_inset CommandInset citation
LatexCommand cite
key "Bastoni:SemiPartitioned"

\end_inset

 (some tasks allowed to migrate)
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end evaluation
\end_layout

\begin_deeper
\begin_layout Itemize
non-work-conserving placement of jobs on one core as long as it fits, fire
 up second core only when necessary
\end_layout

\begin_layout Itemize
core count reduced more aggressively compared to:
\end_layout

\begin_deeper
\begin_layout Itemize
greedy commodity schedulers
\end_layout

\begin_layout Itemize
heuristics based on the past
\end_layout

\begin_layout Itemize
planning based on worst-case execution time and period
\begin_inset CommandInset citation
LatexCommand cite
key "Collette:JobParallelism"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
the number of kernel traps and process migrations could be lower in my system,
 because I assign cores exclusively (i.e.
 no time-slicing) for a while
\end_layout

\end_deeper
\begin_layout Itemize
discuss related work in detail
\end_layout

\begin_deeper
\begin_layout Itemize
schedule in space instead of in time, demote threads
\end_layout

\begin_deeper
\begin_layout Itemize
kernel threads are the wrong abstraction
\begin_inset CommandInset citation
LatexCommand cite
key "Anderson:SchedulerActivations"

\end_inset


\end_layout

\begin_layout Itemize
communication of available parallelism from application to scheduler allows
 global core arbitration
\end_layout

\end_deeper
\begin_layout Itemize
OS design for systems with 1000+ cores focus on space sharing instead of
 time sharing
\begin_inset CommandInset citation
LatexCommand cite
key "Wentzlaff:fos"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
even stronger separation between cores: explicit communication instead of
 cache coherent shared memory
\begin_inset CommandInset citation
LatexCommand cite
key "Baumann:Barrelfish"

\end_inset


\end_layout

\begin_layout Itemize
run parts of the system close or on the device they target
\begin_inset CommandInset citation
LatexCommand cite
key "Nightingale:Helios"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
existing placement strategies can augment our placement algorithm
\end_layout

\begin_deeper
\begin_layout Itemize
fits well with our programming model of applications exposing metadata on
 parallel work
\end_layout

\begin_layout Itemize
performance counters often used for runtime monitoring, like online cache
 utility modeling
\begin_inset CommandInset citation
LatexCommand cite
key "West:CacheUtility"

\end_inset

 and detection of sharing patterns
\begin_inset CommandInset citation
LatexCommand cite
key "Tam:SharingAwareScheduling"

\end_inset


\end_layout

\begin_layout Itemize
L2 cache misses is the primary metric that expresses locality of a job,
 because it covers the two major harmful communication paths: memory accesses
 and coherency traffic
\end_layout

\begin_layout Itemize
placement of jobs on cores influences contention on caches, prefetcher and
 DRAM controller
\begin_inset CommandInset citation
LatexCommand cite
key "Zhuravlev:DIO"

\end_inset


\end_layout

\begin_layout Itemize
cache thrashing with hyperthreads
\begin_inset CommandInset citation
LatexCommand cite
key "Fedorova:SMT_Scheduling"

\end_inset


\end_layout

\begin_layout Itemize
on NUMA-systems, placement influences memory latency
\begin_inset CommandInset citation
LatexCommand cite
key "Blagodurov:DINO"

\end_inset


\end_layout

\begin_layout Itemize
batch work by moving it around in the scheduling window to enable longer
 sleep times
\begin_inset CommandInset citation
LatexCommand cite
key "Awan:EnhancedRaceToHalt"

\end_inset


\end_layout

\begin_layout Itemize
migrate to prevent fan noise or throttling
\begin_inset CommandInset citation
LatexCommand cite
key "Merkel:EnergyModel"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
execution order of blocks within a job is relevant for speed and cache working
 set size
\begin_inset CommandInset citation
LatexCommand cite
key "Chen:ConstructiveCacheSharing"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
chunking, placement and ordering influence speedup for confluent algorithms
\begin_inset CommandInset citation
LatexCommand cite
key "Kulkarni:GaloisScheduling"

\end_inset


\end_layout

\begin_layout Itemize
use a lightweight specification language to describe beneficial scheduling
 policies
\begin_inset CommandInset citation
LatexCommand cite
key "Nguyen:ConcurrentSchedulers"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
knowledge about the job layout in both space and time allows disabling the
 periodic timer tick
\end_layout

\begin_deeper
\begin_layout Itemize
dynamically dedicate cores: place work somewhere, then let it run without
 interference
\end_layout

\begin_deeper
\begin_layout Itemize
the timer-tick is OS-level polling, hits all cores no matter what they run
\end_layout

\begin_layout Itemize
move to a tick-less kernels helps to reducing OS noise and energy consumption
\end_layout

\end_deeper
\begin_layout Itemize
good for barrier-sync-style HPC applications: even the timer interrupt hurts
 them badly
\begin_inset CommandInset citation
LatexCommand cite
key "Tsafrir:OSNoise"

\end_inset


\end_layout

\begin_layout Itemize
suggested solution: demand-driven 
\begin_inset Quotes eld
\end_inset

smart
\begin_inset Quotes erd
\end_inset

 timers which allow for batching instead of the slavish periodic tick
\end_layout

\begin_deeper
\begin_layout Itemize
idea is an extension to timers with precision
\begin_inset CommandInset citation
LatexCommand cite
key "Peter:30Seconds"

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
hardware extensions supporting work queues and reduced context switching
\end_layout

\begin_deeper
\begin_layout Itemize
NVIDIA Fermi uses GigaThread hardware to decide placement
\begin_inset CommandInset citation
LatexCommand cite
key "NVIDIA_Fermi"

\end_inset


\end_layout

\begin_layout Itemize
Core Manager distributes work and its data to processing elements
\begin_inset CommandInset citation
LatexCommand cite
key "Limberg:Tomahawk"

\end_inset


\end_layout

\begin_layout Itemize
Asynchronous Direct Messages
\begin_inset CommandInset citation
LatexCommand cite
key "Sanchez:ADM"

\end_inset

 allow very fine-grained lambdas
\end_layout

\begin_deeper
\begin_layout Itemize
more flexible: small hardware extension to be used by work queue implementation
\end_layout

\begin_layout Itemize
allows exposing more parallelism by splitting into smaller lambdas
\end_layout

\begin_layout Itemize
scalable because of local queues and work stealing that bypasses the memory
 hierarchy
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
holistic approach that extends placement problems beyond individual computers
 to distributed systems: MOSIX
\end_layout

\begin_deeper
\begin_layout Itemize
load balancing on networks of computers, predicts future problems within
 manycores
\end_layout

\begin_layout Itemize
increasing message latency between cores relative to compute speed: placement
 of work and communication patterns relevant
\end_layout

\begin_layout Itemize
employs gossiping to establish global system view without a central authority
\end_layout

\begin_layout Itemize
ad-hoc solution for my approach: assume that lambdas within the same job
 are more likely to talk to each other, place closer together
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Chapter
\begin_inset CommandInset label
LatexCommand label
name "5-chap:Adaptivity"

\end_inset

Adapt to Handle Overload
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
our 
\begin_inset Quotes eld
\end_inset

no admission
\begin_inset Quotes erd
\end_inset

 policy requires us to deal with overloads when the work does not fit within
 the deadlines
\end_layout

\begin_deeper
\begin_layout Itemize
but only when overloaded: timeliness first, fairness only when overloaded
\end_layout

\end_deeper
\begin_layout Itemize
load shedding is an old concept
\begin_inset CommandInset citation
LatexCommand cite
key "Lampson:HintsDesign"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

shed load to control demand, rather than allowing the system to become overloade
d.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Robert Morris idea: red button next to terminal, push when dissatisfied,
 system must raise your QoS or throw you off
\end_layout

\begin_layout Itemize
this old idea already argued for quality-aware adaptation, not just load-aware
\end_layout

\begin_layout Itemize
when overloaded, real-time applications become brittle and show bi-modal
 fairness
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:PriorityProgress"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
quality-aware adaptation is application-specific
\end_layout

\begin_deeper
\begin_layout Itemize
some work just needs to be done, no discussion, no adaptation possible
\end_layout

\begin_deeper
\begin_layout Itemize
I would argue this is the common case
\end_layout

\begin_layout Itemize
we can only hope to compensate by using the most efficient compute resource
 and organize it the most efficient way
\end_layout

\end_deeper
\begin_layout Itemize
some applications can make quality/resource trade-offs according to application-
specific notion of quality
\end_layout

\begin_deeper
\begin_layout Itemize
video is one example
\end_layout

\begin_layout Itemize
however, quality per invested CPU time is varying: with resource-fairness,
 quality would be varying
\end_layout

\begin_layout Itemize
application knowledge needed, however applications can lie to unfairly degrade
 others
\end_layout

\begin_layout Itemize
combine resource-fairness and quality-fairness
\end_layout

\begin_layout Itemize
this also applies to resources other than CPU time, like network bandwidth
 for streaming
\end_layout

\end_deeper
\begin_layout Itemize
look-ahead enables choosing the part to degrade amongst many options, compared
 to forcibly degrade the job at hand
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end solution
\end_layout

\begin_deeper
\begin_layout Itemize
workload: offer different processing paths, trading resources and quality
\end_layout

\begin_layout Itemize
application: under given resource constraints, find a quality-optimal path
 through this lattice of options
\end_layout

\begin_layout Itemize
system: distribute computing resource cutbacks in a quality-fair fashion
\end_layout

\end_deeper
\begin_layout Itemize
backpressure needs to be quality-fair, not resource-fair, but the quality
 scale is application specific and does not compare
\end_layout

\begin_deeper
\begin_layout Itemize
global quality-scheduling too complex, resort to balanced backpressure and
 per-application adaptivity
\end_layout

\begin_layout Itemize
needs help from the applications: provide percentage of missed deadlines
 relative to the maximum quality case, that represents the bare minimum
 quality users will accept
\end_layout

\begin_layout Itemize
backpressure will be distributed amongst adaptive applications weighted
 by this minimum quality
\end_layout

\begin_layout Itemize
assumption: linear quality drop from meeting all deadlines down to that
 percentage
\end_layout

\begin_deeper
\begin_layout Itemize
could also use time-utility functions to optimize
\end_layout

\begin_layout Itemize
could also include heuristics like less degradation for the frontmost applicatio
n
\end_layout

\end_deeper
\begin_layout Itemize
use of percentage of missed deadlines as quality parameter inspired by QRMS
\begin_inset CommandInset citation
LatexCommand cite
key "Hamann:QRMS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
describe fallback decoding path for video
\begin_inset CommandInset citation
LatexCommand cite
key "Roitzsch:VideoQuality"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
decoding time estimate already given, quality estimate needed
\end_layout

\begin_layout Itemize
greedy solution for (constrained) bin-packing: order jobs by quality/resource
 ratio
\end_layout

\end_deeper
\begin_layout Itemize
end-to-end evaluation
\end_layout

\begin_deeper
\begin_layout Itemize
compare reduction policy in scheduler: quality-based vs.
 fairness-based
\end_layout

\begin_layout Itemize
compare to ad-hoc adaptation using a low water-mark in the video player
 queue
\end_layout

\begin_layout Itemize
compare to fully clairvoyant oracle that calculates truly quality-optimal
 execution
\end_layout

\end_deeper
\begin_layout Itemize
discuss related work
\end_layout

\begin_deeper
\begin_layout Itemize
other fairness-policies can be integrated into my system as well
\end_layout

\begin_deeper
\begin_layout Itemize
relative or absolute shares for temporal isolation, like CBS
\end_layout

\end_deeper
\begin_layout Itemize
task models that allow for deadline misses
\end_layout

\begin_deeper
\begin_layout Itemize
(m,k)-firm tasks
\end_layout

\begin_layout Itemize
imprecise computation
\begin_inset CommandInset citation
LatexCommand cite
key "Lin:Imprecise"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
scheduling systems that control overload
\end_layout

\begin_deeper
\begin_layout Itemize
overload handling with adaptive reservations
\begin_inset CommandInset citation
LatexCommand cite
key "Abeni:AdaptiveReservations"

\end_inset


\end_layout

\begin_layout Itemize
virtual time for progress fairness
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:CoopPoll"

\end_inset


\end_layout

\begin_layout Itemize
resource kernels
\begin_inset CommandInset citation
LatexCommand cite
key "Rajkumar:ResourceKernels"

\end_inset

: user-level QoS expected to be more useful than stacked schedulers
\end_layout

\end_deeper
\begin_layout Itemize
overload notification
\end_layout

\begin_deeper
\begin_layout Itemize
inject language exceptions on deadline overruns: post-mortem, no look-ahead
\end_layout

\end_deeper
\begin_layout Itemize
application-specific adaptation
\end_layout

\begin_deeper
\begin_layout Itemize
load-shedding queues in network servers
\begin_inset CommandInset citation
LatexCommand cite
key "Welsh:SEDA"

\end_inset


\end_layout

\begin_layout Itemize
reducing video quality
\begin_inset CommandInset citation
LatexCommand cite
key "Isovic:QoS_Video,Wuest:QoS_Video"

\end_inset


\end_layout

\begin_layout Itemize
other sources for adaptive video
\end_layout

\begin_deeper
\begin_layout Itemize
SVC
\end_layout

\begin_layout Itemize
adaptive streaming protocols: application propagates back-pressure even
 to the server
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
prioritize work and skip the low priorities when congested
\begin_inset CommandInset citation
LatexCommand cite
key "Krasic:PriorityProgress"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
simple quality-aware scheme
\end_layout

\begin_layout Itemize
global priority-monotonic ordering of video frames
\end_layout

\begin_layout Itemize
unclear how much of the fairness benefits stem from the priority sorting
 or just from global queueing
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Chapter
The Road Ahead
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
changing paradigm of computing, future: always on, always connected
\end_layout

\begin_deeper
\begin_layout Itemize
smartphones, tablets and the cloud usher in a new era
\end_layout

\begin_layout Itemize
mobile computing, but still with responsiveness and smooth video demanded
 by users
\end_layout

\begin_layout Itemize
battery and energy constraints added to the problem space
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

energy is the new speed
\begin_inset Quotes erd
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
energy works differently
\end_layout

\begin_deeper
\begin_layout Itemize
deadlines are inherent to the application, energy limitations are driven
 by the long-term intent of the user
\end_layout

\begin_layout Itemize
many existing solutions throttle threads according to an energy budget
\begin_inset CommandInset citation
LatexCommand cite
key "Roy:Cinder"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
not graceful degradation, but just degradation
\end_layout

\end_deeper
\begin_layout Itemize
assuming software does only useful work against the user's stated intent,
 throttling makes no sense
\end_layout

\begin_layout Itemize
only energy efficiency (doing the same with less energy) and maybe adaptivity
 remains
\end_layout

\begin_deeper
\begin_layout Itemize
high impact of tail power: power state more important than utilization
\begin_inset CommandInset citation
LatexCommand cite
key "Pathak:PowerModeling"

\end_inset


\end_layout

\begin_layout Itemize
piggy-backing and bactching helps a lot, which needs knowledge about acceptable
 delays for requests
\end_layout

\begin_layout Itemize
directly enabled by look-ahead and deadline-knowledge
\end_layout

\begin_layout Itemize
batch disk IO with deferrable requests
\begin_inset CommandInset citation
LatexCommand cite
key "Weissel:Coop_IO"

\end_inset


\end_layout

\begin_layout Itemize
batch network requests to power up radio less often
\begin_inset CommandInset citation
LatexCommand cite
key "Roy:Cinder,Lagar-Cavilla:TrafficBackfilling"

\end_inset


\end_layout

\begin_layout Itemize
in the large: use predictions of renewable energy supply to schedule background
 jobs in datacenters
\begin_inset CommandInset citation
LatexCommand cite
key "Aksanli:EnergyPrediction"

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
we may have targeted hardware with reduced instruction sets available that
 is more energy-efficient
\end_layout

\begin_deeper
\begin_layout Itemize
pieces of GPU code (and other ISAs with tighter assumptions and less ability)
 interwoven with CPU code
\end_layout

\begin_layout Itemize
devices like GPU (and increasingly network cards
\begin_inset CommandInset citation
LatexCommand cite
key "Nightingale:Helios"

\end_inset

) treated as compute resources like CPU, not as a peripheral
\begin_inset CommandInset citation
LatexCommand cite
key "Kato:GPUManagement"

\end_inset


\end_layout

\begin_layout Itemize
hardware video decoders as an example of a special-purpose, limited-ISA
 co-processor
\end_layout

\begin_deeper
\begin_layout Itemize
saves some energy (up to 25%
\begin_inset CommandInset citation
LatexCommand cite
key "LeSueur:SlowDownSleep"

\end_inset

), but not game-changing savings
\end_layout

\begin_layout Itemize
treat as any coprocessor that work with tighter restrictions on the available
 instructions can be offloaded to (see 
\family typewriter
restrict
\family default
 keyword proposal
\begin_inset CommandInset citation
LatexCommand cite
key "Sutter:C++AMP_Keynote"

\end_inset

)
\end_layout

\begin_layout Plain Layout
\begin_inset Flex NewThought
status collapsed

\begin_layout Plain Layout
As a side note,
\end_layout

\end_inset

 even though this work does not deal with peripheral scheduling: What complicate
s the metadata-driven scheduling is the increasing complexity of devices
 themselves.
 The position of our disk write request is a logical block number, with
 only the drive knowing the physical position of the actual sector.
 Devices also increasingly develop internal self-scheduling capabilities:
 The software scheduler in the driver can send multiple outstanding requests
 to the device and a hardware scheduler in the device will use its more
 detailed knowledge on request execution properties to order the requests
 beneficially.
\end_layout

\begin_layout Plain Layout
Disks behave this way since the introduction of native command queueing
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
native command queueing
\end_layout

\end_inset

.
\begin_inset CommandInset citation
LatexCommand cite
key "Intel:NCQ"

\end_inset

 But because the device’s scheduling policy is fixed, it still makes sense
 for the software scheduler to pre-order the request according to its own
 policy, using job metadata derived with a simplified model of the device.
 A disk scheduler may have a notion of request urgency and inter-application
 fairness that the hardware scheduler would not know about.
\begin_inset CommandInset citation
LatexCommand cite
key "Reuther:DAS"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
special-purpose devices offer more choice for job placement and change energy
 tradeoffs, but they do not eliminate the fundamental problem to get given
 work done (meeting given deadlines) with as little resources (energy, time)
 as possible
\end_layout

\begin_deeper
\begin_layout Itemize
from FPGAs over DSP/SoCs to GPGPU and GPCPU: design spectrum for compute
 ressources plus interconnects
\end_layout

\begin_layout Itemize
placement decisions in space and time still relevant
\end_layout

\end_deeper
\begin_layout Itemize
choosing between race-to-halt and slowdown depends on workload and platform
\begin_inset CommandInset citation
LatexCommand cite
key "LeSueur:SlowDownSleep"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
end-to-end solution: this is only a rough sketch
\end_layout

\begin_deeper
\begin_layout Itemize
workload: energy-aware encoding of video
\end_layout

\begin_layout Itemize
we get the three swim lanes again, but with a different metric and intention
\end_layout

\begin_layout Itemize
application: maintain energy model (enhances real-time), code for specialized
 hardware ISA (enables placement), adapt to save energy (enhances adaptivity)
\end_layout

\begin_layout Itemize
system: collect and act on energy metrics (enhances real-time), outsource
 to specialized hardware (enhances placement), backpressure based on energy
 intent (enhances adaptivity)
\end_layout

\end_deeper
\begin_layout Itemize
metadata to decide energy consequences can be collected per-job at runtime
\end_layout

\begin_deeper
\begin_layout Itemize
performance counter can help to tell memory- and CPU-bound jobs apart
\end_layout

\begin_deeper
\begin_layout Itemize
clocking down the CPU especially helpful for memory-bound jobs
\begin_inset CommandInset citation
LatexCommand cite
key "Snowdon:Koala"

\end_inset


\end_layout

\begin_layout Itemize
exploit look-ahead for energy metadata: clock CPU down and then run all
 pending memory-bound jobs
\end_layout

\end_deeper
\begin_layout Itemize
linear combination of metrics to predict energy in a similar way to the
 execution time
\end_layout

\begin_deeper
\begin_layout Itemize
performance counters to train energy model
\begin_inset CommandInset citation
LatexCommand cite
key "Merkel:EnergyModel"

\end_inset


\end_layout

\begin_layout Itemize
energy counter in Intel Sandy Bridge CPUs
\end_layout

\begin_layout Itemize
more complex energy predictors available
\begin_inset CommandInset citation
LatexCommand cite
key "Lewis:CAP"

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
using backpressure also for energy-management
\end_layout

\begin_deeper
\begin_layout Itemize
some applications can adapt their energy or computation time needs
\begin_inset CommandInset citation
LatexCommand cite
key "Flinn:EnergyAdaptation"

\end_inset


\end_layout

\begin_layout Itemize
trivial examples (disable backup on low battery) are rather obvious and
 not interesting, more dynamic examples are rare
\end_layout

\begin_layout Itemize
use energy instead of CPU time as a cost metric in adaptation decisions
\end_layout

\end_deeper
\begin_layout Itemize
other ends that were left open in this thesis
\end_layout

\begin_deeper
\begin_layout Itemize
a thread-less systems architecture (kernel interface), jobs as first class
 citizens in the system
\end_layout

\begin_layout Itemize
fault tolerance: recovery options may differ in required time and provided
 service quality, deadlines helpful
\end_layout

\begin_layout Itemize
unreliable computing: reliability requirements can be attached to lambdas,
 placement on reliable or unreliable core
\end_layout

\end_deeper
\begin_layout Itemize
future development can be researched within the presented design
\end_layout

\begin_layout Itemize
summarize the key contributions again
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
backmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "Bibliography/Thesis"
options "Bibliography/Thesis"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nochapteredge
\end_layout

\end_inset


\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList margintable

\end_inset


\begin_inset CommandInset index_print
LatexCommand printindex
type "idx"

\end_inset


\end_layout

\end_body
\end_document
